{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51db7e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9119cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/mergeddecoder_foldtree2_test.pkl\n",
      "Encoder: mk1_Encoder(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (res_backbone_res): TransformerConv(256, 256, heads=5)\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): GraphNorm(256)\n",
      "  )\n",
      "  (bn): BatchNorm1d(857, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.01, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (ffin): Sequential(\n",
      "    (0): Linear(in_features=1017, out_features=512, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "  )\n",
      "  (out_dense): Sequential(\n",
      "    (0): Linear(in_features=276, out_features=256, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (vector_quantizer): VectorQuantizerEMA(\n",
      "    (embeddings): Embedding(40, 128)\n",
      "  )\n",
      ")\n",
      "Decoder: HeteroGAE_Decoder(\n",
      "  (convs): ModuleList(\n",
      "    (0-2): 3 x HeteroConv(num_relations=4)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-2): 3 x GraphNorm(256)\n",
      "  )\n",
      "  (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm_in): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  (bn_foldx): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm_foldx): LayerNorm((23,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.005, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (lin): Sequential(\n",
      "    (0): Dropout(p=0.005, inplace=False)\n",
      "    (1): DynamicTanh(normalized_shape=768, alpha_init_value=0.5, channels_last=True)\n",
      "    (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): GELU(approximate='none')\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      "  (aadecoder): Sequential(\n",
      "    (0): Dropout(p=0.005, inplace=False)\n",
      "    (1): Linear(in_features=640, out_features=256, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (6): GELU(approximate='none')\n",
      "    (7): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "model = 'models/mergeddecoder_foldtree2_test'\n",
    "with open( model + '.pkl', 'rb') as f:\n",
    "\tencoder, decoder = pickle.load(f)\n",
    "\n",
    "print('Model loaded from', model + '.pkl')\n",
    "print('Encoder:', encoder)\n",
    "print('Decoder:', decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0453b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder loaded: mk1_Encoder(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (res_backbone_res): TransformerConv(256, 256, heads=5)\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): GraphNorm(256)\n",
      "  )\n",
      "  (bn): BatchNorm1d(857, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.01, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (ffin): Sequential(\n",
      "    (0): Linear(in_features=1017, out_features=512, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "  )\n",
      "  (out_dense): Sequential(\n",
      "    (0): Linear(in_features=276, out_features=256, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (vector_quantizer): VectorQuantizerEMA(\n",
      "    (embeddings): Embedding(40, 128)\n",
      "  )\n",
      ")\n",
      "Decoder loaded: HeteroGAE_Decoder(\n",
      "  (convs): ModuleList(\n",
      "    (0-2): 3 x HeteroConv(num_relations=4)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-2): 3 x GraphNorm(256)\n",
      "  )\n",
      "  (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm_in): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  (bn_foldx): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm_foldx): LayerNorm((23,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.005, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (lin): Sequential(\n",
      "    (0): Dropout(p=0.005, inplace=False)\n",
      "    (1): DynamicTanh(normalized_shape=768, alpha_init_value=0.5, channels_last=True)\n",
      "    (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): GELU(approximate='none')\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      "  (aadecoder): Sequential(\n",
      "    (0): Dropout(p=0.005, inplace=False)\n",
      "    (1): Linear(in_features=640, out_features=256, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (6): GELU(approximate='none')\n",
      "    (7): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "#use torch save and make sure it is compatible with cpu\n",
    "torch.save(encoder  , model + '_encoder.pth')\n",
    "torch.save(decoder , model + '_decoder.pth')\n",
    "\n",
    "\n",
    "encoder_loaded = torch.load(model + '_encoder.pth', map_location=torch.device('cpu'), weights_only=False)\n",
    "decoder_loaded = torch.load(model + '_decoder.pth', map_location=torch.device('cpu') , weights_only=False)\n",
    "\n",
    "\n",
    "print('Encoder loaded:', encoder_loaded)\n",
    "print('Decoder loaded:', decoder_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36407ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
