{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8502a6b",
   "metadata": {},
   "source": [
    "# Test MonoDecoders: Sequence and Geometry\n",
    "This notebook replicates the training logic from `learn.py` using the decoder in `mono_decoders.py` for amino acid and geometry prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951a071",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6586f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5103ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248b7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "from foldtree2.src import pdbgraph\n",
    "from foldtree2.src import foldtree2_ecddcd as ft2\n",
    "from foldtree2.src.mono_decoders import MultiMonoDecoder\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d142a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Data setup\n",
    "datadir = '../../datasets/foldtree2/'\n",
    "dataset_path = 'structs_traininffttest.h5'\n",
    "converter = pdbgraph.PDB2PyG(aapropcsv='./foldtree2/config/aaindex1.csv')\n",
    "struct_dat = pdbgraph.StructureDataset(dataset_path)\n",
    "train_loader = DataLoader(struct_dat, batch_size=5, shuffle=True, num_workers=4)\n",
    "\n",
    "data_sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc573dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk1_Encoder(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (res_backbone_res): TransformerConv(256, 256, heads=5)\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): GraphNorm(256)\n",
      "  )\n",
      "  (bn): BatchNorm1d(857, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.01, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (ffin): Sequential(\n",
      "    (0): Linear(in_features=1017, out_features=512, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): DynamicTanh(normalized_shape=256, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (0): DynamicTanh(normalized_shape=256, alpha_init_value=0.5, channels_last=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): DynamicTanh(normalized_shape=256, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (out_dense): Sequential(\n",
      "    (0): Linear(in_features=276, out_features=256, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (vector_quantizer): VectorQuantizerEMA(\n",
      "    (embeddings): Embedding(20, 128)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "ndim = data_sample['res'].x.shape[1]\n",
    "ndim_godnode = data_sample['godnode'].x.shape[1]\n",
    "ndim_fft2i = data_sample['fourier2di'].x.shape[1]\n",
    "ndim_fft2r = data_sample['fourier2dr'].x.shape[1]\n",
    "\n",
    "num_embeddings = 20\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "encoder = ft2.mk1_Encoder(\n",
    "\tin_channels=ndim,\n",
    "\thidden_channels=[hidden_size, hidden_size],\n",
    "\tout_channels=embedding_dim,\n",
    "\tmetadata={'edge_types': [('res','backbone','res')]},\n",
    "\tnum_embeddings=num_embeddings,\n",
    "\tcommitment_cost=0.9,\n",
    "\tedge_dim=1,\n",
    "\tencoder_hidden=hidden_size,\n",
    "\tEMA=True,\n",
    "\tnheads=5,\n",
    "\tdropout_p=0.01,\n",
    "\treset_codes=False,\n",
    "\tflavor='transformer',\n",
    "\tfftin=True\n",
    ")\n",
    "\n",
    "\n",
    "print(encoder)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91703478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing decoder for task: sequence_transformer\n",
      "False True False False False\n",
      "512 8 1 0.005\n",
      "Initializing decoder for task: contacts\n",
      "False False True False False\n",
      "MultiMonoDecoder(\n",
      "  (decoders): ModuleDict(\n",
      "    (sequence_transformer): Transformer_AA_Decoder(\n",
      "      (input_proj): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): Linear(in_features=384, out_features=512, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (4): Tanh()\n",
      "      )\n",
      "      (transformer_encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.005, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.005, inplace=False)\n",
      "            (dropout2): Dropout(p=0.005, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (lin): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (5): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (contacts): HeteroGAE_geo_Decoder(\n",
      "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convs): ModuleList(\n",
      "        (0-3): 4 x HeteroConv(num_relations=2)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-3): 4 x GraphNorm(256)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.005, inplace=False)\n",
      "      (jk): JumpingKnowledge(cat)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (lin): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (6): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "use_monodecoder = True  # Set to True to use MultiMonoDecoder, False for Single Decoder\n",
    "if use_monodecoder == True:\n",
    "\t# MultiMonoDecoder for sequence and geometry\n",
    "\tmono_configs = {\n",
    "\t\t'sequence_transformer': {\n",
    "\t\t\t'in_channels': {'res': embedding_dim},\n",
    "\t\t\t'xdim': 20,\n",
    "\t\t\t'concat_positions': True,\n",
    "\t\t\t'hidden_channels': {('res','backbone','res'): [hidden_size*2] , ('res','backbonerev','res'): [hidden_size*2]},\n",
    "\t\t\t'layers': 1,\n",
    "\t\t\t'AAdecoder_hidden': [hidden_size, hidden_size, hidden_size//2],\n",
    "\t\t\t'amino_mapper': converter.aaindex,\n",
    "\t\t\t'flavor': 'sage',\n",
    "\t\t\t'nheads': 8,\n",
    "\t\t\t'dropout': 0.005,\n",
    "\t\t\t'normalize': False,\n",
    "\t\t\t'residual': False\n",
    "\t\t},\n",
    "\t\t\n",
    "\t\t'contacts': {\n",
    "\t\t\t'in_channels': {'res': embedding_dim, 'godnode4decoder': ndim_godnode, 'foldx': 23 ,  'fft2r': ndim_fft2r, 'fft2i': ndim_fft2i},\n",
    "\t\t\t'concat_positions': True,\n",
    "\t\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*8, ('res','backbonerev','res'): [hidden_size]*8},\n",
    "\t\t\t'layers': 4,\n",
    "\t\t\t'FFT2decoder_hidden': [hidden_size, hidden_size, hidden_size],\n",
    "\t\t\t'contactdecoder_hidden': [hidden_size//4, hidden_size//8],\n",
    "\t\t\t'nheads': 1,\n",
    "\t\t\t'Xdecoder_hidden': [hidden_size, hidden_size,  hidden_size ],\n",
    "\t\t\t'metadata': converter.metadata,\n",
    "\t\t\t'flavor': 'sage',\n",
    "\t\t\t'dropout': 0.005,\n",
    "\t\t\t'output_fft': False,\n",
    "\t\t\t'output_rt':False,\n",
    "\t\t\t'normalize': False,\n",
    "\t\t\t'residual': False,\n",
    "\t\t\t'contact_mlp': False\n",
    "\n",
    "\t\t}\n",
    "\t}\n",
    "\t\n",
    "\tdecoder = MultiMonoDecoder( configs=mono_configs)\n",
    "else:\n",
    "\t# Single decoder \n",
    "\tdecoder = ft2.HeteroGAE_Decoder(\n",
    "            in_channels={'res': embedding_dim , 'godnode4decoder': ndim_godnode, 'foldx': 23},\n",
    "            concat_positions=True,\n",
    "            hidden_channels={('res','backbone','res'): [hidden_size]*5, ('res','backbonerev','res'): [hidden_size]*5, ('res','informs','godnode4decoder'): [hidden_size]*5 , ('godnode4decoder','informs','res'): [hidden_size]*5},\n",
    "            layers=5,\n",
    "            AAdecoder_hidden=[hidden_size, hidden_size, hidden_size//2],\n",
    "            Xdecoder_hidden=[hidden_size, hidden_size, hidden_size],\n",
    "            contactdecoder_hidden=[hidden_size//2, hidden_size//2],\n",
    "            nheads=5,\n",
    "            amino_mapper=converter.aaindex,\n",
    "            flavor='sage',\n",
    "            dropout=0.005,\n",
    "            normalize=True,\n",
    "            residual=False,\n",
    "            contact_mlp=False\n",
    "        )\n",
    "decoder = decoder.to(device)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24b3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiMonoDecoder(\n",
       "  (decoders): ModuleDict(\n",
       "    (sequence_transformer): Transformer_AA_Decoder(\n",
       "      (input_proj): Sequential(\n",
       "        (0): Dropout(p=0.005, inplace=False)\n",
       "        (1): Linear(in_features=384, out_features=512, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): Tanh()\n",
       "      )\n",
       "      (transformer_encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.005, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.005, inplace=False)\n",
       "            (dropout2): Dropout(p=0.005, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lin): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (5): LogSoftmax(dim=1)\n",
       "      )\n",
       "    )\n",
       "    (contacts): HeteroGAE_geo_Decoder(\n",
       "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convs): ModuleList(\n",
       "        (0-3): 4 x HeteroConv(num_relations=2)\n",
       "      )\n",
       "      (norms): ModuleList(\n",
       "        (0-3): 4 x GraphNorm(256)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.005, inplace=False)\n",
       "      (jk): JumpingKnowledge(cat)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (lin): Sequential(\n",
       "        (0): Dropout(p=0.005, inplace=False)\n",
       "        (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (6): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop (demo, similar to learn.py)\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "num_epochs = 100  # For demonstration, keep small\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "edgeweight = 0.1\n",
    "xweight = 0.1\n",
    "fft2weight = 0.01\n",
    "vqweight = 0.001\n",
    "clip_grad = True\n",
    "encoder.device = device\n",
    "encoder.train()\n",
    "decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8583d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected batch index: 912\n",
      "HeteroData(\n",
      "  identifier='A0A1I8D3W7',\n",
      "  AA={ x=[624, 20] },\n",
      "  R_true={ x=[624, 3, 3] },\n",
      "  bondangles={ x=[624, 3] },\n",
      "  coords={ x=[624, 3] },\n",
      "  fourier1di={ x=[624, 80] },\n",
      "  fourier1dr={ x=[624, 80] },\n",
      "  fourier2di={ x=[1, 1300] },\n",
      "  fourier2dr={ x=[1, 1300] },\n",
      "  godnode={ x=[1, 5] },\n",
      "  godnode4decoder={ x=[1, 5] },\n",
      "  plddt={ x=[624, 1] },\n",
      "  positions={ x=[624, 256] },\n",
      "  res={ x=[624, 857] },\n",
      "  t_true={ x=[624, 3] },\n",
      "  (godnode4decoder, informs, res)={ edge_index=[2, 624] },\n",
      "  (godnode, informs, res)={ edge_index=[2, 624] },\n",
      "  (res, backbone, res)={\n",
      "    edge_index=[2, 1247],\n",
      "    edge_attr=[623],\n",
      "  },\n",
      "  (res, backbonerev, res)={\n",
      "    edge_index=[2, 1247],\n",
      "    edge_attr=[623],\n",
      "  },\n",
      "  (res, contactPoints, res)={\n",
      "    edge_index=[2, 4552],\n",
      "    edge_attr=[4552],\n",
      "  },\n",
      "  (res, hbond, res)={\n",
      "    edge_index=[2, 632],\n",
      "    edge_attr=[632],\n",
      "  },\n",
      "  (res, informs, godnode)={ edge_index=[2, 624] },\n",
      "  (res, informs, godnode4decoder)={ edge_index=[2, 624] },\n",
      "  (res, window, res)={\n",
      "    edge_index=[2, 1244],\n",
      "    edge_attr=[1244],\n",
      "  },\n",
      "  (res, windowrev, res)={\n",
      "    edge_index=[2, 623],\n",
      "    edge_attr=[623],\n",
      "  }\n",
      ")\n",
      "torch.Size([624, 857]) x_dict[res] shape\n",
      "z_quantized shape: torch.Size([624, 128])\n",
      "vq_loss: tensor(2.9994, device='cuda:1', grad_fn=<SubBackward0>)\n",
      "x shape: torch.Size([624, 128])\n",
      "x_dict keys: dict_keys(['AA', 'R_true', 'bondangles', 'coords', 'fourier1di', 'fourier1dr', 'fourier2di', 'fourier2dr', 'godnode', 'godnode4decoder', 'plddt', 'positions', 'res', 't_true'])\n",
      "edge_index_dict keys: dict_keys([('godnode4decoder', 'informs', 'res'), ('godnode', 'informs', 'res'), ('res', 'backbone', 'res'), ('res', 'backbonerev', 'res'), ('res', 'contactPoints', 'res'), ('res', 'hbond', 'res'), ('res', 'informs', 'godnode'), ('res', 'informs', 'godnode4decoder'), ('res', 'window', 'res'), ('res', 'windowrev', 'res')])\n",
      "Encoded z shape: torch.Size([624, 128])\n"
     ]
    }
   ],
   "source": [
    "#get one sample from the dataloader\n",
    "train_loader = DataLoader(struct_dat, batch_size=1, shuffle=True, num_workers=4)\n",
    "import random\n",
    "\n",
    "randint = random.randint(0, len(train_loader) - 1)\n",
    "print(f\"Randomly selected batch index: {randint}\")\n",
    "data_sample = struct_dat[randint]\n",
    "print(data_sample)\n",
    "data = data_sample.to(device)\n",
    "optimizer.zero_grad()\n",
    "z, vqloss = encoder(data , debug = True)\n",
    "print('Encoded z shape:', z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "104038db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import PDB\n",
    "from Bio.PDB import PDBParser\n",
    "from foldtree2.src.AFDB_tools import grab_struct\n",
    "\n",
    "def getCAatoms(pdb_file):\n",
    "\tparser = PDBParser(QUIET=True)\n",
    "\t# Parse the structure\n",
    "\tstructure = parser.get_structure('structure', pdb_file)\n",
    "\tca_atoms = []\n",
    "\tfor model in structure:\n",
    "\t\tfor chain in model:\n",
    "\t\t\tfor residue in chain :\n",
    "\t\t\t\tif 'CA' in residue and PDB.is_aa(residue) :\n",
    "\t\t\t\t\tca_atoms.append(residue['CA'])\n",
    "\treturn ca_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60378468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get aa and contacts\n",
    "\n",
    "from torch_geometric.data import DataLoader , HeteroData\n",
    "from scipy import sparse\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#add precision and recall metrics\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def get_backbone(naa):\n",
    "\tbackbone_mat = np.zeros((naa, naa))\n",
    "\tbackbone_rev_mat = np.zeros((naa, naa))\n",
    "\tnp.fill_diagonal(backbone_mat[1:], 1)\n",
    "\tnp.fill_diagonal(backbone_rev_mat[:, 1:], 1)\n",
    "\treturn backbone_mat, backbone_rev_mat\n",
    "\n",
    "def sparse2pairs(sparsemat):\n",
    "\tsparsemat = sparse.find(sparsemat)\n",
    "\treturn np.vstack([sparsemat[0],sparsemat[1]])\n",
    "\n",
    "def decoder_reconstruction2aa( ords , device, verbose = False):\n",
    "\tdecoder.eval()\n",
    "\tprint(ords)\n",
    "\tz = encoder.vector_quantizer.embeddings( ords  ).to('cpu')\n",
    "\t\n",
    "\tedge_index = torch.tensor( [ [i,j] for i in range(z.shape[0]) for j in range(z.shape[0]) ]  , dtype = torch.long).T\n",
    "\tgodnode_index = np.vstack([np.zeros(z.shape[0]), [ i for i in range(z.shape[0]) ] ])\n",
    "\tgodnode_rev = np.vstack([ [ i for i in range(z.shape[0]) ] , np.zeros(z.shape[0]) ])\n",
    "\t#generate a backbone for the decoder\n",
    "\tdata = HeteroData()\n",
    "\t\n",
    "\tdata['res'].x = z\n",
    "\tbackbone, backbone_rev = get_backbone( z.shape[0] )\n",
    "\tbackbone = sparse.csr_matrix(backbone)\n",
    "\tbackbone_rev = sparse.csr_matrix(backbone_rev)\n",
    "\tbackbone = sparse2pairs(backbone)\n",
    "\tbackbone_rev = sparse2pairs(backbone_rev)\n",
    "\tpositional_encoding = converter.get_positional_encoding( z.shape[0] , 256 )\n",
    "\tprint( 'positional encoding shape:', positional_encoding.shape )\n",
    "\tdata['res'].batch = torch.tensor([0 for i in range(z.shape[0])], dtype=torch.long)\n",
    "\tdata['positions'].x = torch.tensor( positional_encoding, dtype=torch.float32)\n",
    "\tdata['res','backbone','res'].edge_index = torch.tensor(backbone,  dtype=torch.long )\n",
    "\tdata[ 'res' , 'backbone_rev' , 'res'].edge_index = torch.tensor(backbone_rev, dtype=torch.long)\n",
    "\tprint( data['res'].x.shape )\n",
    "\t#add the godnode\n",
    "\tdata['godnode'].x = torch.tensor(np.ones((1,5)), dtype=torch.float32)\n",
    "\tdata['godnode4decoder'].x = torch.tensor(np.ones((1,5)), dtype=torch.float32)\n",
    "\tdata['godnode4decoder', 'informs', 'res'].edge_index = torch.tensor(godnode_index, dtype=torch.long)\n",
    "\tdata['res', 'informs', 'godnode4decoder'].edge_index = torch.tensor(godnode_rev, dtype=torch.long)\n",
    "\tdata['res', 'informs', 'godnode'].edge_index = torch.tensor(godnode_rev, dtype=torch.long)\n",
    "\tedge_index = edge_index.to( device )\n",
    "\tprint( data )\n",
    "\tdata = data.to( device )\n",
    "\tallpairs = torch.tensor( [ [i,j] for i in range(z.shape[0]) for j in range(z.shape[0]) ]  , dtype = torch.long).T\n",
    "\tout = decoder( data , allpairs )\n",
    "\trecon_x = out['aa'] if 'aa' in out else None\n",
    "\tedge_probs = out['edge_probs'] if 'edge_probs' in out else None\n",
    "\n",
    "\tprint( edge_probs.shape)\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\tamino_map = decoder.decoders['sequence'].amino_acid_indices\n",
    "\texcept:\n",
    "\t\tamino_map = decoder.decoders['sequence_transformer'].amino_acid_indices\n",
    "\t\tprint('Using amino_acid_indices_dict instead of amino_acid_indices')\n",
    "\trevmap_aa = { v:k for k,v in amino_map.items() }\n",
    "\taastr = ''.join(revmap_aa[int(idx.item())] for idx in recon_x.argmax(dim=1) )\n",
    "\t\n",
    "\t\"\"\"\n",
    "\taastr = None\n",
    "\n",
    "\tedge_probs = edge_probs.reshape((z.shape[0], z.shape[0]))\n",
    "\tif verbose == True:\n",
    "\t\tprint( recon_x )\n",
    "\t\tprint( edge_probs )\n",
    "\treturn aastr ,edge_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Epoch 0:   6%| | 7/125 [00:10<02:33"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(struct_dat, batch_size=40, shuffle=True, num_workers=4)\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "from foldtree2.src.losses.losses import recon_loss_diag , aa_reconstruction_loss\n",
    "for epoch in range(num_epochs):\n",
    "\ttotal_loss_x = 0\n",
    "\ttotal_loss_edge = 0\n",
    "\ttotal_vq = 0\n",
    "\ttotal_loss_fft2 = 0\n",
    "\tfor data in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "\t\tdata = data.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tz, vqloss = encoder(data)\n",
    "\t\tdata['res'].x = z\n",
    "\t\t# For demonstration, only sequence and contacts tasks\n",
    "\t\tout = decoder(data, None)\n",
    "\t\trecon_x = out['aa'] if isinstance(out, dict) and 'aa' in out else out[0] if isinstance(out, (list, tuple)) else None\n",
    "\t\tfft2_x = out['fft2pred'] if isinstance(out, dict) and 'fft2pred' in out else out[1] if isinstance(out, (list, tuple)) else None\n",
    "\t\t# Edge loss: use contactPoints if available\n",
    "\t\tedge_index = data.edge_index_dict['res', 'contactPoints', 'res'] if hasattr(data, 'edge_index_dict') and ('res', 'contactPoints', 'res') in data.edge_index_dict else None\n",
    "\t\tif edge_index is not None:\n",
    "\t\t\tedgeloss, _ = recon_loss_diag(data, edge_index, decoder, plddt=False, offdiag=False , key = 'edge_probs')\n",
    "\t\telse:\n",
    "\t\t\tedgeloss = torch.tensor(0.0, device=device)\n",
    "\t\txloss = aa_reconstruction_loss(data['AA'].x, recon_x)\n",
    "\t\tif fft2_x is not None:\n",
    "\t\t\tfft2loss = F.smooth_l1_loss(torch.cat( [ data['fourier2dr'].x ,data['fourier2di'].x ] ,axis = 1 ) , fft2_x )\n",
    "\t\telse:\n",
    "\t\t\tfft2loss = torch.tensor(0.0, device=device)\n",
    "\t\tloss = xweight * xloss + edgeweight * edgeloss + vqweight * vqloss + fft2loss* fft2weight\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\tif clip_grad:\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1.0)\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss_x += xloss.item()\n",
    "\t\ttotal_loss_edge += edgeloss.item()\n",
    "\t\ttotal_loss_fft2 += fft2loss.item()\n",
    "\t\ttotal_vq += vqloss.item() if isinstance(vqloss, torch.Tensor) else float(vqloss)\n",
    "\tscheduler.step(total_loss_x)\n",
    "\tprint(f\"Epoch {epoch}: AA Loss: {total_loss_x/len(train_loader):.4f}, Edge Loss: {total_loss_edge/len(train_loader):.4f}, VQ Loss: {total_vq/len(train_loader):.4f} , FFT2 Loss: {total_loss_fft2/len(train_loader):.4f}\")\n",
    "\n",
    "\tencoder.eval()\n",
    "\tdecoder.eval()\n",
    "\t\n",
    "\t# predict all vs all contacts for the last sample\n",
    "\tdata_sample = data_sample.to(device)\n",
    "\tz, vqloss = encoder(data_sample)\n",
    "\tprint('Encoded z shape:', z.shape)\n",
    "\tords = encoder.vector_quantizer.discretize_z(z.detach())\n",
    "\tzdiscrete = ords[0].detach()\n",
    "\tprint('Encoded zdiscrete shape:', zdiscrete.shape)\n",
    "\t\n",
    "\taastr, edge_probs = decoder_reconstruction2aa( zdiscrete , device, verbose=True)\n",
    "\t#show the distance matrix\n",
    "\tgrab_struct(str(data_sample.identifier) , structfolder='tmp/')\n",
    "\t#find the total number of residues\n",
    "\tca_atoms = getCAatoms( 'tmp/' + str(data_sample.identifier) + '.pdb')\n",
    "\tdist_mat = np.zeros((len(ca_atoms), len(ca_atoms)))\n",
    "\t\n",
    "\tfor i, res1 in enumerate(ca_atoms):\n",
    "\t\tfor j, res2 in enumerate(ca_atoms):\n",
    "\t\t\tif i < j:\n",
    "\t\t\t\tdist_mat[i, j] = np.linalg.norm(res1.coord - res2.coord)\n",
    "\tdist_mat += dist_mat.T  # Make it symmetric\n",
    "\tnp.fill_diagonal(dist_mat, 0)\n",
    "\t\n",
    "\tndistmat = dist_mat.copy()\n",
    "\tndistmat[dist_mat>10 ] = 0\n",
    "\tndistmat[dist_mat<=10 ] = 1\n",
    "\n",
    "\tfig, axs = plt.subplots(3, 3, figsize=(20, 10))\n",
    "\n",
    "\t# Predicted Contacts\n",
    "\tim0 = axs[0, 0].imshow(np.log(edge_probs.detach().cpu().numpy()), cmap='hot', interpolation='nearest')\n",
    "\taxs[0, 0].set_title(f\"Epoch {epoch} - Predicted Contacts for {data.identifier[0]}\")\n",
    "\tfig.colorbar(im0, ax=axs[0, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "\t# Distance Matrix\n",
    "\tim1 = axs[0, 1].imshow(dist_mat, cmap='hot', interpolation='nearest')\n",
    "\taxs[0, 1].set_title(f\"Epoch {epoch} - Distance Matrix for {data.identifier[0]}\")\n",
    "\tfig.colorbar(im1, ax=axs[0, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "\t# Distance Diff\n",
    "\tim2 = axs[0, 2].imshow( ndistmat , cmap='hot', interpolation='nearest')\n",
    "\taxs[0, 2].set_title(f\"Epoch {epoch} - Distance Diff (Predicted vs True) for {data.identifier[0]}\")\n",
    "\tfig.colorbar(im2, ax=axs[0, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "\t# exclude diagonal from the distance matrix in the ROC and Precision-Recall curves\n",
    "\tnpdistmat = ndistmat.copy()\n",
    "\tedge_probs = edge_probs.detach().cpu().numpy()\n",
    "\tedge_probs = edge_probs.reshape((z.shape[0], z.shape[0]))\n",
    "\t#flatten both matrices for ROC and Precision-Recall curves\n",
    "\tndistmat_flat = npdistmat.flatten()\n",
    "\tedge_probs_flat = edge_probs.flatten()\n",
    "\t# Remove NaN values from both arrays\n",
    "\t\n",
    "\t# ROC Curve\n",
    "\tfpr, tpr, _ = roc_curve(ndistmat_flat, edge_probs_flat)\n",
    "\troc_auc = auc(fpr, tpr)\n",
    "\taxs[1, 0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "\taxs[1, 0].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "\taxs[1, 0].set_xlim([0.0, 1.0])\n",
    "\taxs[1, 0].set_ylim([0.0, 1.05])\n",
    "\taxs[1, 0].set_xlabel('False Positive Rate')\n",
    "\taxs[1, 0].set_ylabel('True Positive Rate')\n",
    "\taxs[1, 0].set_title('Receiver Operating Characteristic')\n",
    "\taxs[1, 0].legend(loc='lower right')\n",
    "\n",
    "\t# Precision-Recall Curve\n",
    "\ty_true = ndistmat_flat\n",
    "\ty_scores = edge_probs_flat\n",
    "\tprecision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "\tap_score = average_precision_score(y_true, y_scores)\n",
    "\taxs[1, 1].plot(recall, precision, color='green', lw=2, label=f'AP = {ap_score:.2f}')\n",
    "\taxs[1, 1].set_xlabel('Recall')\n",
    "\taxs[1, 1].set_ylabel('Precision')\n",
    "\taxs[1, 1].set_title('Precision-Recall Curve')\n",
    "\taxs[1, 1].legend(loc='lower left')\n",
    "\n",
    "\tdist_mat_flat = dist_mat.flatten()  # Ensure we use the same valid mask for distance matrix\n",
    "\tdist_mat_flat = dist_mat_flat/dist_mat_flat.max()  # Normalize the distance matrix for better visualization\n",
    "\t# Correlation\n",
    "\tcorr = np.corrcoef( y_scores, dist_mat_flat)[0, 1]\n",
    "\taxs[1, 2].scatter( y_scores, dist_mat_flat, alpha=0.05)\n",
    "\taxs[1, 2].set_xlabel('Predicted Contacts')\n",
    "\taxs[1, 2].set_ylabel('True Distance Matrix')\n",
    "\taxs[1, 2].set_title(f'Correlation: {corr:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "\t# ROC Curve\n",
    "\t# Mask out entries not separated by at least 10 residues\n",
    "\tmask = np.fromfunction(lambda i, j: np.abs(i - j) >= 10, dist_mat.shape)\n",
    "\tmasked_ndistmat = np.where(mask, ndistmat, np.nan)\n",
    "\tmasked_edge_probs = np.where(mask, edge_probs, np.nan)\n",
    "\n",
    "\t# Flatten and filter out nan values\n",
    "\tndistmat_flat_masked = masked_ndistmat.flatten()\n",
    "\tedge_probs_flat_masked = masked_edge_probs.flatten()\n",
    "\tvalid_mask = ~np.isnan(ndistmat_flat_masked) & ~np.isnan(edge_probs_flat_masked)\n",
    "\tndistmat_flat_masked = ndistmat_flat_masked[valid_mask]\n",
    "\tedge_probs_flat_masked = edge_probs_flat_masked[valid_mask]\n",
    "\n",
    "\t# ROC Curve\n",
    "\tfpr, tpr, _ = roc_curve(ndistmat_flat_masked, edge_probs_flat_masked)\n",
    "\troc_auc = auc(fpr, tpr)\n",
    "\taxs[2, 0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "\taxs[2, 0].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "\taxs[2, 0].set_xlim([0.0, 1.0])\n",
    "\taxs[2, 0].set_ylim([0.0, 1.05])\n",
    "\taxs[2, 0].set_xlabel('False Positive Rate')\n",
    "\taxs[2, 0].set_ylabel('True Positive Rate')\n",
    "\taxs[2, 0].set_title('Receiver Operating Characteristic')\n",
    "\taxs[2, 0].legend(loc='lower right')\n",
    "\n",
    "\t# Precision-Recall Curve\n",
    "\ty_true = ndistmat_flat_masked\n",
    "\ty_scores = edge_probs_flat_masked\n",
    "\tprecision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "\tap_score = average_precision_score(y_true, y_scores)\n",
    "\taxs[2, 1].plot(recall, precision, color='green', lw=2, label=f'AP = {ap_score:.2f}')\n",
    "\taxs[2, 1].set_xlabel('Recall')\n",
    "\taxs[2, 1].set_ylabel('Precision')\n",
    "\taxs[2, 1].set_title('Precision-Recall Curve')\n",
    "\taxs[2, 1].legend(loc='lower left')\n",
    "\n",
    "\tdist_mat_flat = dist_mat.flatten()  # Ensure we use the same valid mask for distance matrix\n",
    "\tdist_mat_flat = dist_mat_flat/dist_mat_flat.max()  # Normalize the distance matrix for better visualization\n",
    "\t# Correlation\n",
    "\tcorr = np.corrcoef( y_scores, dist_mat_flat)[0, 1]\n",
    "\taxs[2, 2].scatter( y_scores, dist_mat_flat, alpha=0.05)\n",
    "\taxs[2, 2].set_xlabel('Predicted Contacts')\n",
    "\taxs[2, 2].set_ylabel('True Distance Matrix')\n",
    "\taxs[2, 2].set_title(f'Correlation: {corr:.2f}')\n",
    "\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "\tencoder.train()\n",
    "\tdecoder.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "import pickle\n",
    "modeldir = 'models'\n",
    "modelname = 'monodecoder_foldtree2_test'\n",
    "with open(os.path.join(modeldir, modelname + '.pkl'), 'wb') as f:\n",
    "    pickle.dump((encoder, decoder), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a913d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencoded_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#grab the pdbs and get the total number of residues\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#ensure encoder produces fastas with the same residues as the pdbs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pdbs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(encoded_df.head())\n",
    "#grab the pdbs and get the total number of residues\n",
    "#ensure encoder produces fastas with the same residues as the pdbs\n",
    "pdbs = []\n",
    "for identifier in encoded_df.index:\n",
    "\tpdbs.append( str(identifier) + '.pdb' )\n",
    "encoded_df['pdb'] = pdbs\n",
    "for i in range(len(encoded_df)):\n",
    "\tidentifier = encoded_df.index[i]\n",
    "\tpdb_file = 'tmp/' + identifier + '.pdb'\n",
    "\tif not os.path.exists(pdb_file):\n",
    "\t\tgrab_struct(str(identifier), structfolder='tmp/')\n",
    "\tca_atoms = getCAatoms(pdb_file)\n",
    "\ttotal_residues = sum(len(atoms) for atoms in ca_atoms.values())\n",
    "\tencoded_df.at[identifier, 'total_residues'] = total_residues\n",
    "encoded_df['delta'] = encoded_df['length_ord'] - encoded_df['total_residues']\n",
    "assert (encoded_df['delta'] == 0).all(), \"Mismatch between sequence length and total residues in PDB files\"\n",
    "assert (encoded_df['length_ord'] == encoded_df['length_hex']).all(), \"Mismatch between ord and hex lengths\"\n",
    "assert (encoded_df['length_ord'] == encoded_df['length_seq']).all(), \"Mismatch between ord and sequence lengths\"\n",
    "assert (encoded_df['length_hex'] == encoded_df['length_seq']).all(), \"Mismatch between hex and sequence lengths\"\n",
    "print(\"All checks passed. Sequence lengths match PDB total residues and ord/hex lengths.\")\n",
    "print(\"Encoded sequences DataFrame:\")\n",
    "encoded_df.to_csv('encoded_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c03f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b81368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
