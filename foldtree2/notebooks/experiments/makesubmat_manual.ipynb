{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a974e708",
   "metadata": {},
   "source": [
    "# Structure-Based Substitution Matrix Generation\n",
    "\n",
    "This notebook implements the makesubmat.py logic with real-time visualizations to monitor matrix convergence during compilation.\n",
    "\n",
    "## Workflow Overview\n",
    "1. Load trained FoldTree2 encoder model\n",
    "2. Encode protein structures into discrete structural tokens\n",
    "3. Process structural alignments iteratively\n",
    "4. Visualize matrix changes and convergence metrics\n",
    "5. Generate final MAFFT and RAxML compatible matrices\n",
    "\n",
    "## Convergence Monitoring\n",
    "We track:\n",
    "- **Matrix Frobenius Norm**: Overall magnitude of changes\n",
    "- **Gradient Norm**: Rate of change between iterations\n",
    "- **Element-wise Variance**: Stability of individual substitution scores\n",
    "- **Heatmap Evolution**: Visual progression of the matrix structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae83fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FoldTree2 imports\n",
    "from foldtree2.src import AFDB_tools, foldseek2tree\n",
    "from foldtree2.src.pdbgraph import PDB2PyG, StructureDataset\n",
    "import foldtree2.src.encoder as ft2\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45537d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: notebook_1k_training_nopositions/monodecoder_model_best_encoder\n",
      "  Model dir: ./models/\n",
      "  Data dir: ../../../../datasets/\n",
      "  Dataset: structalignmk4.h5\n",
      "  Identity threshold: 0.3\n",
      "  Visualization update interval: 5 files\n"
     ]
    }
   ],
   "source": [
    "# Configuration Parameters\n",
    "modelname = 'notebook_1k_training_nopositions/monodecoder_model_best_encoder'  # Model name without .pt extension\n",
    "modeldir = './models/'\n",
    "datadir = '../../../../datasets/'\n",
    "dataset_path = 'structalignmk4.h5'\n",
    "fident_thresh = 0.3  # Sequence identity threshold for alignments\n",
    "output_dir = './models/'\n",
    "\n",
    "# Visualization parameters\n",
    "update_interval = 5  # Update plots every N alignment files\n",
    "figsize = (18, 12)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Model: {modelname}\")\n",
    "print(f\"  Model dir: {modeldir}\")\n",
    "print(f\"  Data dir: {datadir}\")\n",
    "print(f\"  Dataset: {dataset_path}\")\n",
    "print(f\"  Identity threshold: {fident_thresh}\")\n",
    "print(f\"  Visualization update interval: {update_interval} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d4ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab58dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./models/notebook_1k_training_nopositions/monodecoder_model_best_encoder.pt\n",
      "Using device: cuda\n",
      "Number of embeddings: 40\n",
      "Embedding dimension: 128\n",
      "\n",
      "Encoder architecture:\n",
      "mk1_Encoder(\n",
      "  (position_mlp): Position_MLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.01, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): Dropout(p=0.01, inplace=False)\n",
      "      (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (input): ModuleDict(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (ln): LayerNorm((857,), eps=1e-05, elementwise_affine=True)\n",
      "    (inmlp): Sequential(\n",
      "      (0): Dropout(p=0.01, inplace=False)\n",
      "      (1): LayerNorm((889,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): Linear(in_features=889, out_features=400, bias=True)\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (5): GELU(approximate='none')\n",
      "    )\n",
      "    (ffin): Sequential(\n",
      "      (0): Dropout(p=0.01, inplace=False)\n",
      "      (1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): Linear(in_features=160, out_features=400, bias=True)\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (5): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (body): ModuleDict(\n",
      "    (convs): ModuleList(\n",
      "      (0-1): 2 x ModuleDict(\n",
      "        (res_contactPoints_res): TransformerConv(200, 200, heads=16)\n",
      "      )\n",
      "    )\n",
      "    (norms): ModuleList(\n",
      "      (0-1): 2 x GraphNorm(200)\n",
      "    )\n",
      "    (jk): JumpingKnowledge(cat)\n",
      "  )\n",
      "  (head): ModuleDict(\n",
      "    (lin): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (3): GELU(approximate='none')\n",
      "    )\n",
      "    (out_dense): Sequential(\n",
      "      (0): Linear(in_features=220, out_features=200, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (3): GELU(approximate='none')\n",
      "      (4): Linear(in_features=200, out_features=128, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (vector_quantizer): VectorQuantizerEMA(\n",
      "    (embeddings): Embedding(40, 128)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load trained encoder model\n",
    "model_path = os.path.join(modeldir, modelname + '.pt')\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "encoder = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = encoder.to(device)\n",
    "encoder.device = device\n",
    "encoder.eval()\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of embeddings: {encoder.num_embeddings}\")\n",
    "print(f\"Embedding dimension: {encoder.out_channels if hasattr(encoder, 'out_channels') else 'N/A'}\")\n",
    "print(\"\\nEncoder architecture:\")\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e068bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def encode_structures(encoder, device, dataset_path):\n",
    "    \"\"\"Encode protein structures using trained model.\"\"\"\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"Loading dataset from {dataset_path}\")\n",
    "        struct_dat = StructureDataset(dataset_path)\n",
    "    else:\n",
    "        print(f\"Dataset {dataset_path} not found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded {len(struct_dat)} structures\")\n",
    "    encoder_loader = DataLoader(struct_dat, batch_size=1, shuffle=False)\n",
    "    \n",
    "    def databatch2list(loader):\n",
    "        for data in loader:\n",
    "            data = data.to_data_list()\n",
    "            for d in data:\n",
    "                d = d.to(device)\n",
    "                yield d\n",
    "    \n",
    "    encoder_loader = databatch2list(encoder_loader)\n",
    "    \n",
    "    # Encode structures\n",
    "    output_path = os.path.join(output_dir, modelname + '_aln_encoded.fasta')\n",
    "    encoder.encode_structures_fasta(encoder_loader, output_path, replace=True)\n",
    "    print(f\"Encoded structures saved to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def build_char_set(encoded_df):\n",
    "    \"\"\"Build character set and position mappings.\"\"\"\n",
    "    char_set = set()\n",
    "    for seq in encoded_df.seq:\n",
    "        char_set = char_set.union(set(seq))\n",
    "    char_set = list(char_set)\n",
    "    char_set.sort()\n",
    "    \n",
    "    print(f\"Character set size: {len(char_set)}\")\n",
    "    print(f\"Characters (ord): {[ord(c) for c in char_set[:10]]}... ({len(char_set)} total)\")\n",
    "    \n",
    "    char_position_map = {char: i for i, char in enumerate(char_set)}\n",
    "    \n",
    "    # Create RAxML compatible character set\n",
    "    raxml_chars = \"\"\"0 1 2 3 4 5 6 7 8 9 A B C D E F G H I J K L M N O P Q R S T U V W X Y Z ! \" # $ % & ' ( ) * + , / : ; < = > @ [ \\ ] ^ _ { | } ~\"\"\".split()\n",
    "    raxml_charset = [raxml_chars[char_position_map[c]] for c in char_set]\n",
    "    raxml_char_position_map = {c: i for i, c in enumerate(raxml_charset)}\n",
    "    \n",
    "    assert len(raxml_charset) == len(char_set), \"Character set length mismatch\"\n",
    "    \n",
    "    return char_set, char_position_map, raxml_charset, raxml_char_position_map\n",
    "\n",
    "def compute_log_odds_from_counts(pair_counts, char_freqs, pseudocount=1e-20, log_base=np.e):\n",
    "    \"\"\"Compute log-odds substitution scores from pair counts.\"\"\"\n",
    "    n = pair_counts.shape[0]\n",
    "    total_pairs = np.sum(pair_counts)\n",
    "    obs_freq = (pair_counts + pseudocount) / (total_pairs + pseudocount * (n**2))\n",
    "    char_freqs = char_freqs / np.sum(char_freqs)\n",
    "    exp_freq = np.outer(char_freqs, char_freqs) + pseudocount\n",
    "    ratio = obs_freq / exp_freq\n",
    "    epsilon = 1e-15\n",
    "    log_odds_matrix = np.log(ratio + epsilon) / np.log(log_base)\n",
    "    return log_odds_matrix\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d61062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Visualization Functions\n",
    "\n",
    "class MatrixConvergenceMonitor:\n",
    "    \"\"\"Track and visualize matrix convergence during compilation.\"\"\"\n",
    "    \n",
    "    def __init__(self, matrix_size):\n",
    "        self.matrix_size = matrix_size\n",
    "        self.history = {\n",
    "            'iteration': [],\n",
    "            'frobenius_norm': [],\n",
    "            'gradient_norm': [],\n",
    "            'max_change': [],\n",
    "            'mean_change': [],\n",
    "            'nonzero_elements': [],\n",
    "            'snapshots': []\n",
    "        }\n",
    "        self.prev_matrix = None\n",
    "        \n",
    "    def update(self, iteration, current_matrix):\n",
    "        \"\"\"Update convergence metrics with new matrix state.\"\"\"\n",
    "        # Frobenius norm\n",
    "        frob_norm = np.linalg.norm(current_matrix, 'fro')\n",
    "        \n",
    "        # Gradient (change from previous iteration)\n",
    "        if self.prev_matrix is not None:\n",
    "            gradient = current_matrix - self.prev_matrix\n",
    "            grad_norm = np.linalg.norm(gradient, 'fro')\n",
    "            max_change = np.max(np.abs(gradient))\n",
    "            mean_change = np.mean(np.abs(gradient))\n",
    "        else:\n",
    "            grad_norm = 0\n",
    "            max_change = 0\n",
    "            mean_change = 0\n",
    "        \n",
    "        # Non-zero elements\n",
    "        nonzero = np.count_nonzero(current_matrix)\n",
    "        \n",
    "        # Store metrics\n",
    "        self.history['iteration'].append(iteration)\n",
    "        self.history['frobenius_norm'].append(frob_norm)\n",
    "        self.history['gradient_norm'].append(grad_norm)\n",
    "        self.history['max_change'].append(max_change)\n",
    "        self.history['mean_change'].append(mean_change)\n",
    "        self.history['nonzero_elements'].append(nonzero)\n",
    "        self.history['snapshots'].append(current_matrix.copy())\n",
    "        \n",
    "        self.prev_matrix = current_matrix.copy()\n",
    "    \n",
    "    def plot_convergence(self, figsize=(18, 12)):\n",
    "        \"\"\"Generate comprehensive convergence visualization.\"\"\"\n",
    "        fig, axes = plt.subplots(3, 3, figsize=figsize)\n",
    "        \n",
    "        iterations = self.history['iteration']\n",
    "        \n",
    "        # Row 1: Convergence metrics\n",
    "        axes[0, 0].plot(iterations, self.history['frobenius_norm'], 'b-', linewidth=2)\n",
    "        axes[0, 0].set_xlabel('Iteration (Alignment Files)')\n",
    "        axes[0, 0].set_ylabel('Frobenius Norm')\n",
    "        axes[0, 0].set_title('Matrix Magnitude Over Time')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[0, 1].plot(iterations, self.history['gradient_norm'], 'r-', linewidth=2)\n",
    "        axes[0, 1].set_xlabel('Iteration (Alignment Files)')\n",
    "        axes[0, 1].set_ylabel('Gradient Norm')\n",
    "        axes[0, 1].set_title('Rate of Change (Matrix Gradient)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].set_yscale('log')\n",
    "        \n",
    "        axes[0, 2].plot(iterations, self.history['max_change'], 'g-', label='Max', linewidth=2)\n",
    "        axes[0, 2].plot(iterations, self.history['mean_change'], 'orange', label='Mean', linewidth=2)\n",
    "        axes[0, 2].set_xlabel('Iteration (Alignment Files)')\n",
    "        axes[0, 2].set_ylabel('Change Magnitude')\n",
    "        axes[0, 2].set_title('Element-wise Changes')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        axes[0, 2].set_yscale('log')\n",
    "        \n",
    "        # Row 2: Matrix snapshots (early, middle, recent)\n",
    "        if len(self.history['snapshots']) > 0:\n",
    "            # First snapshot\n",
    "            im0 = axes[1, 0].imshow(self.history['snapshots'][0], cmap='RdBu_r', \n",
    "                                   aspect='auto', interpolation='nearest')\n",
    "            axes[1, 0].set_title(f'Iteration {iterations[0]} (First)')\n",
    "            plt.colorbar(im0, ax=axes[1, 0], fraction=0.046)\n",
    "            \n",
    "            # Middle snapshot\n",
    "            mid_idx = len(self.history['snapshots']) // 2\n",
    "            im1 = axes[1, 1].imshow(self.history['snapshots'][mid_idx], cmap='RdBu_r',\n",
    "                                   aspect='auto', interpolation='nearest')\n",
    "            axes[1, 1].set_title(f'Iteration {iterations[mid_idx]} (Middle)')\n",
    "            plt.colorbar(im1, ax=axes[1, 1], fraction=0.046)\n",
    "            \n",
    "            # Latest snapshot\n",
    "            im2 = axes[1, 2].imshow(self.history['snapshots'][-1], cmap='RdBu_r',\n",
    "                                   aspect='auto', interpolation='nearest')\n",
    "            axes[1, 2].set_title(f'Iteration {iterations[-1]} (Current)')\n",
    "            plt.colorbar(im2, ax=axes[1, 2], fraction=0.046)\n",
    "        \n",
    "        # Row 3: Additional metrics\n",
    "        axes[2, 0].plot(iterations, self.history['nonzero_elements'], 'purple', linewidth=2)\n",
    "        axes[2, 0].set_xlabel('Iteration (Alignment Files)')\n",
    "        axes[2, 0].set_ylabel('Count')\n",
    "        axes[2, 0].set_title('Non-zero Matrix Elements')\n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Convergence rate (derivative of gradient norm)\n",
    "        if len(iterations) > 2:\n",
    "            grad_norms = np.array(self.history['gradient_norm'])\n",
    "            convergence_rate = np.diff(grad_norms)\n",
    "            axes[2, 1].plot(iterations[1:], convergence_rate, 'cyan', linewidth=2)\n",
    "            axes[2, 1].set_xlabel('Iteration (Alignment Files)')\n",
    "            axes[2, 1].set_ylabel('Δ(Gradient Norm)')\n",
    "            axes[2, 1].set_title('Convergence Acceleration')\n",
    "            axes[2, 1].grid(True, alpha=0.3)\n",
    "            axes[2, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Summary statistics\n",
    "        if len(iterations) > 0:\n",
    "            stats_text = f\"\"\"Matrix Convergence Summary\n",
    "            \n",
    "Final Iteration: {iterations[-1]}\n",
    "Final Frobenius Norm: {self.history['frobenius_norm'][-1]:.4f}\n",
    "Final Gradient Norm: {self.history['gradient_norm'][-1]:.6f}\n",
    "Mean Gradient Norm: {np.mean(self.history['gradient_norm'][1:]):.6f}\n",
    "Non-zero Elements: {self.history['nonzero_elements'][-1]} / {self.matrix_size**2}\n",
    "Sparsity: {100*(1 - self.history['nonzero_elements'][-1]/(self.matrix_size**2)):.2f}%\n",
    "\n",
    "Convergence Status:\n",
    "{'✓ CONVERGED' if self.history['gradient_norm'][-1] < 0.01 else '⚠ STILL CHANGING'}\n",
    "            \"\"\"\n",
    "            axes[2, 2].text(0.1, 0.5, stats_text, fontsize=10, \n",
    "                           verticalalignment='center', family='monospace')\n",
    "            axes[2, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def get_convergence_summary(self):\n",
    "        \"\"\"Return summary statistics about convergence.\"\"\"\n",
    "        if len(self.history['iteration']) == 0:\n",
    "            return \"No data collected yet.\"\n",
    "        \n",
    "        return {\n",
    "            'total_iterations': len(self.history['iteration']),\n",
    "            'final_frobenius_norm': self.history['frobenius_norm'][-1],\n",
    "            'final_gradient_norm': self.history['gradient_norm'][-1],\n",
    "            'mean_gradient_norm': np.mean(self.history['gradient_norm'][1:]),\n",
    "            'max_gradient_norm': np.max(self.history['gradient_norm']),\n",
    "            'is_converged': self.history['gradient_norm'][-1] < 0.01,\n",
    "            'sparsity': 1 - self.history['nonzero_elements'][-1] / (self.matrix_size**2)\n",
    "        }\n",
    "\n",
    "print(\"Visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb83bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print( encoder.out_channels )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1351ceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing encoded FASTA...\n",
      "Encoding structures (this may take a while)...\n",
      "Loading dataset from structalignmk4.h5\n",
      "Loaded 12530 structures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding structures to FASTA: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding structures to FASTA: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NodeStorage' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding structures (this may take a while)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     encoded_fasta_path \u001b[38;5;241m=\u001b[39m \u001b[43mencode_structures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load encoded sequences\u001b[39;00m\n\u001b[1;32m     13\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m ft2\u001b[38;5;241m.\u001b[39mload_encoded_fasta(encoded_fasta_path, alphabet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mencode_structures\u001b[0;34m(encoder, device, dataset_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Encode structures\u001b[39;00m\n\u001b[1;32m     25\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, modelname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_aln_encoded.fasta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_structures_fasta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoded structures saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n",
      "File \u001b[0;32m~/projects/foldtree2/foldtree2/src/encoder.py:289\u001b[0m, in \u001b[0;36mmk1_Encoder.encode_structures_fasta\u001b[0;34m(self, dataloader, filename, verbose, alphabet, replace, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres shape\u001b[39m\u001b[38;5;124m'\u001b[39m, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    288\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 289\u001b[0m z, qloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m strdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_quantizer\u001b[38;5;241m.\u001b[39mdiscretize_z(z)\n\u001b[1;32m    291\u001b[0m identifier \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39midentifier\n",
      "File \u001b[0;32m~/projects/foldtree2/foldtree2/src/encoder.py:222\u001b[0m, in \u001b[0;36mmk1_Encoder.forward\u001b[0;34m(self, data, edge_attr_dict, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Add fourier features if present\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfftin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffin\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput:\n\u001b[0;32m--> 222\u001b[0m \tx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffin\u001b[39m\u001b[38;5;124m'\u001b[39m](torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfourier1dr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfourier1di\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# ===================== BODY PROCESSING =====================\u001b[39;00m\n\u001b[1;32m    225\u001b[0m x_save \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/foldtree2/lib/python3.9/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NodeStorage' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "# Load or encode structures\n",
    "encoded_fasta_path = os.path.join(output_dir, modelname + '_aln_encoded.fasta')\n",
    "overwrite_encoding = True  # Set to True to re-encode structures\n",
    "if overwrite_encoding:\n",
    "\tprint(\"Overwriting existing encoded FASTA...\")\n",
    "if os.path.exists(encoded_fasta_path) and not overwrite_encoding:\n",
    "    print(f\"Using existing encoded FASTA: {encoded_fasta_path}\")\n",
    "else:\n",
    "    print(\"Encoding structures (this may take a while)...\")\n",
    "    encoded_fasta_path = encode_structures(encoder, device, dataset_path)\n",
    "\n",
    "# Load encoded sequences\n",
    "encoded_df = ft2.load_encoded_fasta(encoded_fasta_path, alphabet=None, replace=False)\n",
    "print(f\"\\nLoaded {len(encoded_df)} encoded sequences\")\n",
    "print(f\"Sample sequence length: {len(encoded_df.iloc[0].seq)}\")\n",
    "print(f\"First sequence ID: {encoded_df.index[0]}\")\n",
    "\n",
    "# Build character set\n",
    "char_set, char_position_map, raxml_charset, raxml_char_position_map = build_char_set(encoded_df)\n",
    "matrix_size = len(char_set)\n",
    "print(f\"\\nMatrix size: {matrix_size} x {matrix_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find alignment files\n",
    "alnfiles = glob.glob(os.path.join(datadir, 'struct_align/*/allvall.csv'))\n",
    "print(f\"Found {len(alnfiles)} alignment files\")\n",
    "\n",
    "if len(alnfiles) == 0:\n",
    "    print(\"ERROR: No alignment files found!\")\n",
    "    print(f\"Expected location: {os.path.join(datadir, 'struct_align/*/allvall.csv')}\")\n",
    "else:\n",
    "    print(f\"\\nSample alignment files:\")\n",
    "    for f in alnfiles[:5]:\n",
    "        print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce17d52",
   "metadata": {},
   "source": [
    "## Process Alignments with Real-Time Convergence Monitoring\n",
    "\n",
    "The next cell processes structural alignments iteratively, updating the substitution matrix and visualizing convergence metrics in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process alignments iteratively with convergence monitoring\n",
    "cols = 'query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,qaln,taln'.split(',')\n",
    "\n",
    "# Initialize matrices and convergence monitor\n",
    "pair_counts = np.zeros((matrix_size, matrix_size))\n",
    "background_freq = np.zeros(matrix_size)\n",
    "seqcount = 0\n",
    "monitor = MatrixConvergenceMonitor(matrix_size)\n",
    "\n",
    "# Track processed sequences to avoid double-counting\n",
    "all_processed_seqs = set()\n",
    "\n",
    "print(f\"Processing {len(alnfiles)} alignment files...\")\n",
    "print(f\"Visualization updates every {update_interval} files\\n\")\n",
    "\n",
    "for file_idx, aln_file in enumerate(tqdm.tqdm(alnfiles, desc=\"Processing alignments\")):\n",
    "    # Read alignment file\n",
    "    try:\n",
    "        aln_df = pd.read_table(aln_file)\n",
    "        aln_df.columns = cols\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {aln_file}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Track sequences in this file\n",
    "    file_seqset = set()\n",
    "    \n",
    "    # Process pairwise alignments\n",
    "    for q in aln_df['query'].unique():\n",
    "        for t in aln_df['target'].unique():\n",
    "            if q != t:\n",
    "                aln = aln_df[(aln_df['query'] == q) & (aln_df['target'] == t)]\n",
    "                \n",
    "                if len(aln) > 0 and aln.fident.iloc[0] < fident_thresh:\n",
    "                    aln = aln.iloc[0]\n",
    "                    qaln = aln.qaln\n",
    "                    taln = aln.taln\n",
    "                    qaccession = q.split('.')[0]\n",
    "                    taccession = t.split('.')[0]\n",
    "                    \n",
    "                    if qaccession in encoded_df.index and taccession in encoded_df.index:\n",
    "                        # Get encoded sequences for aligned regions\n",
    "                        qz = str(encoded_df.loc[qaccession].seq[aln.qstart-1:aln.qend])\n",
    "                        tz = str(encoded_df.loc[taccession].seq[aln.tstart-1:aln.tend])\n",
    "                        \n",
    "                        # Update background frequencies (only once per sequence)\n",
    "                        if qaccession not in all_processed_seqs:\n",
    "                            background_freq += np.array([qz.count(c) for c in char_set])\n",
    "                            file_seqset.add(qaccession)\n",
    "                            all_processed_seqs.add(qaccession)\n",
    "                            seqcount += len(qz)\n",
    "                        \n",
    "                        if taccession not in all_processed_seqs:\n",
    "                            background_freq += np.array([tz.count(c) for c in char_set])\n",
    "                            file_seqset.add(taccession)\n",
    "                            all_processed_seqs.add(taccession)\n",
    "                            seqcount += len(tz)\n",
    "                        \n",
    "                        # Check alignment lengths match\n",
    "                        if len(qz) == len(qaln.replace('-','')) and len(tz) == len(taln.replace('-','')):\n",
    "                            # Map aligned positions to character indices\n",
    "                            qz_iter = iter(qz)\n",
    "                            tz_iter = iter(tz)\n",
    "                            qaln_ft2, taln_ft2 = [], []\n",
    "                            \n",
    "                            for q_char in qaln:\n",
    "                                if q_char == '-':\n",
    "                                    qaln_ft2.append(None)\n",
    "                                else:\n",
    "                                    qaln_ft2.append(char_position_map[next(qz_iter)])\n",
    "                            \n",
    "                            for t_char in taln.strip():\n",
    "                                if t_char == '-':\n",
    "                                    taln_ft2.append(None)\n",
    "                                else:\n",
    "                                    taln_ft2.append(char_position_map[next(tz_iter)])\n",
    "                            \n",
    "                            # Count substitution pairs\n",
    "                            alnzip = [[a, b] for a, b in zip(qaln_ft2, taln_ft2) \n",
    "                                     if a is not None and b is not None]\n",
    "                            \n",
    "                            if len(alnzip) > 0:\n",
    "                                alnzip = np.array(alnzip)\n",
    "                                pair_counts[alnzip[:,0], alnzip[:,1]] += 1\n",
    "    \n",
    "    # Update convergence monitor at regular intervals\n",
    "    if (file_idx + 1) % update_interval == 0 or file_idx == len(alnfiles) - 1:\n",
    "        # Compute current log-odds matrix\n",
    "        current_log_odds = compute_log_odds_from_counts(pair_counts, background_freq)\n",
    "        \n",
    "        # Update monitor\n",
    "        monitor.update(file_idx + 1, current_log_odds)\n",
    "        \n",
    "        # Display convergence plots\n",
    "        clear_output(wait=True)\n",
    "        fig = monitor.plot_convergence(figsize=figsize)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print current status\n",
    "        summary = monitor.get_convergence_summary()\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Progress: {file_idx + 1}/{len(alnfiles)} files ({100*(file_idx+1)/len(alnfiles):.1f}%)\")\n",
    "        print(f\"Processed sequences: {len(all_processed_seqs)}\")\n",
    "        print(f\"Total sequence positions: {seqcount}\")\n",
    "        print(f\"Gradient norm: {summary['final_gradient_norm']:.6f}\")\n",
    "        print(f\"Converged: {summary['is_converged']}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"\\nAlignment processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb979e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final convergence summary and statistics\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL CONVERGENCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = monitor.get_convergence_summary()\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nTotal pair counts: {np.sum(pair_counts):.0f}\")\n",
    "print(f\"Non-zero pairs: {np.count_nonzero(pair_counts)}\")\n",
    "print(f\"Sparsity: {100*(1 - np.count_nonzero(pair_counts)/(matrix_size**2)):.2f}%\")\n",
    "\n",
    "# Display final convergence plot\n",
    "fig = monitor.plot_convergence(figsize=figsize)\n",
    "plt.savefig(os.path.join(output_dir, f'{modelname}_convergence.png'), dpi=150, bbox_inches='tight')\n",
    "print(f\"\\nSaved convergence plot to: {os.path.join(output_dir, f'{modelname}_convergence.png')}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f78d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final substitution matrices\n",
    "\n",
    "# Normalize background frequencies\n",
    "background_freq = background_freq / np.sum(background_freq)\n",
    "\n",
    "# Compute log-odds matrix\n",
    "print(\"Computing final log-odds matrix...\")\n",
    "log_odds_matrix = compute_log_odds_from_counts(pair_counts, background_freq)\n",
    "\n",
    "# Visualize final matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Raw pair counts\n",
    "im0 = axes[0, 0].imshow(pair_counts, cmap='viridis', aspect='auto', interpolation='nearest')\n",
    "axes[0, 0].set_title('Raw Pair Counts', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Character Index')\n",
    "axes[0, 0].set_ylabel('Character Index')\n",
    "plt.colorbar(im0, ax=axes[0, 0], fraction=0.046)\n",
    "\n",
    "# Log-odds scores\n",
    "im1 = axes[0, 1].imshow(log_odds_matrix, cmap='RdBu_r', aspect='auto', \n",
    "                        interpolation='nearest', vmin=-2, vmax=2)\n",
    "axes[0, 1].set_title('Log-Odds Substitution Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Character Index')\n",
    "axes[0, 1].set_ylabel('Character Index')\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046)\n",
    "\n",
    "# Background frequencies\n",
    "axes[1, 0].bar(range(len(background_freq)), background_freq, color='steelblue', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Character Index')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Background Character Frequencies', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Diagonal vs off-diagonal scores\n",
    "diagonal = np.diag(log_odds_matrix)\n",
    "off_diagonal = log_odds_matrix[~np.eye(matrix_size, dtype=bool)]\n",
    "\n",
    "axes[1, 1].hist(diagonal, bins=30, alpha=0.7, label='Diagonal (same char)', color='green')\n",
    "axes[1, 1].hist(off_diagonal, bins=30, alpha=0.7, label='Off-diagonal (different char)', color='red')\n",
    "axes[1, 1].set_xlabel('Log-Odds Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Substitution Scores', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f'{modelname}_final_matrices.png'), dpi=150, bbox_inches='tight')\n",
    "print(f\"Saved final matrix visualization to: {os.path.join(output_dir, f'{modelname}_final_matrices.png')}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMatrix Statistics:\")\n",
    "print(f\"  Log-odds range: [{np.min(log_odds_matrix):.3f}, {np.max(log_odds_matrix):.3f}]\")\n",
    "print(f\"  Mean diagonal score: {np.mean(diagonal):.3f}\")\n",
    "print(f\"  Mean off-diagonal score: {np.mean(off_diagonal):.3f}\")\n",
    "print(f\"  Std diagonal: {np.std(diagonal):.3f}\")\n",
    "print(f\"  Std off-diagonal: {np.std(off_diagonal):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output MAFFT-compatible matrix\n",
    "\n",
    "def output_mafft_matrix(submat, char_set, char_position_map, outpath):\n",
    "    \"\"\"Write substitution matrix in MAFFT format.\"\"\"\n",
    "    def formathex(hexnum):\n",
    "        if len(hexnum) == 3:\n",
    "            return hexnum[0:2] + '0' + hexnum[2]\n",
    "        else:\n",
    "            return hexnum\n",
    "    \n",
    "    reverse_char_map = {v: k for k, v in char_position_map.items()}\n",
    "    \n",
    "    with open(outpath, 'w') as f:\n",
    "        for i in range(len(char_set)):\n",
    "            for j in range(len(char_set)):\n",
    "                if i <= j:\n",
    "                    stringi = reverse_char_map[i]\n",
    "                    stringj = reverse_char_map[j]\n",
    "                    hexi = formathex(hex(ord(stringi)))\n",
    "                    hexj = formathex(hex(ord(stringj)))\n",
    "                    f.write(f'{hexi} {hexj} {submat[i,j]}\\n')\n",
    "\n",
    "mafft_path = os.path.join(output_dir, f'{modelname}_mafftmat.mtx')\n",
    "output_mafft_matrix(log_odds_matrix, char_set, char_position_map, mafft_path)\n",
    "print(f\"MAFFT matrix saved to: {mafft_path}\")\n",
    "print(f\"  Format: Upper triangular with hex character codes\")\n",
    "print(f\"  Size: {matrix_size}x{matrix_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output RAxML-compatible matrix\n",
    "\n",
    "def compute_raxml_compatible_matrix(pair_counts, char_freqs, raxml_charset, \n",
    "                                    raxml_char_position_map, pseudocount=1e-20, \n",
    "                                    log_base=np.e, scaling_factor=1.0):\n",
    "    \"\"\"Compute time-reversible rate matrix for RAxML.\"\"\"\n",
    "    # Compute log odds\n",
    "    log_odds_matrix = compute_log_odds_from_counts(pair_counts, char_freqs, \n",
    "                                                    pseudocount, log_base)\n",
    "    \n",
    "    # Exponentiate to get relative rates\n",
    "    preliminary_rates = np.exp(log_odds_matrix * scaling_factor)\n",
    "    \n",
    "    # Symmetrize for reversibility\n",
    "    n = preliminary_rates.shape[0]\n",
    "    rate_matrix = np.zeros_like(preliminary_rates)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                rate_matrix[i, j] = (preliminary_rates[i, j] + preliminary_rates[j, i]) / 2.0\n",
    "    \n",
    "    # Set diagonal so rows sum to zero\n",
    "    for i in range(n):\n",
    "        rate_matrix[i, i] = -np.sum(rate_matrix[i, :]) + rate_matrix[i, i]\n",
    "    \n",
    "    # Scale so expected rate = 1\n",
    "    char_freqs = char_freqs / np.sum(char_freqs)\n",
    "    expected_rate = -np.sum(char_freqs * np.diag(rate_matrix))\n",
    "    rate_matrix = rate_matrix / expected_rate\n",
    "    \n",
    "    return rate_matrix, char_freqs\n",
    "\n",
    "def output_raxml_matrix(matrix, background_frequencies, outpath):\n",
    "    \"\"\"Write RAxML-compatible matrix.\"\"\"\n",
    "    with open(outpath, \"w\") as f:\n",
    "        # Lower triangular matrix\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[0]):\n",
    "                if j < i:\n",
    "                    f.write(f\" {matrix[i,j]:.6f}\")\n",
    "            f.write(\"\\n\")\n",
    "        # Frequencies\n",
    "        for i, freq in enumerate(background_frequencies):\n",
    "            f.write(f\"{freq:.6f} \")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "raxml_matrix, char_freqs = compute_raxml_compatible_matrix(\n",
    "    pair_counts, background_freq, raxml_charset, raxml_char_position_map, \n",
    "    scaling_factor=1.0\n",
    ")\n",
    "\n",
    "raxml_path = os.path.join(output_dir, f'{modelname}_submat.txt')\n",
    "output_raxml_matrix(raxml_matrix, char_freqs, raxml_path)\n",
    "print(f\"\\nRAxML matrix saved to: {raxml_path}\")\n",
    "print(f\"  Format: Lower triangular + frequencies\")\n",
    "print(f\"  Size: {matrix_size}x{matrix_size}\")\n",
    "print(f\"  Time-reversible: Yes\")\n",
    "print(f\"  Expected substitution rate: 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate results for future use\n",
    "\n",
    "results_path = os.path.join(output_dir, f'{modelname}_pair_counts.pkl')\n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'pair_counts': pair_counts,\n",
    "        'char_set': char_set,\n",
    "        'char_position_map': char_position_map,\n",
    "        'raxml_charset': raxml_charset,\n",
    "        'raxml_char_position_map': raxml_char_position_map,\n",
    "        'background_freq': background_freq,\n",
    "        'convergence_history': monitor.history\n",
    "    }, f)\n",
    "\n",
    "print(f\"Saved intermediate results to: {results_path}\")\n",
    "print(\"\\nSaved data includes:\")\n",
    "print(\"  - Pair counts matrix\")\n",
    "print(\"  - Character sets and mappings\")\n",
    "print(\"  - Background frequencies\")\n",
    "print(\"  - Full convergence history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d6e19",
   "metadata": {},
   "source": [
    "## Analysis: Matrix Evolution Over Time\n",
    "\n",
    "Visualize how specific substitution scores evolved during the iteration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track evolution of specific matrix elements over time\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Select sample matrix positions to track\n",
    "sample_positions = [\n",
    "    (0, 0),  # Diagonal element\n",
    "    (0, 1),  # Adjacent off-diagonal\n",
    "    (matrix_size//2, matrix_size//2),  # Middle diagonal\n",
    "    (5, 10)  # Random off-diagonal\n",
    "]\n",
    "\n",
    "iterations = monitor.history['iteration']\n",
    "\n",
    "# Plot 1: Evolution of sample positions\n",
    "for pos in sample_positions:\n",
    "    values = [snapshot[pos] for snapshot in monitor.history['snapshots']]\n",
    "    label = f'[{pos[0]},{pos[1]}]{\"(diag)\" if pos[0]==pos[1] else \"\"}'\n",
    "    axes[0, 0].plot(iterations, values, marker='o', linewidth=2, label=label)\n",
    "\n",
    "axes[0, 0].set_xlabel('Iteration (Alignment Files)')\n",
    "axes[0, 0].set_ylabel('Log-Odds Score')\n",
    "axes[0, 0].set_title('Evolution of Sample Matrix Elements', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Variance across iterations for each position\n",
    "if len(monitor.history['snapshots']) > 3:\n",
    "    snapshot_array = np.array(monitor.history['snapshots'])\n",
    "    element_variance = np.var(snapshot_array, axis=0)\n",
    "    \n",
    "    im = axes[0, 1].imshow(element_variance, cmap='hot', aspect='auto', interpolation='nearest')\n",
    "    axes[0, 1].set_title('Element-wise Variance Across Iterations', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Character Index')\n",
    "    axes[0, 1].set_ylabel('Character Index')\n",
    "    plt.colorbar(im, ax=axes[0, 1], fraction=0.046)\n",
    "\n",
    "# Plot 3: Mean absolute change per iteration\n",
    "mean_abs_changes = []\n",
    "for i in range(1, len(monitor.history['snapshots'])):\n",
    "    change = np.abs(monitor.history['snapshots'][i] - monitor.history['snapshots'][i-1])\n",
    "    mean_abs_changes.append(np.mean(change))\n",
    "\n",
    "if len(mean_abs_changes) > 0:\n",
    "    axes[1, 0].plot(iterations[1:], mean_abs_changes, 'purple', linewidth=2, marker='o')\n",
    "    axes[1, 0].set_xlabel('Iteration (Alignment Files)')\n",
    "    axes[1, 0].set_ylabel('Mean Absolute Change')\n",
    "    axes[1, 0].set_title('Average Element Change Per Iteration', fontweight='bold')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Cumulative changes heatmap\n",
    "if len(monitor.history['snapshots']) > 1:\n",
    "    cumulative_change = np.abs(monitor.history['snapshots'][-1] - monitor.history['snapshots'][0])\n",
    "    im = axes[1, 1].imshow(cumulative_change, cmap='plasma', aspect='auto', interpolation='nearest')\n",
    "    axes[1, 1].set_title('Total Change from First to Last Iteration', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Character Index')\n",
    "    axes[1, 1].set_ylabel('Character Index')\n",
    "    plt.colorbar(im, ax=axes[1, 1], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f'{modelname}_evolution_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "print(f\"Saved evolution analysis to: {os.path.join(output_dir, f'{modelname}_evolution_analysis.png')}\")\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "if len(mean_abs_changes) > 0:\n",
    "    print(f\"\\nEvolution Statistics:\")\n",
    "    print(f\"  Initial mean change: {mean_abs_changes[0]:.6f}\")\n",
    "    print(f\"  Final mean change: {mean_abs_changes[-1]:.6f}\")\n",
    "    print(f\"  Reduction factor: {mean_abs_changes[0]/mean_abs_changes[-1]:.2f}x\")\n",
    "    print(f\"  Most variable position: {np.unravel_index(element_variance.argmax(), element_variance.shape)}\")\n",
    "    print(f\"  Max variance: {np.max(element_variance):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106436b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Files Generated\n",
    "1. **MAFFT Matrix**: `{modelname}_mafftmat.mtx` - For MAFFT alignment with custom scoring\n",
    "2. **RAxML Matrix**: `{modelname}_submat.txt` - For phylogenetic inference with RAxML\n",
    "3. **Convergence Plot**: `{modelname}_convergence.png` - Real-time monitoring visualization\n",
    "4. **Final Matrices**: `{modelname}_final_matrices.png` - Matrix structure and statistics\n",
    "5. **Evolution Analysis**: `{modelname}_evolution_analysis.png` - Element tracking over time\n",
    "6. **Intermediate Data**: `{modelname}_pair_counts.pkl` - Reusable computation results\n",
    "\n",
    "### Key Insights from Convergence Monitoring\n",
    "- **Gradient Norm**: Measures the rate at which the matrix is changing between iterations\n",
    "- **Frobenius Norm**: Overall magnitude of the matrix values\n",
    "- **Element Variance**: Identifies which substitution pairs are most sensitive to new data\n",
    "- **Convergence Status**: Automatically detects when the matrix has stabilized\n",
    "\n",
    "The real-time visualization helps ensure:\n",
    "1. The matrix converges to a stable solution\n",
    "2. No outlier alignment files cause dramatic shifts\n",
    "3. Sufficient data has been processed for reliable estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foldtree2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
