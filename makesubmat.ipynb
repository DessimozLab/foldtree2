{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the afdb clusters file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "#autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import AFDB_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read the afdb rep file\n",
    "reps = pd.read_table( 'afdbclusters/1-AFDBClusters-entryId_repId_taxId.tsv', header=None, names=['entryId', 'repId', 'taxId'] )\n",
    "print( 'reps' , reps.head() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "structs = glob.glob( 'structs/*.pdb' )\n",
    "#remove the .pdb extension\n",
    "structs = [ s.split( '/' )[-1].split( '.' )[0] for s in structs ]\n",
    "print(structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the reps that have structures\n",
    "reps = reps[ reps['repId'].isin( structs ) ]\n",
    "print(  len(reps)  , reps.head() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a structure alignment directory\n",
    "if not os.path.exists( 'struct_align' ):\n",
    "    os.makedirs( 'struct_align' )\n",
    "\n",
    "#make a directory for each cluster representative\n",
    "for rep in reps['repId']:\n",
    "    if not os.path.exists( 'struct_align/' + rep  ):\n",
    "        os.makedirs( 'struct_align/' + rep  )\n",
    "    if not os.path.exists( 'struct_align/' + rep  + '/structs/'):\n",
    "        os.makedirs( 'struct_align/' + rep + '/structs/' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1400/1400 [06:38<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#download n struct members for each cluster\n",
    "import tqdm\n",
    "n = 5\n",
    "for rep in tqdm.tqdm(reps.repId.unique() ):\n",
    "    subdf = reps[ reps['repId'] == rep ]\n",
    "    if len(subdf) < n:\n",
    "        n = len(subdf)\n",
    "    subdf = subdf.sample( n = n  )\n",
    "    subdf = subdf.head( n )\n",
    "    #download the structures\n",
    "    for uniID in subdf['entryId']:\n",
    "        AFDB_tools.grab_struct(uniID , structfolder='struct_align/' + rep  + '/structs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1400/1400 [06:41<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#for each folder in struct_align, align the structures with all vs all using foldseek\n",
    "from src import foldseek2tree\n",
    "import tqdm\n",
    "\n",
    "for rep in tqdm.tqdm(reps.repId.unique() ):\n",
    "    #align the structures\n",
    "    foldseek2tree.runFoldseek_allvall_EZsearch( infolder='struct_align/' + rep  + '/structs/', outpath='struct_align/' + rep + '/allvall.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive embeddings for all structures in the struct_align folder\n",
    "#derive charatcters for 10,20,40,80,128,256,512 kmeans clusters\n",
    "charsets = [10,20,40,80,128,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t'}, 20: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t', 10: '\\n', 11: '\\x0b', 12: '\\x0c', 13: '\\r', 14: '\\x0e', 15: '\\x0f', 16: '\\x10', 17: '\\x11', 18: '\\x12', 19: '\\x13'}, 40: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t', 10: '\\n', 11: '\\x0b', 12: '\\x0c', 13: '\\r', 14: '\\x0e', 15: '\\x0f', 16: '\\x10', 17: '\\x11', 18: '\\x12', 19: '\\x13', 20: '\\x14', 21: '\\x15', 22: '\\x16', 23: '\\x17', 24: '\\x18', 25: '\\x19', 26: '\\x1a', 27: '\\x1b', 28: '\\x1c', 29: '\\x1d', 30: '\\x1e', 31: '\\x1f', 32: ' ', 33: '!', 34: '\"', 35: '#', 36: '$', 37: '%', 38: '&', 39: \"'\"}, 80: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t', 10: '\\n', 11: '\\x0b', 12: '\\x0c', 13: '\\r', 14: '\\x0e', 15: '\\x0f', 16: '\\x10', 17: '\\x11', 18: '\\x12', 19: '\\x13', 20: '\\x14', 21: '\\x15', 22: '\\x16', 23: '\\x17', 24: '\\x18', 25: '\\x19', 26: '\\x1a', 27: '\\x1b', 28: '\\x1c', 29: '\\x1d', 30: '\\x1e', 31: '\\x1f', 32: ' ', 33: '!', 34: '\"', 35: '#', 36: '$', 37: '%', 38: '&', 39: \"'\", 40: '(', 41: ')', 42: '*', 43: '+', 44: ',', 45: '-', 46: '.', 47: '/', 48: '0', 49: '1', 50: '2', 51: '3', 52: '4', 53: '5', 54: '6', 55: '7', 56: '8', 57: '9', 58: ':', 59: ';', 60: '<', 61: '=', 62: '>', 63: '?', 64: '@', 65: 'A', 66: 'B', 67: 'C', 68: 'D', 69: 'E', 70: 'F', 71: 'G', 72: 'H', 73: 'I', 74: 'J', 75: 'K', 76: 'L', 77: 'M', 78: 'N', 79: 'O'}, 128: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t', 10: '\\n', 11: '\\x0b', 12: '\\x0c', 13: '\\r', 14: '\\x0e', 15: '\\x0f', 16: '\\x10', 17: '\\x11', 18: '\\x12', 19: '\\x13', 20: '\\x14', 21: '\\x15', 22: '\\x16', 23: '\\x17', 24: '\\x18', 25: '\\x19', 26: '\\x1a', 27: '\\x1b', 28: '\\x1c', 29: '\\x1d', 30: '\\x1e', 31: '\\x1f', 32: ' ', 33: '!', 34: '\"', 35: '#', 36: '$', 37: '%', 38: '&', 39: \"'\", 40: '(', 41: ')', 42: '*', 43: '+', 44: ',', 45: '-', 46: '.', 47: '/', 48: '0', 49: '1', 50: '2', 51: '3', 52: '4', 53: '5', 54: '6', 55: '7', 56: '8', 57: '9', 58: ':', 59: ';', 60: '<', 61: '=', 62: '>', 63: '?', 64: '@', 65: 'A', 66: 'B', 67: 'C', 68: 'D', 69: 'E', 70: 'F', 71: 'G', 72: 'H', 73: 'I', 74: 'J', 75: 'K', 76: 'L', 77: 'M', 78: 'N', 79: 'O', 80: 'P', 81: 'Q', 82: 'R', 83: 'S', 84: 'T', 85: 'U', 86: 'V', 87: 'W', 88: 'X', 89: 'Y', 90: 'Z', 91: '[', 92: '\\\\', 93: ']', 94: '^', 95: '_', 96: '`', 97: 'a', 98: 'b', 99: 'c', 100: 'd', 101: 'e', 102: 'f', 103: 'g', 104: 'h', 105: 'i', 106: 'j', 107: 'k', 108: 'l', 109: 'm', 110: 'n', 111: 'o', 112: 'p', 113: 'q', 114: 'r', 115: 's', 116: 't', 117: 'u', 118: 'v', 119: 'w', 120: 'x', 121: 'y', 122: 'z', 123: '{', 124: '|', 125: '}', 126: '~', 127: '\\x7f'}, 256: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t', 10: '\\n', 11: '\\x0b', 12: '\\x0c', 13: '\\r', 14: '\\x0e', 15: '\\x0f', 16: '\\x10', 17: '\\x11', 18: '\\x12', 19: '\\x13', 20: '\\x14', 21: '\\x15', 22: '\\x16', 23: '\\x17', 24: '\\x18', 25: '\\x19', 26: '\\x1a', 27: '\\x1b', 28: '\\x1c', 29: '\\x1d', 30: '\\x1e', 31: '\\x1f', 32: ' ', 33: '!', 34: '\"', 35: '#', 36: '$', 37: '%', 38: '&', 39: \"'\", 40: '(', 41: ')', 42: '*', 43: '+', 44: ',', 45: '-', 46: '.', 47: '/', 48: '0', 49: '1', 50: '2', 51: '3', 52: '4', 53: '5', 54: '6', 55: '7', 56: '8', 57: '9', 58: ':', 59: ';', 60: '<', 61: '=', 62: '>', 63: '?', 64: '@', 65: 'A', 66: 'B', 67: 'C', 68: 'D', 69: 'E', 70: 'F', 71: 'G', 72: 'H', 73: 'I', 74: 'J', 75: 'K', 76: 'L', 77: 'M', 78: 'N', 79: 'O', 80: 'P', 81: 'Q', 82: 'R', 83: 'S', 84: 'T', 85: 'U', 86: 'V', 87: 'W', 88: 'X', 89: 'Y', 90: 'Z', 91: '[', 92: '\\\\', 93: ']', 94: '^', 95: '_', 96: '`', 97: 'a', 98: 'b', 99: 'c', 100: 'd', 101: 'e', 102: 'f', 103: 'g', 104: 'h', 105: 'i', 106: 'j', 107: 'k', 108: 'l', 109: 'm', 110: 'n', 111: 'o', 112: 'p', 113: 'q', 114: 'r', 115: 's', 116: 't', 117: 'u', 118: 'v', 119: 'w', 120: 'x', 121: 'y', 122: 'z', 123: '{', 124: '|', 125: '}', 126: '~', 127: '\\x7f', 128: '\\x80', 129: '\\x81', 130: '\\x82', 131: '\\x83', 132: '\\x84', 133: '\\x85', 134: '\\x86', 135: '\\x87', 136: '\\x88', 137: '\\x89', 138: '\\x8a', 139: '\\x8b', 140: '\\x8c', 141: '\\x8d', 142: '\\x8e', 143: '\\x8f', 144: '\\x90', 145: '\\x91', 146: '\\x92', 147: '\\x93', 148: '\\x94', 149: '\\x95', 150: '\\x96', 151: '\\x97', 152: '\\x98', 153: '\\x99', 154: '\\x9a', 155: '\\x9b', 156: '\\x9c', 157: '\\x9d', 158: '\\x9e', 159: '\\x9f', 160: '\\xa0', 161: '¡', 162: '¢', 163: '£', 164: '¤', 165: '¥', 166: '¦', 167: '§', 168: '¨', 169: '©', 170: 'ª', 171: '«', 172: '¬', 173: '\\xad', 174: '®', 175: '¯', 176: '°', 177: '±', 178: '²', 179: '³', 180: '´', 181: 'µ', 182: '¶', 183: '·', 184: '¸', 185: '¹', 186: 'º', 187: '»', 188: '¼', 189: '½', 190: '¾', 191: '¿', 192: 'À', 193: 'Á', 194: 'Â', 195: 'Ã', 196: 'Ä', 197: 'Å', 198: 'Æ', 199: 'Ç', 200: 'È', 201: 'É', 202: 'Ê', 203: 'Ë', 204: 'Ì', 205: 'Í', 206: 'Î', 207: 'Ï', 208: 'Ð', 209: 'Ñ', 210: 'Ò', 211: 'Ó', 212: 'Ô', 213: 'Õ', 214: 'Ö', 215: '×', 216: 'Ø', 217: 'Ù', 218: 'Ú', 219: 'Û', 220: 'Ü', 221: 'Ý', 222: 'Þ', 223: 'ß', 224: 'à', 225: 'á', 226: 'â', 227: 'ã', 228: 'ä', 229: 'å', 230: 'æ', 231: 'ç', 232: 'è', 233: 'é', 234: 'ê', 235: 'ë', 236: 'ì', 237: 'í', 238: 'î', 239: 'ï', 240: 'ð', 241: 'ñ', 242: 'ò', 243: 'ó', 244: 'ô', 245: 'õ', 246: 'ö', 247: '÷', 248: 'ø', 249: 'ù', 250: 'ú', 251: 'û', 252: 'ü', 253: 'ý', 254: 'þ', 255: 'ÿ'}, 512: {0: '\\x00', 1: '\\x01', 2: '\\x02', 3: '\\x03', 4: '\\x04', 5: '\\x05', 6: '\\x06', 7: '\\x07', 8: '\\x08', 9: '\\t', 10: '\\n', 11: '\\x0b', 12: '\\x0c', 13: '\\r', 14: '\\x0e', 15: '\\x0f', 16: '\\x10', 17: '\\x11', 18: '\\x12', 19: '\\x13', 20: '\\x14', 21: '\\x15', 22: '\\x16', 23: '\\x17', 24: '\\x18', 25: '\\x19', 26: '\\x1a', 27: '\\x1b', 28: '\\x1c', 29: '\\x1d', 30: '\\x1e', 31: '\\x1f', 32: ' ', 33: '!', 34: '\"', 35: '#', 36: '$', 37: '%', 38: '&', 39: \"'\", 40: '(', 41: ')', 42: '*', 43: '+', 44: ',', 45: '-', 46: '.', 47: '/', 48: '0', 49: '1', 50: '2', 51: '3', 52: '4', 53: '5', 54: '6', 55: '7', 56: '8', 57: '9', 58: ':', 59: ';', 60: '<', 61: '=', 62: '>', 63: '?', 64: '@', 65: 'A', 66: 'B', 67: 'C', 68: 'D', 69: 'E', 70: 'F', 71: 'G', 72: 'H', 73: 'I', 74: 'J', 75: 'K', 76: 'L', 77: 'M', 78: 'N', 79: 'O', 80: 'P', 81: 'Q', 82: 'R', 83: 'S', 84: 'T', 85: 'U', 86: 'V', 87: 'W', 88: 'X', 89: 'Y', 90: 'Z', 91: '[', 92: '\\\\', 93: ']', 94: '^', 95: '_', 96: '`', 97: 'a', 98: 'b', 99: 'c', 100: 'd', 101: 'e', 102: 'f', 103: 'g', 104: 'h', 105: 'i', 106: 'j', 107: 'k', 108: 'l', 109: 'm', 110: 'n', 111: 'o', 112: 'p', 113: 'q', 114: 'r', 115: 's', 116: 't', 117: 'u', 118: 'v', 119: 'w', 120: 'x', 121: 'y', 122: 'z', 123: '{', 124: '|', 125: '}', 126: '~', 127: '\\x7f', 128: '\\x80', 129: '\\x81', 130: '\\x82', 131: '\\x83', 132: '\\x84', 133: '\\x85', 134: '\\x86', 135: '\\x87', 136: '\\x88', 137: '\\x89', 138: '\\x8a', 139: '\\x8b', 140: '\\x8c', 141: '\\x8d', 142: '\\x8e', 143: '\\x8f', 144: '\\x90', 145: '\\x91', 146: '\\x92', 147: '\\x93', 148: '\\x94', 149: '\\x95', 150: '\\x96', 151: '\\x97', 152: '\\x98', 153: '\\x99', 154: '\\x9a', 155: '\\x9b', 156: '\\x9c', 157: '\\x9d', 158: '\\x9e', 159: '\\x9f', 160: '\\xa0', 161: '¡', 162: '¢', 163: '£', 164: '¤', 165: '¥', 166: '¦', 167: '§', 168: '¨', 169: '©', 170: 'ª', 171: '«', 172: '¬', 173: '\\xad', 174: '®', 175: '¯', 176: '°', 177: '±', 178: '²', 179: '³', 180: '´', 181: 'µ', 182: '¶', 183: '·', 184: '¸', 185: '¹', 186: 'º', 187: '»', 188: '¼', 189: '½', 190: '¾', 191: '¿', 192: 'À', 193: 'Á', 194: 'Â', 195: 'Ã', 196: 'Ä', 197: 'Å', 198: 'Æ', 199: 'Ç', 200: 'È', 201: 'É', 202: 'Ê', 203: 'Ë', 204: 'Ì', 205: 'Í', 206: 'Î', 207: 'Ï', 208: 'Ð', 209: 'Ñ', 210: 'Ò', 211: 'Ó', 212: 'Ô', 213: 'Õ', 214: 'Ö', 215: '×', 216: 'Ø', 217: 'Ù', 218: 'Ú', 219: 'Û', 220: 'Ü', 221: 'Ý', 222: 'Þ', 223: 'ß', 224: 'à', 225: 'á', 226: 'â', 227: 'ã', 228: 'ä', 229: 'å', 230: 'æ', 231: 'ç', 232: 'è', 233: 'é', 234: 'ê', 235: 'ë', 236: 'ì', 237: 'í', 238: 'î', 239: 'ï', 240: 'ð', 241: 'ñ', 242: 'ò', 243: 'ó', 244: 'ô', 245: 'õ', 246: 'ö', 247: '÷', 248: 'ø', 249: 'ù', 250: 'ú', 251: 'û', 252: 'ü', 253: 'ý', 254: 'þ', 255: 'ÿ', 256: 'Ā', 257: 'ā', 258: 'Ă', 259: 'ă', 260: 'Ą', 261: 'ą', 262: 'Ć', 263: 'ć', 264: 'Ĉ', 265: 'ĉ', 266: 'Ċ', 267: 'ċ', 268: 'Č', 269: 'č', 270: 'Ď', 271: 'ď', 272: 'Đ', 273: 'đ', 274: 'Ē', 275: 'ē', 276: 'Ĕ', 277: 'ĕ', 278: 'Ė', 279: 'ė', 280: 'Ę', 281: 'ę', 282: 'Ě', 283: 'ě', 284: 'Ĝ', 285: 'ĝ', 286: 'Ğ', 287: 'ğ', 288: 'Ġ', 289: 'ġ', 290: 'Ģ', 291: 'ģ', 292: 'Ĥ', 293: 'ĥ', 294: 'Ħ', 295: 'ħ', 296: 'Ĩ', 297: 'ĩ', 298: 'Ī', 299: 'ī', 300: 'Ĭ', 301: 'ĭ', 302: 'Į', 303: 'į', 304: 'İ', 305: 'ı', 306: 'Ĳ', 307: 'ĳ', 308: 'Ĵ', 309: 'ĵ', 310: 'Ķ', 311: 'ķ', 312: 'ĸ', 313: 'Ĺ', 314: 'ĺ', 315: 'Ļ', 316: 'ļ', 317: 'Ľ', 318: 'ľ', 319: 'Ŀ', 320: 'ŀ', 321: 'Ł', 322: 'ł', 323: 'Ń', 324: 'ń', 325: 'Ņ', 326: 'ņ', 327: 'Ň', 328: 'ň', 329: 'ŉ', 330: 'Ŋ', 331: 'ŋ', 332: 'Ō', 333: 'ō', 334: 'Ŏ', 335: 'ŏ', 336: 'Ő', 337: 'ő', 338: 'Œ', 339: 'œ', 340: 'Ŕ', 341: 'ŕ', 342: 'Ŗ', 343: 'ŗ', 344: 'Ř', 345: 'ř', 346: 'Ś', 347: 'ś', 348: 'Ŝ', 349: 'ŝ', 350: 'Ş', 351: 'ş', 352: 'Š', 353: 'š', 354: 'Ţ', 355: 'ţ', 356: 'Ť', 357: 'ť', 358: 'Ŧ', 359: 'ŧ', 360: 'Ũ', 361: 'ũ', 362: 'Ū', 363: 'ū', 364: 'Ŭ', 365: 'ŭ', 366: 'Ů', 367: 'ů', 368: 'Ű', 369: 'ű', 370: 'Ų', 371: 'ų', 372: 'Ŵ', 373: 'ŵ', 374: 'Ŷ', 375: 'ŷ', 376: 'Ÿ', 377: 'Ź', 378: 'ź', 379: 'Ż', 380: 'ż', 381: 'Ž', 382: 'ž', 383: 'ſ', 384: 'ƀ', 385: 'Ɓ', 386: 'Ƃ', 387: 'ƃ', 388: 'Ƅ', 389: 'ƅ', 390: 'Ɔ', 391: 'Ƈ', 392: 'ƈ', 393: 'Ɖ', 394: 'Ɗ', 395: 'Ƌ', 396: 'ƌ', 397: 'ƍ', 398: 'Ǝ', 399: 'Ə', 400: 'Ɛ', 401: 'Ƒ', 402: 'ƒ', 403: 'Ɠ', 404: 'Ɣ', 405: 'ƕ', 406: 'Ɩ', 407: 'Ɨ', 408: 'Ƙ', 409: 'ƙ', 410: 'ƚ', 411: 'ƛ', 412: 'Ɯ', 413: 'Ɲ', 414: 'ƞ', 415: 'Ɵ', 416: 'Ơ', 417: 'ơ', 418: 'Ƣ', 419: 'ƣ', 420: 'Ƥ', 421: 'ƥ', 422: 'Ʀ', 423: 'Ƨ', 424: 'ƨ', 425: 'Ʃ', 426: 'ƪ', 427: 'ƫ', 428: 'Ƭ', 429: 'ƭ', 430: 'Ʈ', 431: 'Ư', 432: 'ư', 433: 'Ʊ', 434: 'Ʋ', 435: 'Ƴ', 436: 'ƴ', 437: 'Ƶ', 438: 'ƶ', 439: 'Ʒ', 440: 'Ƹ', 441: 'ƹ', 442: 'ƺ', 443: 'ƻ', 444: 'Ƽ', 445: 'ƽ', 446: 'ƾ', 447: 'ƿ', 448: 'ǀ', 449: 'ǁ', 450: 'ǂ', 451: 'ǃ', 452: 'Ǆ', 453: 'ǅ', 454: 'ǆ', 455: 'Ǉ', 456: 'ǈ', 457: 'ǉ', 458: 'Ǌ', 459: 'ǋ', 460: 'ǌ', 461: 'Ǎ', 462: 'ǎ', 463: 'Ǐ', 464: 'ǐ', 465: 'Ǒ', 466: 'ǒ', 467: 'Ǔ', 468: 'ǔ', 469: 'Ǖ', 470: 'ǖ', 471: 'Ǘ', 472: 'ǘ', 473: 'Ǚ', 474: 'ǚ', 475: 'Ǜ', 476: 'ǜ', 477: 'ǝ', 478: 'Ǟ', 479: 'ǟ', 480: 'Ǡ', 481: 'ǡ', 482: 'Ǣ', 483: 'ǣ', 484: 'Ǥ', 485: 'ǥ', 486: 'Ǧ', 487: 'ǧ', 488: 'Ǩ', 489: 'ǩ', 490: 'Ǫ', 491: 'ǫ', 492: 'Ǭ', 493: 'ǭ', 494: 'Ǯ', 495: 'ǯ', 496: 'ǰ', 497: 'Ǳ', 498: 'ǲ', 499: 'ǳ', 500: 'Ǵ', 501: 'ǵ', 502: 'Ƕ', 503: 'Ƿ', 504: 'Ǹ', 505: 'ǹ', 506: 'Ǻ', 507: 'ǻ', 508: 'Ǽ', 509: 'ǽ', 510: 'Ǿ', 511: 'ǿ'}}\n"
     ]
    }
   ],
   "source": [
    "submats = { c: np.zeros( ( c , c ) ) for c in charsets }\n",
    "#change the character number to an ascii character\n",
    "colmap = { c:{ i: chr(i) for i in range( c ) } for c in charsets }\n",
    "revcolmap = { c:{ chr(i): i for i in range( c ) } for c in charsets }\n",
    "print( colmap )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "for rep in tqdm.tqdm(reps.repId.unique() ):\n",
    "    #load the all vs all aln\n",
    "    aln_df = pd.read_tsv('struct_align/' + rep + '/allvall.csv')\n",
    "    #load the embedding of the structures\n",
    "    q = aln_df['s1'].unique()\n",
    "    t = aln_df['s2'].unique()\n",
    "    \n",
    "    for q in aln_df['s1'].unique():\n",
    "        for t in aln_df['s2'].unique():\n",
    "            if q != t:\n",
    "                #align the structures\n",
    "                aln = aln_df[ (aln_df['s1'] == q) & (aln_df['s2'] == t) ]\n",
    "                qaln = aln.qaln\n",
    "                taln = aln.taln\n",
    "                for charset in charsets:\n",
    "                    #derive the embeddings\n",
    "                    \n",
    "                    with h5py.File('aln_embeds/' + rep + '.h5' , 'r') as hf:\n",
    "                        q_embeds = iter(hf[q][charset].decode())\n",
    "                        t_embeds = iter(hf[q][charset].decode())\n",
    "                    \n",
    "                    #transfer the alignments to the embeddings\n",
    "                    qaln_ft2 = ''.join([ next(q_embeds) if x == '-' else x for x in qaln ])\n",
    "                    taln_ft2 = ''.join([ next(t_embeds) if x == '-' else x for x in taln ])\n",
    "                    \n",
    "                    alnzip = zip( qaln_ft2 , taln_ft2 )\n",
    "                    for qchar, tchar in alnzip:\n",
    "                        if qchar != '-' and tchar != '-':\n",
    "                            submats[charset][ colmap[charset][qchar] , colmap[charset][tchar] ] += 1\n",
    "                            submats[charset][ colmap[charset][tchar] , colmap[charset][qchar] ] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save the submats in raw form\n",
    "for charset in charsets:\n",
    "    np.save( 'submats/' + str(charset) + '.npy' , submats[charset] )\n",
    "    with open( 'submats/' + str(charset) + '.txt' , 'w' ) as f:\n",
    "        for i in range( charset ):\n",
    "            f.write( '\\t'.join( [ str(submats[charset][i,j]) for j in range( charset ) ] ) + '\\n' )\n",
    "\n",
    "#normalize the submats rows and columns to sum to 1\n",
    "for charset in charsets:\n",
    "    rowsums = submats[charset].sum( axis=1 )\n",
    "    colsums = submats[charset].sum( axis=0 )\n",
    "    for i in range( charset ):\n",
    "        submats[charset][i,:] = submats[charset][i,:] / rowsums[i]\n",
    "        submats[charset][:,i] = submats[charset][:,i] / colsums[i]\n",
    "\n",
    "#save the submats in normalized form\n",
    "for charset in charsets:\n",
    "    np.save( 'submats/' + str(charset) + '_norm.npy' , submats[charset] )\n",
    "    with open( 'submats/' + str(charset) + '_norm.txt' , 'w' ) as f:\n",
    "        for i in range( charset ):\n",
    "            f.write( '\\t'.join( [ str(submats[charset][i,j]) for j in range( charset ) ] ) + '\\n' )\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
