{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimiye tree topologz with alphago tzpe agent strategz\n",
    "\n",
    "\n",
    "import gym\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the Environment\n",
    "class GraphEnvironment:\n",
    "    def __init__(self):\n",
    "        self.state = self.reset()\n",
    "        self.action_dim = 4  # Number of nodes + 1 for the \"end\" action\n",
    "\n",
    "    def reset(self):\n",
    "        # Define the initial graph state\n",
    "        x = torch.tensor([[1], [2], [3]], dtype=torch.float)  # Example node features\n",
    "        edge_index = torch.tensor([[0, 1], [1, 2], [2, 0]], dtype=torch.long).t().contiguous()\n",
    "        self.state = Data(x=x, edge_index=edge_index)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        if action == self.action_dim - 1:  # \"end\" action\n",
    "            done = True\n",
    "            reward = -torch.sum(self.state.x).item()  # Example reward function\n",
    "        else:\n",
    "            # Modify the graph based on the action\n",
    "            self.state.x[action] += 1\n",
    "            reward = -torch.sum(self.state.x).item()  # Example reward function\n",
    "            done = torch.sum(self.state.x) > 10  # Example termination condition\n",
    "        return self.state, reward, done\n",
    "\n",
    "\n",
    "env = GraphEnvironment()\n",
    "input_dim = env.reset().num_node_features\n",
    "hidden_dim = 64\n",
    "output_dim = hidden_dim\n",
    "action_dim = env.action_dim  # Number of nodes + 1 for the \"end\" action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a graph environment class for phylogenetic trees\n",
    "import dendropy\n",
    "import torch\n",
    "\n",
    "def sparse2pairs(sparsemat, matrows = None):\n",
    "    '''\n",
    "    This functino takes a sparse matrix and returns a list of pairs of the non zero entries\n",
    "    args:\n",
    "        sparsemat: a sparse matrix\n",
    "        matrows: a list of the matrix rows to keep\n",
    "    Returns:    \n",
    "        a list of pairs of the non zero entries\n",
    "    '''\n",
    "    if matrows :\n",
    "        sparsemat = sparsemat[matrows,:]\n",
    "        sparsemat = sparsemat[:,matrows]\n",
    "    sparsemat = scipy.sparse.find(sparsemat)\n",
    "    return np.vstack([sparsemat[0],sparsemat[1]])\n",
    "\n",
    "\n",
    "class PhyloTreeEnvironment:\n",
    "    def __init__(self , newick_tree):\n",
    "        self.state = self.reset()\n",
    "        self.action_dim = 4  # Number of nodes + 1 for the \"end\" action\n",
    "        self.newick_tree = newick_tree\n",
    "        # Define the initial graph state\n",
    "        self.tree = dendropy.Tree.get(data=newick_tree, schema=\"newick\")\n",
    "        #label the nodes with a matrix row index\n",
    "        for i, node in enumerate(self.tree.preorder_node_iter()):\n",
    "            node.matrow = i\n",
    "        N = len(tree.nodes())\n",
    "        #mimic the fitch algo\n",
    "        #propagate up and down in separate graphs\n",
    "        index_up = np.vstack([ [n.matrow, c.matrow ] for n in tree.nodes() for c in n.child_nodes()])\n",
    "        index_down = np.vstack([ [c.matrow, n.matrow ] for n in tree.nodes() for c in n.child_nodes()])\n",
    "        connectmat_up = scipy.sparse.lil_matrix(( N ,  N ) )\n",
    "        connectmat_down = scipy.sparse.lil_matrix(( N ,  N ) )\n",
    "        connectmat_up[index_up[:,0],index_up[:,1]] = 1 \n",
    "        connectmat_down[index_down[:,0],index_down[:,1]] = 1 \n",
    "        diag = [[n,n] for n in range(N)]\n",
    "        connectmat_diag=scipy.sparse.lil_matrix(( N ,  N ) )\n",
    "        connectmat_diag[diag,diag] = 1 \n",
    "        #create a pytorch geometric graph\n",
    "        self.connectmat_down = torch.tensor( sparse2pairs(connectmat_down) , dtype=torch.long) \n",
    "        self.connectmat_up = torch.tensor( sparse2pairs(connectmat_up) , dtype=torch.long)\n",
    "        self.connectmat_diag = torch.tensor( sparse2pairs(connectmat_diag) , dtype=torch.long)\n",
    "\n",
    "    def tree2graph(self):\n",
    "        index_up = np.vstack([ [n.matrow, c.matrow ] for n in tree.nodes() for c in n.child_nodes()])\n",
    "        index_down = np.vstack([ [c.matrow, n.matrow ] for n in tree.nodes() for c in n.child_nodes()])\n",
    "        connectmat_up = scipy.sparse.lil_matrix(( N ,  N ) )\n",
    "        connectmat_down = scipy.sparse.lil_matrix(( N ,  N ) )\n",
    "        connectmat_up[index_up[:,0],index_up[:,1]] = 1 \n",
    "        connectmat_down[index_down[:,0],index_down[:,1]] = 1 \n",
    "        diag = [[n,n] for n in range(N)]\n",
    "        connectmat_diag=scipy.sparse.lil_matrix(( N ,  N ) )\n",
    "        connectmat_diag[diag,diag] = 1 \n",
    "        #create a pytorch geometric graph\n",
    "        self.connectmat_down = torch.tensor( sparse2pairs(connectmat_down) , dtype=torch.long) \n",
    "        self.connectmat_up = torch.tensor( sparse2pairs(connectmat_up) , dtype=torch.long)\n",
    "        self.connectmat_diag = torch.tensor( sparse2pairs(connectmat_diag) , dtype=torch.long)\n",
    "\n",
    "    def step(self, action):\n",
    "        #cut and graft a node\n",
    "\n",
    "        #reinit the graph\n",
    "        \n",
    "\n",
    "    def cut_and_grat(self, cutnode , graftnode ):\n",
    "        #use dendropy to cut and graft a node on a branch\n",
    "\n",
    "        #cut the node\n",
    "        parent = cutnode.parent_node\n",
    "        parent.remove_child(cutnode)\n",
    "        up_one = parent.parent_node\n",
    "        #gab the other child of the parent node\n",
    "        other_child = parent.child_nodes()[0]\n",
    "        up_one.add_child(other_child)\n",
    "\n",
    "        #collapse the branch where the node was cut\n",
    "\n",
    "        #make the dendropy tree from the graph\n",
    "\n",
    "\n",
    "\n",
    "        #graft the node on the branch leading to the graftnode\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        # Define the initial graph state\n",
    "        x = torch.tensor([[1], [2], [3]], dtype=torch.float)\n",
    "\n",
    "    def label_internal_nodes(self , evomodel = None ):\n",
    "        tree = evomodel(self.tree )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dendropy\n",
      "  Downloading DendroPy-5.0.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: setuptools in /home/dmoi/miniconda3/envs/tf_gpu/lib/python3.8/site-packages (from dendropy) (69.2.0)\n",
      "Downloading DendroPy-5.0.0-py3-none-any.whl (458 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.0/459.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dendropy\n",
      "Successfully installed dendropy-5.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dendropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tree:\n",
      "((A,B,(C,D)),(E,(F,G)));\n",
      "\n",
      "                         /--------------------------------------------------- A\n",
      "                         |                                                     \n",
      "/------------------------+--------------------------------------------------- B\n",
      "|                        |                                                     \n",
      "|                        |                         /------------------------- C\n",
      "+                        \\-------------------------+                           \n",
      "|                                                  \\------------------------- D\n",
      "|                                                                              \n",
      "|                        /--------------------------------------------------- E\n",
      "\\------------------------+                                                     \n",
      "                         |                         /------------------------- F\n",
      "                         \\-------------------------+                           \n",
      "                                                   \\------------------------- G\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Node with label C not found in the tree.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree\u001b[38;5;241m.\u001b[39mas_string(schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewick\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree\u001b[38;5;241m.\u001b[39mas_ascii_plot())\n\u001b[0;32m---> 80\u001b[0m \u001b[43mcut_and_graft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModified Tree:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(tree\u001b[38;5;241m.\u001b[39mas_string(schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewick\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[11], line 66\u001b[0m, in \u001b[0;36mcut_and_graft\u001b[0;34m(tree, source_node_label, target_node_label)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcut_and_graft\u001b[39m(tree, source_node_label, target_node_label):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Cut a subtree from the tree and graft it onto the same tree while maintaining binary tree structure.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m        target_node_label (str): The label of the node where the subtree will be grafted.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     subtree, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcut_subtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_node_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     graft_subtree(tree, target_node_label, subtree)\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mcut_subtree\u001b[0;34m(tree, node_label)\u001b[0m\n\u001b[1;32m     16\u001b[0m node \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mfind_node_with_label(node_label)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode with label \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the tree.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m parent_node \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparent_node\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Node with label C not found in the tree."
     ]
    }
   ],
   "source": [
    "import dendropy\n",
    "from dendropy import Tree, Node\n",
    "\n",
    "def cut_subtree(tree, node_label):\n",
    "    \"\"\"\n",
    "    Cut a subtree from a given tree at the specified node label.\n",
    "    \n",
    "    Args:\n",
    "        tree (Tree): The tree to cut from.\n",
    "        node_label (str): The label of the node where the subtree will be cut.\n",
    "    \n",
    "    Returns:\n",
    "        Tree: The subtree that was cut.\n",
    "        Node: The original node where the subtree was cut.\n",
    "    \"\"\"\n",
    "    node = tree.find_node_with_label(node_label)\n",
    "    if node is None:\n",
    "        raise ValueError(f\"Node with label {node_label} not found in the tree.\")\n",
    "    \n",
    "    parent_node = node.parent_node\n",
    "    if parent_node is None:\n",
    "        raise ValueError(\"Cannot cut the root node.\")\n",
    "    \n",
    "    parent_node.remove_child(node)\n",
    "    subtree = Tree(seed_node=node)\n",
    "    \n",
    "    return subtree, parent_node\n",
    "\n",
    "def graft_subtree(tree, graft_point_label, subtree):\n",
    "    \"\"\"\n",
    "    Graft a subtree onto a target tree at the specified graft point label while ensuring binary tree constraints.\n",
    "    \n",
    "    Args:\n",
    "        tree (Tree): The tree to graft onto.\n",
    "        graft_point_label (str): The label of the node where the subtree will be grafted.\n",
    "        subtree (Tree): The subtree to graft.\n",
    "    \"\"\"\n",
    "    graft_point_node = tree.find_node_with_label(graft_point_label)\n",
    "    if graft_point_node is None:\n",
    "        raise ValueError(f\"Node with label {graft_point_label} not found in the tree.\")\n",
    "    \n",
    "    if len(graft_point_node.child_nodes()) < 2:\n",
    "        graft_point_node.add_child(subtree.seed_node)\n",
    "    else:\n",
    "        # Create a new internal node to maintain binary tree structure\n",
    "        new_internal_node = Node()\n",
    "        new_internal_node.add_child(subtree.seed_node)\n",
    "        \n",
    "        # Move one of the existing children to the new internal node\n",
    "        existing_child = graft_point_node.child_nodes()[1]\n",
    "        graft_point_node.remove_child(existing_child)\n",
    "        new_internal_node.add_child(existing_child)\n",
    "        \n",
    "        # Add the new internal node to the graft point node\n",
    "        graft_point_node.add_child(new_internal_node)\n",
    "\n",
    "def cut_and_graft(tree, source_node_label, target_node_label):\n",
    "    \"\"\"\n",
    "    Cut a subtree from the tree and graft it onto the same tree while maintaining binary tree structure.\n",
    "    \n",
    "    Args:\n",
    "        tree (Tree): The tree to modify.\n",
    "        source_node_label (str): The label of the node where the subtree will be cut.\n",
    "        target_node_label (str): The label of the node where the subtree will be grafted.\n",
    "    \"\"\"\n",
    "    subtree, _ = cut_subtree(tree, source_node_label)\n",
    "    graft_subtree(tree, target_node_label, subtree)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    tree_newick = \"((A,B,(C,D)),(E,(F,G)));\"\n",
    "\n",
    "    tree = Tree.get(data=tree_newick, schema=\"newick\")\n",
    "    \n",
    "    \n",
    "    print(\"Original Tree:\")\n",
    "    print(tree.as_string(schema=\"newick\"))\n",
    "    print(tree.as_ascii_plot())\n",
    "   \n",
    "    cut_and_graft(tree, \"C\", \"G\")\n",
    "    print(\"Modified Tree:\")\n",
    "    print(tree.as_string(schema=\"newick\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the Graph Neural Network\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Define the DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, gnn, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        self.gnn = gnn\n",
    "        self.fc = nn.Linear(state_dim, action_dim)\n",
    "        self.target_gnn = gnn\n",
    "        self.target_fc = nn.Linear(state_dim, action_dim)\n",
    "        self.update_target_model()\n",
    "        \n",
    "        self.optimizer = optim.Adam(list(self.gnn.parameters()) + list(self.fc.parameters()), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_gnn.load_state_dict(self.gnn.state_dict())\n",
    "        self.target_fc.load_state_dict(self.fc.state_dict())\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_dim)\n",
    "        with torch.no_grad():\n",
    "            state = self.gnn(state)\n",
    "            q_values = self.fc(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            with torch.no_grad():\n",
    "                next_state = self.gnn(next_state)\n",
    "                target = reward\n",
    "                if not done:\n",
    "                    target += self.gamma * torch.max(self.target_fc(next_state)).item()\n",
    "            state = self.gnn(state)\n",
    "            target_f = self.fc(state)\n",
    "            target_f[action] = target\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(target_f, self.fc(state))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "gnn = GCN(input_dim, hidden_dim, output_dim)\n",
    "agent = DQNAgent(gnn, output_dim, action_dim)\n",
    "\n",
    "episodes = 1000\n",
    "batch_size = 64\n",
    "\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            print(f\"Episode {e+1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.2}\")\n",
    "        agent.replay(batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
