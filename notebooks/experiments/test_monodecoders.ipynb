{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8502a6b",
   "metadata": {},
   "source": [
    "# Test MonoDecoders: Sequence and Geometry\n",
    "This notebook replicates the training logic from `learn.py` using the decoder in `mono_decoders.py` for amino acid and geometry prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6586f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5103ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248b7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "from src import pdbgraph\n",
    "from src import foldtree2_ecddcd as ft2\n",
    "from src.mono_decoders import MultiMonoDecoder\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d142a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Data setup\n",
    "datadir = '../../datasets/foldtree2/'\n",
    "dataset_path = 'structs_traininffttest.h5'\n",
    "converter = pdbgraph.PDB2PyG(aapropcsv='config/aaindex1.csv')\n",
    "struct_dat = pdbgraph.StructureDataset(dataset_path)\n",
    "train_loader = DataLoader(struct_dat, batch_size=5, shuffle=True, num_workers=4)\n",
    "data_sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample: HeteroDataBatch(\n",
      "  identifier=[5],\n",
      "  AA={\n",
      "    x=[1323, 20],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  R_true={\n",
      "    x=[1323, 3, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  bondangles={\n",
      "    x=[1323, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  coords={\n",
      "    x=[1323, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier1di={\n",
      "    x=[1323, 80],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier1dr={\n",
      "    x=[1323, 80],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier2di={\n",
      "    x=[5, 1300],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier2dr={\n",
      "    x=[5, 1300],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  godnode={\n",
      "    x=[5, 5],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  godnode4decoder={\n",
      "    x=[5, 5],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  plddt={\n",
      "    x=[1323, 1],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  positions={\n",
      "    x=[1323, 256],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  res={\n",
      "    x=[1323, 857],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  t_true={\n",
      "    x=[1323, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  (godnode4decoder, informs, res)={ edge_index=[2, 1323] },\n",
      "  (godnode, informs, res)={ edge_index=[2, 1323] },\n",
      "  (res, backbone, res)={\n",
      "    edge_index=[2, 2641],\n",
      "    edge_attr=[1318],\n",
      "  },\n",
      "  (res, backbonerev, res)={\n",
      "    edge_index=[2, 2641],\n",
      "    edge_attr=[1318],\n",
      "  },\n",
      "  (res, contactPoints, res)={\n",
      "    edge_index=[2, 9804],\n",
      "    edge_attr=[9804],\n",
      "  },\n",
      "  (res, hbond, res)={\n",
      "    edge_index=[2, 1700],\n",
      "    edge_attr=[1700],\n",
      "  },\n",
      "  (res, informs, godnode)={ edge_index=[2, 1323] },\n",
      "  (res, informs, godnode4decoder)={ edge_index=[2, 1323] },\n",
      "  (res, window, res)={\n",
      "    edge_index=[2, 2626],\n",
      "    edge_attr=[2626],\n",
      "  },\n",
      "  (res, windowrev, res)={\n",
      "    edge_index=[2, 1318],\n",
      "    edge_attr=[1318],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Data sample:', data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc573dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk1_Encoder(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (res_contactPoints_res): TransformerConv(400, 400, heads=5)\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): GraphNorm(400)\n",
      "  )\n",
      "  (bn): BatchNorm1d(857, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.01, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (ffin): Sequential(\n",
      "    (0): Linear(in_features=1017, out_features=800, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=800, out_features=400, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): DynamicTanh(normalized_shape=400, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (0): DynamicTanh(normalized_shape=400, alpha_init_value=0.5, channels_last=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): DynamicTanh(normalized_shape=200, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (out_dense): Sequential(\n",
      "    (0): Linear(in_features=220, out_features=200, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=100, out_features=20, bias=True)\n",
      "    (5): GELU(approximate='none')\n",
      "    (6): DynamicTanh(normalized_shape=20, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (vector_quantizer): VectorQuantizerEMA(\n",
      "    (embeddings): Embedding(40, 20)\n",
      "  )\n",
      ")\n",
      "Initializing decoder for task: sequence_transformer\n",
      "False True False False False\n",
      "200 1 2 0.005\n",
      "Initializing decoder for task: contacts\n",
      "False False True False False\n",
      "MultiMonoDecoder(\n",
      "  (decoders): ModuleDict(\n",
      "    (sequence_transformer): Transformer_AA_Decoder(\n",
      "      (input_proj): Sequential(\n",
      "        (0): DynamicTanh(normalized_shape=276, alpha_init_value=0.5, channels_last=True)\n",
      "        (1): Linear(in_features=276, out_features=200, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Dropout(p=0.005, inplace=False)\n",
      "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "      )\n",
      "      (transformer_encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-1): 2 x TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=200, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.005, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=200, bias=True)\n",
      "            (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.005, inplace=False)\n",
      "            (dropout2): Dropout(p=0.005, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (lin): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "        (7): Linear(in_features=100, out_features=20, bias=True)\n",
      "        (8): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (contacts): HeteroGAE_geo_Decoder(\n",
      "      (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convs): ModuleList(\n",
      "        (0-2): 3 x HeteroConv(num_relations=4)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-2): 3 x GraphNorm(200)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.005, inplace=False)\n",
      "      (jk): JumpingKnowledge(cat)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (lin): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): DynamicTanh(normalized_shape=600, alpha_init_value=0.5, channels_last=True)\n",
      "        (2): Linear(in_features=600, out_features=200, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (7): GELU(approximate='none')\n",
      "        (8): DynamicTanh(normalized_shape=200, alpha_init_value=0.5, channels_last=True)\n",
      "      )\n",
      "      (contact_mlp): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Linear(in_features=100, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "ndim = data_sample['res'].x.shape[1]\n",
    "ndim_godnode = data_sample['godnode'].x.shape[1]\n",
    "ndim_fft2i = data_sample['fourier2di'].x.shape[1]\n",
    "ndim_fft2r = data_sample['fourier2dr'].x.shape[1]\n",
    "\n",
    "num_embeddings = 40\n",
    "embedding_dim = 20\n",
    "hidden_size = 200\n",
    "\n",
    "se3transfomer = False  # Set to True for SE3Transformer, False for GNN\n",
    "\n",
    "if se3transfomer == True:\n",
    "\n",
    "\tencoder = se3e.se3_Encoder(\n",
    "\t\tin_channels=ndim,\n",
    "\t\thidden_channels=[hidden_size//2, hidden_size//2],\n",
    "\t\tout_channels=embedding_dim,\n",
    "\t\tmetadata={'edge_types': [('res','contactPoints','res')]},\n",
    "\t\tnum_embeddings=num_embeddings,\n",
    "\t\tcommitment_cost=0.9,\n",
    "\t\tedge_dim=1,\n",
    "\t\tencoder_hidden=hidden_size,\n",
    "\t\tEMA=True,\n",
    "\t\tnheads=5,\n",
    "\t\tdropout_p=0.005,\n",
    "\t\treset_codes=False,\n",
    "\t\tflavor='transformer',\n",
    "\t\tfftin=True\n",
    "\t)\t\t\t\n",
    "else:\n",
    "\tencoder = ft2.mk1_Encoder(\n",
    "\t\tin_channels=ndim,\n",
    "\t\thidden_channels=[hidden_size*2, hidden_size*2],\n",
    "\t\tout_channels=embedding_dim,\n",
    "\t\tmetadata={'edge_types': [('res','contactPoints','res')]},\n",
    "\t\tnum_embeddings=num_embeddings,\n",
    "\t\tcommitment_cost=0.9,\n",
    "\t\tedge_dim=1,\n",
    "\t\tencoder_hidden=hidden_size,\n",
    "\t\tEMA=True,\n",
    "\t\tnheads=5,\n",
    "\t\tdropout_p=0.01,\n",
    "\t\treset_codes=False,\n",
    "\t\tflavor='transformer',\n",
    "\t\tfftin=True\n",
    "\t)\n",
    "\n",
    "\n",
    "print(encoder)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# MultiMonoDecoder for sequence and geometry\n",
    "mono_configs = {\n",
    "\t'sequence_transformer': {\n",
    "\t\t'in_channels': {'res': embedding_dim},\n",
    "\t\t'xdim': 20,\n",
    "\t\t'concat_positions': True,\n",
    "\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*3 , ('res','backbonerev','res'): [hidden_size]*3},\n",
    "\t\t'layers': 2,\n",
    "\t\t'AAdecoder_hidden': [hidden_size, hidden_size, hidden_size//2],\n",
    "\t\t'amino_mapper': converter.aaindex,\n",
    "\t\t'flavor': 'sage',\n",
    "\t\t'nheads': 1,\n",
    "\t\t'dropout': 0.005,\n",
    "\t\t'normalize': True,\n",
    "\t\t'residual': False\n",
    "\t},\n",
    "\t\n",
    "\t'contacts': {\n",
    "\t\t'in_channels': {'res': embedding_dim, 'godnode4decoder': ndim_godnode, 'foldx': 23 ,  'fft2r': ndim_fft2r, 'fft2i': ndim_fft2i},\n",
    "\t\t'concat_positions': True,\n",
    "\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*4, ('res','backbonerev','res'): [hidden_size]*4, ('res','informs','godnode4decoder'): [hidden_size]*4 , ('godnode4decoder','informs','res'): [hidden_size]*4},\n",
    "\t\t'layers': 3,\n",
    "\t\t'FFT2decoder_hidden': [hidden_size, hidden_size, hidden_size],\n",
    "\t\t'contactdecoder_hidden': [hidden_size, hidden_size//2],\n",
    "\t\t'nheads': 1,\n",
    "\t\t'Xdecoder_hidden': [hidden_size, hidden_size,  hidden_size ],\n",
    "\t\t'metadata': converter.metadata,\n",
    "\t\t'flavor': 'mfconv',\n",
    "\t\t'dropout': 0.005,\n",
    "\t\t'output_fft': False,\n",
    "        'output_rt':False,\n",
    "\t\t'normalize': True,\n",
    "\t\t'residual': False,\n",
    "\t\t'contact_mlp': True\n",
    "\n",
    "\t}\n",
    "}\n",
    "decoder = MultiMonoDecoder( configs=mono_configs)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24b3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiMonoDecoder(\n",
       "  (decoders): ModuleDict(\n",
       "    (sequence_transformer): Transformer_AA_Decoder(\n",
       "      (input_proj): Sequential(\n",
       "        (0): DynamicTanh(normalized_shape=276, alpha_init_value=0.5, channels_last=True)\n",
       "        (1): Linear(in_features=276, out_features=200, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.005, inplace=False)\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "      )\n",
       "      (transformer_encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=200, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.005, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=200, bias=True)\n",
       "            (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.005, inplace=False)\n",
       "            (dropout2): Dropout(p=0.005, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lin): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
       "        (7): Linear(in_features=100, out_features=20, bias=True)\n",
       "        (8): LogSoftmax(dim=1)\n",
       "      )\n",
       "    )\n",
       "    (contacts): HeteroGAE_geo_Decoder(\n",
       "      (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convs): ModuleList(\n",
       "        (0-2): 3 x HeteroConv(num_relations=4)\n",
       "      )\n",
       "      (norms): ModuleList(\n",
       "        (0-2): 3 x GraphNorm(200)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.005, inplace=False)\n",
       "      (jk): JumpingKnowledge(cat)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (lin): Sequential(\n",
       "        (0): Dropout(p=0.005, inplace=False)\n",
       "        (1): DynamicTanh(normalized_shape=600, alpha_init_value=0.5, channels_last=True)\n",
       "        (2): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): DynamicTanh(normalized_shape=200, alpha_init_value=0.5, channels_last=True)\n",
       "      )\n",
       "      (contact_mlp): Sequential(\n",
       "        (0): Dropout(p=0.005, inplace=False)\n",
       "        (1): Linear(in_features=400, out_features=200, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=100, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop (demo, similar to learn.py)\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "num_epochs = 50  # For demonstration, keep small\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "edgeweight = 0.01\n",
    "xweight = .1\n",
    "fft2weight = 0.01\n",
    "vqweight = 0.0001\n",
    "clip_grad = True\n",
    "encoder.device = device\n",
    "encoder.train()\n",
    "decoder.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8583d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118, 857]) x_dict[res] shape\n",
      "z_quantized shape: torch.Size([118, 20])\n",
      "vq_loss: tensor(0.9754, device='cuda:1', grad_fn=<SubBackward0>)\n",
      "x shape: torch.Size([118, 20])\n",
      "x_dict keys: dict_keys(['AA', 'R_true', 'bondangles', 'coords', 'fourier1di', 'fourier1dr', 'fourier2di', 'fourier2dr', 'godnode', 'godnode4decoder', 'plddt', 'positions', 'res', 't_true'])\n",
      "edge_index_dict keys: dict_keys([('godnode4decoder', 'informs', 'res'), ('godnode', 'informs', 'res'), ('res', 'backbone', 'res'), ('res', 'backbonerev', 'res'), ('res', 'contactPoints', 'res'), ('res', 'hbond', 'res'), ('res', 'informs', 'godnode'), ('res', 'informs', 'godnode4decoder'), ('res', 'window', 'res'), ('res', 'windowrev', 'res')])\n",
      "Encoded z shape: torch.Size([118, 20])\n"
     ]
    }
   ],
   "source": [
    "#get one sample from the dataloader\n",
    "train_loader = DataLoader(struct_dat, batch_size=1, shuffle=True, num_workers=4)\n",
    "data_sample = next(iter(train_loader))\n",
    "data = data_sample.to(device)\n",
    "optimizer.zero_grad()\n",
    "z, vqloss = encoder(data , debug = True)\n",
    "print('Encoded z shape:', z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104038db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import PDB\n",
    "from Bio.PDB import PDBParser\n",
    "from src.AFDB_tools import \tgrab_struct\n",
    "\n",
    "def getCAatoms(pdb_file):\n",
    "\tparser = PDBParser(QUIET=True)\n",
    "\t# Parse the structure\n",
    "\tstructure = parser.get_structure('structure', pdb_file)\n",
    "\tca_atoms = []\n",
    "\tfor model in structure:\n",
    "\t\tfor chain in model:\n",
    "\t\t\tfor residue in chain :\n",
    "\t\t\t\tif 'CA' in residue and PDB.is_aa(residue) :\n",
    "\t\t\t\t\tca_atoms.append(residue['CA'])\n",
    "\treturn ca_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60378468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get aa and contacts\n",
    "\n",
    "from torch_geometric.data import DataLoader , HeteroData\n",
    "from scipy import sparse\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_backbone(naa):\n",
    "\tbackbone_mat = np.zeros((naa, naa))\n",
    "\tbackbone_rev_mat = np.zeros((naa, naa))\n",
    "\tnp.fill_diagonal(backbone_mat[1:], 1)\n",
    "\tnp.fill_diagonal(backbone_rev_mat[:, 1:], 1)\n",
    "\treturn backbone_mat, backbone_rev_mat\n",
    "\n",
    "def sparse2pairs(sparsemat):\n",
    "\tsparsemat = sparse.find(sparsemat)\n",
    "\treturn np.vstack([sparsemat[0],sparsemat[1]])\n",
    "\n",
    "def decoder_reconstruction2aa( ords , device, verbose = False):\n",
    "\tdecoder.eval()\n",
    "\tprint(ords)\n",
    "\tz = encoder.vector_quantizer.embeddings( ords  ).to('cpu')\n",
    "\tedge_index = torch.tensor( [ [i,j] for i in range(z.shape[0]) for j in range(z.shape[0]) ]  , dtype = torch.long).T\n",
    "\tgodnode_index = np.vstack([np.zeros(z.shape[0]), [ i for i in range(z.shape[0]) ] ])\n",
    "\tgodnode_rev = np.vstack([ [ i for i in range(z.shape[0]) ] , np.zeros(z.shape[0]) ])\n",
    "\t#generate a backbone for the decoder\n",
    "\tdata = HeteroData()\n",
    "\tdata['res'].x = z\n",
    "\tbackbone, backbone_rev = get_backbone( z.shape[0] )\n",
    "\tbackbone = sparse.csr_matrix(backbone)\n",
    "\tbackbone_rev = sparse.csr_matrix(backbone_rev)\n",
    "\tbackbone = sparse2pairs(backbone)\n",
    "\tbackbone_rev = sparse2pairs(backbone_rev)\n",
    "\tpositional_encoding = converter.get_positional_encoding( z.shape[0] , 256 )\n",
    "\tprint( 'positional encoding shape:', positional_encoding.shape )\n",
    "\tdata['res'].batch = torch.tensor([0 for i in range(z.shape[0])], dtype=torch.long)\n",
    "\tdata['positions'].x = torch.tensor( positional_encoding, dtype=torch.float32)\n",
    "\tdata['res','backbone','res'].edge_index = torch.tensor(backbone,  dtype=torch.long )\n",
    "\tdata[ 'res' , 'backbone_rev' , 'res'].edge_index = torch.tensor(backbone_rev, dtype=torch.long)\n",
    "\tprint( data['res'].x.shape )\n",
    "\t#add the godnode\n",
    "\tdata['godnode'].x = torch.tensor(np.ones((1,5)), dtype=torch.float32)\n",
    "\tdata['godnode4decoder'].x = torch.tensor(np.ones((1,5)), dtype=torch.float32)\n",
    "\tdata['godnode4decoder', 'informs', 'res'].edge_index = torch.tensor(godnode_index, dtype=torch.long)\n",
    "\tdata['res', 'informs', 'godnode4decoder'].edge_index = torch.tensor(godnode_rev, dtype=torch.long)\n",
    "\tdata['res', 'informs', 'godnode'].edge_index = torch.tensor(godnode_rev, dtype=torch.long)\n",
    "\tedge_index = edge_index.to( device )\n",
    "\tprint( data )\n",
    "\tdata = data.to( device )\n",
    "\tallpairs = torch.tensor( [ [i,j] for i in range(z.shape[0]) for j in range(z.shape[0]) ]  , dtype = torch.long).T\n",
    "\tout = decoder( data , allpairs ) \n",
    "\n",
    "\trecon_x = out['aa'] if 'aa' in out else None\n",
    "\tedge_probs = out['edge_probs'] if 'edge_probs' in out else None\n",
    "\n",
    "\tprint( edge_probs.shape)\n",
    "\ttry:\n",
    "\t\tamino_map = decoder.decoders['sequence'].amino_acid_indices\n",
    "\texcept:\n",
    "\t\tamino_map = decoder.decoders['sequence_transformer'].amino_acid_indices\n",
    "\t\tprint('Using amino_acid_indices_dict instead of amino_acid_indices')\n",
    "\trevmap_aa = { v:k for k,v in amino_map.items() }\n",
    "\tedge_probs = edge_probs.reshape((z.shape[0], z.shape[0]))\n",
    "\tif verbose == True:\n",
    "\t\tprint( recon_x )\n",
    "\t\tprint( edge_probs )\n",
    "\taastr = ''.join(revmap_aa[int(idx.item())] for idx in recon_x.argmax(dim=1) )\n",
    "\treturn aastr ,edge_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                         | 0/500 [00:00<?, ?it/s]/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "Epoch 0:   0%|                                                                                                         | 0/500 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontactPoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_dict\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontactPoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_index_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m \tedgeloss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrecon_loss_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplddt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge_probs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m \tedgeloss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/projects/foldtree2/src/losses/losses.py:200\u001b[0m, in \u001b[0;36mrecon_loss_diag\u001b[0;34m(data, pos_edge_index, decoder, poslossmod, neglossmod, plddt, offdiag, nclamp, key)\u001b[0m\n\u001b[1;32m    198\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m c1 \u001b[38;5;241m&\u001b[39m c2\n\u001b[1;32m    199\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure mask is 1D\t\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \tneg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mneg_loss\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    202\u001b[0m neg_loss \u001b[38;5;241m=\u001b[39m neg_loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m poslossmod\u001b[38;5;241m*\u001b[39mpos_loss \u001b[38;5;241m+\u001b[39m neglossmod\u001b[38;5;241m*\u001b[39mneg_loss, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(struct_dat, batch_size=10, shuffle=True, num_workers=4)\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "from losses.losses import recon_loss_diag , aa_reconstruction_loss\n",
    "for epoch in range(num_epochs):\n",
    "\ttotal_loss_x = 0\n",
    "\ttotal_loss_edge = 0\n",
    "\ttotal_vq = 0\n",
    "\ttotal_loss_fft2 = 0\n",
    "\tfor data in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "\t\tdata = data.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tz, vqloss = encoder(data)\n",
    "\t\tdata['res'].x = z\n",
    "\t\t# For demonstration, only sequence and contacts tasks\n",
    "\t\tout = decoder(data, None)\n",
    "\t\trecon_x = out['aa'] if isinstance(out, dict) and 'aa' in out else out[0] if isinstance(out, (list, tuple)) else None\n",
    "\t\tfft2_x = out['fft2pred'] if isinstance(out, dict) and 'fft2pred' in out else out[1] if isinstance(out, (list, tuple)) else None\n",
    "\t\t# Edge loss: use contactPoints if available\n",
    "\t\tedge_index = data.edge_index_dict['res', 'contactPoints', 'res'] if hasattr(data, 'edge_index_dict') and ('res', 'contactPoints', 'res') in data.edge_index_dict else None\n",
    "\t\tif edge_index is not None:\n",
    "\t\t\tedgeloss, _ = recon_loss_diag(data, edge_index, decoder, plddt=False, offdiag=False , key = 'edge_probs')\n",
    "\t\telse:\n",
    "\t\t\tedgeloss = torch.tensor(0.0, device=device)\n",
    "\t\txloss = aa_reconstruction_loss(data['AA'].x, recon_x)\n",
    "\t\tif fft2_x is not None:\n",
    "\t\t\tfft2loss = F.smooth_l1_loss(torch.cat( [ data['fourier2dr'].x ,data['fourier2di'].x ] ,axis = 1 ) , fft2_x )\n",
    "\t\telse:\n",
    "\t\t\tfft2loss = torch.tensor(0.0, device=device)\n",
    "\t\tloss = xweight * xloss + edgeweight * edgeloss + vqweight * vqloss + fft2loss* fft2weight\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\tif clip_grad:\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1.0)\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss_x += xloss.item()\n",
    "\t\ttotal_loss_edge += edgeloss.item()\n",
    "\t\ttotal_loss_fft2 += fft2loss.item()\n",
    "\t\ttotal_vq += vqloss.item() if isinstance(vqloss, torch.Tensor) else float(vqloss)\n",
    "\tscheduler.step(total_loss_x)\n",
    "\tprint(f\"Epoch {epoch}: AA Loss: {total_loss_x/len(train_loader):.4f}, Edge Loss: {total_loss_edge/len(train_loader):.4f}, VQ Loss: {total_vq/len(train_loader):.4f} , FFT2 Loss: {total_loss_fft2/len(train_loader):.4f}\")\n",
    "\n",
    "\tencoder.eval()\n",
    "\tdecoder.eval()\n",
    "\t\n",
    "\t# predict all vs all contacts for the last sample\n",
    "\tdata_sample = data_sample.to(device)\n",
    "\tz, vqloss = encoder(data_sample)\n",
    "\tprint('Encoded z shape:', z.shape)\n",
    "\tords = encoder.vector_quantizer.discretize_z(z.detach())\n",
    "\tzdiscrete = ords[0].detach()\n",
    "\tprint('Encoded zdiscrete shape:', zdiscrete.shape)\n",
    "\t\n",
    "\taastr, edge_probs = decoder_reconstruction2aa( zdiscrete , device, verbose=True)\n",
    "\t#show the distance matrix\n",
    "\tgrab_struct(str(data_sample.identifier[0]) , structfolder='tmp/')\n",
    "\t#find the total number of residues\n",
    "\tca_atoms = getCAatoms( 'tmp/' + str(data_sample.identifier[0]) + '.pdb')\n",
    "\tdist_mat = np.zeros((len(ca_atoms), len(ca_atoms)))\n",
    "\t\n",
    "\tfor i, res1 in enumerate(ca_atoms):\n",
    "\t\tfor j, res2 in enumerate(ca_atoms):\n",
    "\t\t\tif i < j:\n",
    "\t\t\t\tdist_mat[i, j] = np.linalg.norm(res1.coord - res2.coord)\n",
    "\tdist_mat += dist_mat.T  # Make it symmetric\n",
    "\tnp.fill_diagonal(dist_mat, 0)\n",
    "\t\n",
    "\tndistmat = dist_mat.copy()\n",
    "\tndistmat[dist_mat>10 ] = 0\n",
    "\tndistmat[dist_mat<=10 ] = 1\n",
    "\n",
    "\tfig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "\tim0 = axs[0].imshow(1 - edge_probs.detach().cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "\taxs[0].set_title(f\"Epoch {epoch} - Predicted Contacts for {data.identifier[0]}\")\n",
    "\tfig.colorbar(im0, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "\tim1 = axs[1].imshow(dist_mat, cmap='hot', interpolation='nearest')\n",
    "\taxs[1].set_title(f\"Epoch {epoch} - Distance Matrix for {data.identifier[0]}\")\n",
    "\tfig.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "\tim2 = axs[2].imshow(ndistmat, cmap='hot', interpolation='nearest')\n",
    "\taxs[2].set_title(f\"Epoch {epoch} - Distance Diff (Predicted vs True) for {data.identifier[0]}\")\n",
    "\tfig.colorbar(im2, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "\tencoder.train()\n",
    "\tdecoder.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8550e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete and models saved.\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "import pickle\n",
    "if not os.path.exists('models/'):\n",
    "\tos.makedirs('models/')\n",
    "with open('models/testdebug.pkl', 'wb') as f:\n",
    "\tpickle.dump([encoder,decoder], f)\n",
    "\n",
    "#save state\n",
    "import torch\n",
    "torch.save(encoder.state_dict(), 'models/encoder_testdebug.pth')\n",
    "torch.save(decoder.state_dict(), 'models/decoder_testdebug.pth')\n",
    "\n",
    "print(\"Training complete and models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a913d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencoded_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#grab the pdbs and get the total number of residues\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#ensure encoder produces fastas with the same residues as the pdbs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pdbs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(encoded_df.head())\n",
    "#grab the pdbs and get the total number of residues\n",
    "#ensure encoder produces fastas with the same residues as the pdbs\n",
    "pdbs = []\n",
    "for identifier in encoded_df.index:\n",
    "\tpdbs.append( str(identifier) + '.pdb' )\n",
    "encoded_df['pdb'] = pdbs\n",
    "for i in range(len(encoded_df)):\n",
    "\tidentifier = encoded_df.index[i]\n",
    "\tpdb_file = 'tmp/' + identifier + '.pdb'\n",
    "\tif not os.path.exists(pdb_file):\n",
    "\t\tgrab_struct(str(identifier), structfolder='tmp/')\n",
    "\tca_atoms = getCAatoms(pdb_file)\n",
    "\ttotal_residues = sum(len(atoms) for atoms in ca_atoms.values())\n",
    "\tencoded_df.at[identifier, 'total_residues'] = total_residues\n",
    "encoded_df['delta'] = encoded_df['length_ord'] - encoded_df['total_residues']\n",
    "assert (encoded_df['delta'] == 0).all(), \"Mismatch between sequence length and total residues in PDB files\"\n",
    "assert (encoded_df['length_ord'] == encoded_df['length_hex']).all(), \"Mismatch between ord and hex lengths\"\n",
    "assert (encoded_df['length_ord'] == encoded_df['length_seq']).all(), \"Mismatch between ord and sequence lengths\"\n",
    "assert (encoded_df['length_hex'] == encoded_df['length_seq']).all(), \"Mismatch between hex and sequence lengths\"\n",
    "print(\"All checks passed. Sequence lengths match PDB total residues and ord/hex lengths.\")\n",
    "print(\"Encoded sequences DataFrame:\")\n",
    "encoded_df.to_csv('encoded_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c03f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
