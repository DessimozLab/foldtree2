{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8502a6b",
   "metadata": {},
   "source": [
    "# Test MonoDecoders: Sequence and Geometry\n",
    "This notebook replicates the training logic from `learn.py` using the decoder in `mono_decoders.py` for amino acid and geometry prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6586f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5103ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248b7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "from src import pdbgraph\n",
    "from src import foldtree2_ecddcd as ft2\n",
    "from src.mono_decoders import MultiMonoDecoder\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d142a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Data setup\n",
    "datadir = '../../datasets/foldtree2/'\n",
    "dataset_path = 'structs_traininffttest.h5'\n",
    "converter = pdbgraph.PDB2PyG(aapropcsv='config/aaindex1.csv')\n",
    "struct_dat = pdbgraph.StructureDataset(dataset_path)\n",
    "train_loader = DataLoader(struct_dat, batch_size=5, shuffle=True, num_workers=4)\n",
    "data_sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "556484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample: HeteroDataBatch(\n",
      "  identifier=[5],\n",
      "  AA={\n",
      "    x=[1323, 20],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  R_true={\n",
      "    x=[1323, 3, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  bondangles={\n",
      "    x=[1323, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  coords={\n",
      "    x=[1323, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier1di={\n",
      "    x=[1323, 80],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier1dr={\n",
      "    x=[1323, 80],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier2di={\n",
      "    x=[5, 1300],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  fourier2dr={\n",
      "    x=[5, 1300],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  godnode={\n",
      "    x=[5, 5],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  godnode4decoder={\n",
      "    x=[5, 5],\n",
      "    batch=[5],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  plddt={\n",
      "    x=[1323, 1],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  positions={\n",
      "    x=[1323, 256],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  res={\n",
      "    x=[1323, 857],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  t_true={\n",
      "    x=[1323, 3],\n",
      "    batch=[1323],\n",
      "    ptr=[6],\n",
      "  },\n",
      "  (godnode4decoder, informs, res)={ edge_index=[2, 1323] },\n",
      "  (godnode, informs, res)={ edge_index=[2, 1323] },\n",
      "  (res, backbone, res)={\n",
      "    edge_index=[2, 2641],\n",
      "    edge_attr=[1318],\n",
      "  },\n",
      "  (res, backbonerev, res)={\n",
      "    edge_index=[2, 2641],\n",
      "    edge_attr=[1318],\n",
      "  },\n",
      "  (res, contactPoints, res)={\n",
      "    edge_index=[2, 9804],\n",
      "    edge_attr=[9804],\n",
      "  },\n",
      "  (res, hbond, res)={\n",
      "    edge_index=[2, 1700],\n",
      "    edge_attr=[1700],\n",
      "  },\n",
      "  (res, informs, godnode)={ edge_index=[2, 1323] },\n",
      "  (res, informs, godnode4decoder)={ edge_index=[2, 1323] },\n",
      "  (res, window, res)={\n",
      "    edge_index=[2, 2626],\n",
      "    edge_attr=[2626],\n",
      "  },\n",
      "  (res, windowrev, res)={\n",
      "    edge_index=[2, 1318],\n",
      "    edge_attr=[1318],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Data sample:', data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc573dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk1_Encoder(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (res_contactPoints_res): TransformerConv(100, 100, heads=5)\n",
      "      (res_hbond_res): TransformerConv(100, 100, heads=5)\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): GraphNorm(100)\n",
      "  )\n",
      "  (bn): BatchNorm1d(857, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.005, inplace=False)\n",
      "  (jk): JumpingKnowledge(cat)\n",
      "  (ffin): Sequential(\n",
      "    (0): Linear(in_features=1017, out_features=200, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (lin): Sequential(\n",
      "    (0): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (out_dense): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=100, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=50, out_features=20, bias=True)\n",
      "    (5): GELU(approximate='none')\n",
      "    (6): DynamicTanh(normalized_shape=20, alpha_init_value=0.5, channels_last=True)\n",
      "  )\n",
      "  (vector_quantizer): VectorQuantizerEMA(\n",
      "    (embeddings): Embedding(40, 20)\n",
      "  )\n",
      ")\n",
      "Initializing decoder for task: sequence_transformer\n",
      "False True False False False\n",
      "100 4 3 0.005\n",
      "Initializing decoder for task: contacts\n",
      "False False True False False\n",
      "MultiMonoDecoder(\n",
      "  (decoders): ModuleDict(\n",
      "    (sequence_transformer): Transformer_AA_Decoder(\n",
      "      (input_proj): Sequential(\n",
      "        (0): DynamicTanh(normalized_shape=276, alpha_init_value=0.5, channels_last=True)\n",
      "        (1): Linear(in_features=276, out_features=100, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Dropout(p=0.005, inplace=False)\n",
      "        (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "      )\n",
      "      (transformer_encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.005, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "            (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.005, inplace=False)\n",
      "            (dropout2): Dropout(p=0.005, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (lin): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): DynamicTanh(normalized_shape=50, alpha_init_value=0.5, channels_last=True)\n",
      "        (7): Linear(in_features=50, out_features=20, bias=True)\n",
      "        (8): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (contacts): HeteroGAE_geo_Decoder(\n",
      "      (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convs): ModuleList(\n",
      "        (0-2): 3 x HeteroConv(num_relations=4)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-2): 3 x GraphNorm(100)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.005, inplace=False)\n",
      "      (jk): JumpingKnowledge(cat)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (lin): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): DynamicTanh(normalized_shape=300, alpha_init_value=0.5, channels_last=True)\n",
      "        (2): Linear(in_features=300, out_features=100, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (7): GELU(approximate='none')\n",
      "        (8): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "      )\n",
      "      (godnodedecoder): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "        (5): Linear(in_features=100, out_features=2600, bias=True)\n",
      "      )\n",
      "      (contact_mlp): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): Linear(in_features=200, out_features=50, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Linear(in_features=50, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "ndim = data_sample['res'].x.shape[1]\n",
    "ndim_godnode = data_sample['godnode'].x.shape[1]\n",
    "ndim_fft2i = data_sample['fourier2di'].x.shape[1]\n",
    "ndim_fft2r = data_sample['fourier2dr'].x.shape[1]\n",
    "\n",
    "num_embeddings = 40\n",
    "embedding_dim = 20\n",
    "hidden_size = 100\n",
    "se3transfomer = False  # Set to True for SE3Transformer, False for GNN\n",
    "\n",
    "if se3transfomer == True:\n",
    "\n",
    "\tencoder = se3e.se3_Encoder(\n",
    "\t\tin_channels=ndim,\n",
    "\t\thidden_channels=[hidden_size//2, hidden_size//2],\n",
    "\t\tout_channels=embedding_dim,\n",
    "\t\tmetadata={'edge_types': [('res','contactPoints','res'), ('res','hbond','res')]},\n",
    "\t\tnum_embeddings=num_embeddings,\n",
    "\t\tcommitment_cost=0.9,\n",
    "\t\tedge_dim=1,\n",
    "\t\tencoder_hidden=hidden_size,\n",
    "\t\tEMA=True,\n",
    "\t\tnheads=5,\n",
    "\t\tdropout_p=0.005,\n",
    "\t\treset_codes=False,\n",
    "\t\tflavor='transformer',\n",
    "\t\tfftin=True\n",
    "\t)\t\t\t\n",
    "else:\n",
    "\tencoder = ft2.mk1_Encoder(\n",
    "\t\tin_channels=ndim,\n",
    "\t\thidden_channels=[hidden_size, hidden_size],\n",
    "\t\tout_channels=embedding_dim,\n",
    "\t\tmetadata={'edge_types': [('res','contactPoints','res'), ('res','hbond','res')]},\n",
    "\t\tnum_embeddings=num_embeddings,\n",
    "\t\tcommitment_cost=0.9,\n",
    "\t\tedge_dim=1,\n",
    "\t\tencoder_hidden=hidden_size,\n",
    "\t\tEMA=True,\n",
    "\t\tnheads=5,\n",
    "\t\tdropout_p=0.005,\n",
    "\t\treset_codes=False,\n",
    "\t\tflavor='transformer',\n",
    "\t\tfftin=True\n",
    "\t)\n",
    "\n",
    "\n",
    "print(encoder)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# MultiMonoDecoder for sequence and geometry\n",
    "mono_configs = {\n",
    "\t'sequence_transformer': {\n",
    "\t\t'in_channels': {'res': embedding_dim},\n",
    "\t\t'xdim': 20,\n",
    "\t\t'concat_positions': True,\n",
    "\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*3 , ('res','backbonerev','res'): [hidden_size]*3},\n",
    "\t\t'layers': 3,\n",
    "\t\t'AAdecoder_hidden': [hidden_size, hidden_size, hidden_size//2],\n",
    "\t\t'amino_mapper': converter.aaindex,\n",
    "\t\t'flavor': 'sage',\n",
    "\t\t'dropout': 0.005,\n",
    "\t\t'normalize': True,\n",
    "\t\t'residual': False\n",
    "\t},\n",
    "\t\n",
    "\t'contacts': {\n",
    "\t\t'in_channels': {'res': embedding_dim, 'godnode4decoder': ndim_godnode, 'foldx': 23 ,  'fft2r': ndim_fft2r, 'fft2i': ndim_fft2i},\n",
    "\t\t'concat_positions': True,\n",
    "\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*3, ('res','backbonerev','res'): [hidden_size]*3, ('res','informs','godnode4decoder'): [hidden_size]*3 , ('godnode4decoder','informs','res'): [hidden_size]*3},\n",
    "\t\t'layers': 3,\n",
    "\t\t'FFT2decoder_hidden': [hidden_size, hidden_size, hidden_size],\n",
    "\t\t'contactdecoder_hidden': [hidden_size//2, hidden_size//2],\n",
    "\t\t'nheads': 2,\n",
    "\t\t'Xdecoder_hidden': [hidden_size, hidden_size,  hidden_size ],\n",
    "\t\t'metadata': converter.metadata,\n",
    "\t\t'flavor': 'sage',\n",
    "\t\t'dropout': 0.005,\n",
    "\t\t'output_fft': True,\n",
    "        'output_rt':False,\n",
    "\t\t'normalize': True,\n",
    "\t\t'residual': False,\n",
    "\t\t'contact_mlp': True\n",
    "\t}\n",
    "}\n",
    "decoder = MultiMonoDecoder( configs=mono_configs)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a24b3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiMonoDecoder(\n",
       "  (decoders): ModuleDict(\n",
       "    (sequence_transformer): Transformer_AA_Decoder(\n",
       "      (input_proj): Sequential(\n",
       "        (0): DynamicTanh(normalized_shape=276, alpha_init_value=0.5, channels_last=True)\n",
       "        (1): Linear(in_features=276, out_features=100, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout(p=0.005, inplace=False)\n",
       "        (4): Linear(in_features=100, out_features=100, bias=True)\n",
       "      )\n",
       "      (transformer_encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.005, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "            (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.005, inplace=False)\n",
       "            (dropout2): Dropout(p=0.005, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lin): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): DynamicTanh(normalized_shape=50, alpha_init_value=0.5, channels_last=True)\n",
       "        (7): Linear(in_features=50, out_features=20, bias=True)\n",
       "        (8): LogSoftmax(dim=1)\n",
       "      )\n",
       "    )\n",
       "    (contacts): HeteroGAE_geo_Decoder(\n",
       "      (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convs): ModuleList(\n",
       "        (0-2): 3 x HeteroConv(num_relations=4)\n",
       "      )\n",
       "      (norms): ModuleList(\n",
       "        (0-2): 3 x GraphNorm(100)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.005, inplace=False)\n",
       "      (jk): JumpingKnowledge(cat)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (lin): Sequential(\n",
       "        (0): Dropout(p=0.005, inplace=False)\n",
       "        (1): DynamicTanh(normalized_shape=300, alpha_init_value=0.5, channels_last=True)\n",
       "        (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
       "      )\n",
       "      (godnodedecoder): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
       "        (5): Linear(in_features=100, out_features=2600, bias=True)\n",
       "      )\n",
       "      (contact_mlp): Sequential(\n",
       "        (0): Dropout(p=0.005, inplace=False)\n",
       "        (1): Linear(in_features=200, out_features=50, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=50, out_features=50, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "        (5): Linear(in_features=50, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop (demo, similar to learn.py)\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "num_epochs = 20  # For demonstration, keep small\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "edgeweight = 0.01\n",
    "xweight = 1\n",
    "fft2weight = 0.01\n",
    "vqweight = 0.0001\n",
    "clip_grad = True\n",
    "encoder.device = device\n",
    "encoder.train()\n",
    "decoder.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8583d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6329, 857]) x_dict[res] shape\n",
      "z_quantized shape: torch.Size([6329, 20])\n",
      "vq_loss: tensor(0.7659, device='cuda:1', grad_fn=<SubBackward0>)\n",
      "x shape: torch.Size([6329, 20])\n",
      "x_dict keys: dict_keys(['AA', 'R_true', 'bondangles', 'coords', 'fourier1di', 'fourier1dr', 'fourier2di', 'fourier2dr', 'godnode', 'godnode4decoder', 'plddt', 'positions', 'res', 't_true'])\n",
      "edge_index_dict keys: dict_keys([('godnode4decoder', 'informs', 'res'), ('godnode', 'informs', 'res'), ('res', 'backbone', 'res'), ('res', 'backbonerev', 'res'), ('res', 'contactPoints', 'res'), ('res', 'hbond', 'res'), ('res', 'informs', 'godnode'), ('res', 'informs', 'godnode4decoder'), ('res', 'window', 'res'), ('res', 'windowrev', 'res')])\n",
      "Encoded z shape: torch.Size([6329, 20])\n",
      "['R5D7F0', 'A0A7S4UUN0', 'A0A0F8XUB3', 'A0A3E4NY07', 'A0A1D1W005', 'A0A4R8G4N7', 'A0A1E5XW89', 'A0A7V2CVU6', 'A0A182QEX7', 'A0A0A9S6W1', 'A0A6J8AXJ0', 'A0A6V7WLY8', 'A0A5N5KV62', 'A0A7J8DMC4', 'J5TFK9', 'A0A853HWF1', 'A0A7Y6IRL5', 'K1ISW4', 'Q55EN3', 'A0A7G9LZ85']\n"
     ]
    }
   ],
   "source": [
    "#get one sample from the dataloader\n",
    "train_loader = DataLoader(struct_dat, batch_size=20, shuffle=True, num_workers=4)\n",
    "data_sample = next(iter(train_loader))\n",
    "data = data_sample.to(device)\n",
    "optimizer.zero_grad()\n",
    "z, vqloss = encoder(data , debug = True)\n",
    "print('Encoded z shape:', z.shape)\n",
    "print( data_sample.identifier )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "104038db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing identifier: R5D7F0\n",
      "Total number of CA atoms: 153\n",
      "Processing identifier: A0A7S4UUN0\n",
      "Total number of CA atoms: 563\n",
      "Processing identifier: A0A0F8XUB3\n",
      "Total number of CA atoms: 82\n",
      "Processing identifier: A0A3E4NY07\n",
      "Total number of CA atoms: 81\n",
      "Processing identifier: A0A1D1W005\n",
      "Total number of CA atoms: 758\n",
      "Processing identifier: A0A4R8G4N7\n",
      "Total number of CA atoms: 73\n",
      "Processing identifier: A0A1E5XW89\n",
      "Total number of CA atoms: 1096\n",
      "Processing identifier: A0A7V2CVU6\n",
      "Total number of CA atoms: 626\n",
      "Processing identifier: A0A182QEX7\n",
      "Total number of CA atoms: 281\n",
      "Processing identifier: A0A0A9S6W1\n",
      "Total number of CA atoms: 326\n",
      "Processing identifier: A0A6J8AXJ0\n",
      "Total number of CA atoms: 329\n",
      "Processing identifier: A0A6V7WLY8\n",
      "Total number of CA atoms: 74\n",
      "Processing identifier: A0A5N5KV62\n",
      "Total number of CA atoms: 106\n",
      "Processing identifier: A0A7J8DMC4\n",
      "Total number of CA atoms: 338\n",
      "Processing identifier: J5TFK9\n",
      "Total number of CA atoms: 475\n",
      "Processing identifier: A0A853HWF1\n",
      "Total number of CA atoms: 67\n",
      "Processing identifier: A0A7Y6IRL5\n",
      "Total number of CA atoms: 80\n",
      "Processing identifier: K1ISW4\n",
      "Total number of CA atoms: 207\n",
      "Processing identifier: Q55EN3\n",
      "Total number of CA atoms: 368\n",
      "Processing identifier: A0A7G9LZ85\n",
      "Total number of CA atoms: 246\n",
      "Total residues for all identifiers: 6329\n"
     ]
    }
   ],
   "source": [
    "from Bio import PDB\n",
    "from Bio.PDB import PDBParser\n",
    "def getCAatoms(pdb_file):\n",
    "\tparser = PDBParser(QUIET=True)\n",
    "\t# Parse the structure\n",
    "\tstructure = parser.get_structure('structure', pdb_file)\n",
    "\tca_atoms = {}\n",
    "\tfor model in structure:\n",
    "\t\tfor chain in model:\n",
    "\t\t\tif chain.id not in ca_atoms:\n",
    "\t\t\t\tca_atoms[chain.id] = []\n",
    "\t\t\tfor residue in chain :\n",
    "\t\t\t\tif 'CA' in residue and PDB.is_aa(residue) :\n",
    "\t\t\t\t\tca_atoms[chain.id].append(residue['CA'])\n",
    "\treturn ca_atoms\n",
    "\n",
    "from src.AFDB_tools import \tgrab_struct\n",
    "totals = []\n",
    "for identifier in  list(data.identifier):\n",
    "\tprint('Processing identifier:', identifier)\n",
    "\tgrab_struct(str(identifier) , structfolder='tmp/')\n",
    "\t#find the total number of residues\n",
    "\tca_atoms = getCAatoms( 'tmp/' + str(identifier) + '.pdb')\n",
    "\ttotal_residues = sum(len(atoms) for atoms in ca_atoms.values())\n",
    "\tprint('Total number of CA atoms:', total_residues)\n",
    "\ttotals.append(total_residues)\n",
    "print('Total residues for all identifiers:', sum(totals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79b98a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "21it [00:01, 11.07it/s]\n",
      "42it [00:00, 123534.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          seq  \\\n",
      "protid                                                          \n",
      "A0A813AF04  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1I0BAB0  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A6C0JB65  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1H8XK78  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A849FTN9  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A812B6T8  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1Y4RGK8  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A815TLP4  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A850LSD1  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "G3N7K7      \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "\n",
      "                                                          ord  \\\n",
      "protid                                                          \n",
      "A0A813AF04  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1I0BAB0  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A6C0JB65  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1H8XK78  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A849FTN9  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A812B6T8  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1Y4RGK8  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A815TLP4  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A850LSD1  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "G3N7K7      [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "\n",
      "                                                         hex2  length_ord  \\\n",
      "protid                                                                      \n",
      "A0A813AF04  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...        1024   \n",
      "A0A1I0BAB0  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         526   \n",
      "A0A6C0JB65  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         390   \n",
      "A0A1H8XK78  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         341   \n",
      "A0A849FTN9  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         323   \n",
      "A0A812B6T8  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         300   \n",
      "A0A1Y4RGK8  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         232   \n",
      "A0A815TLP4  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         230   \n",
      "A0A850LSD1  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         212   \n",
      "G3N7K7      [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         198   \n",
      "\n",
      "            length_hex  length_seq  \n",
      "protid                              \n",
      "A0A813AF04        1024        1024  \n",
      "A0A1I0BAB0         526         526  \n",
      "A0A6C0JB65         390         390  \n",
      "A0A1H8XK78         341         341  \n",
      "A0A849FTN9         323         323  \n",
      "A0A812B6T8         300         300  \n",
      "A0A1Y4RGK8         232         232  \n",
      "A0A815TLP4         230         230  \n",
      "A0A850LSD1         212         212  \n",
      "G3N7K7             198         198  \n",
      "                                                          seq  \\\n",
      "protid                                                          \n",
      "A0A3B3YY78  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A4P9WRQ4  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A7Y6TAH4  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A6P9A7H4  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A5E4FM51  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1B2HHY3  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A2T6GBL4  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A0F9ADI7  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A5S5BBP0  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1J5P8G6  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "\n",
      "                                                          ord  \\\n",
      "protid                                                          \n",
      "A0A3B3YY78  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A4P9WRQ4  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A7Y6TAH4  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A6P9A7H4  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A5E4FM51  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1B2HHY3  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A2T6GBL4  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A0F9ADI7  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A5S5BBP0  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1J5P8G6  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "\n",
      "                                                         hex2  length_ord  \\\n",
      "protid                                                                      \n",
      "A0A3B3YY78  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         196   \n",
      "A0A4P9WRQ4  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         161   \n",
      "A0A7Y6TAH4  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         146   \n",
      "A0A6P9A7H4  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         141   \n",
      "A0A5E4FM51  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         111   \n",
      "A0A1B2HHY3  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         107   \n",
      "A0A2T6GBL4  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...          98   \n",
      "A0A0F9ADI7  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...          75   \n",
      "A0A5S5BBP0  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...          69   \n",
      "A0A1J5P8G6  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...          64   \n",
      "\n",
      "            length_hex  length_seq  \n",
      "protid                              \n",
      "A0A3B3YY78         196         196  \n",
      "A0A4P9WRQ4         161         161  \n",
      "A0A7Y6TAH4         146         146  \n",
      "A0A6P9A7H4         141         141  \n",
      "A0A5E4FM51         111         111  \n",
      "A0A1B2HHY3         107         107  \n",
      "A0A2T6GBL4          98          98  \n",
      "A0A0F9ADI7          75          75  \n",
      "A0A5S5BBP0          69          69  \n",
      "A0A1J5P8G6          64          64  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_loader = DataLoader(struct_dat, batch_size=1, shuffle=True, num_workers=4)\n",
    "def databatch2list(loader , limit = 10):\n",
    "\tfor i,data in enumerate(loader):\n",
    "\t\tif i > limit:\n",
    "\t\t\tbreak\n",
    "\t\tdata = data.to_data_list()\n",
    "\t\tfor d in data:\n",
    "\t\t\td = d.to(device)\n",
    "\t\t\tyield d\n",
    "encoder_loader = databatch2list(train_loader, limit=20)\n",
    "encoder.encode_structures_fasta(encoder_loader , './aln_encoded_test.fasta' )\n",
    "#read the test fasta file\n",
    "encoded_fasta =  './aln_encoded_test.fasta' \n",
    "seqstr = ''\n",
    "ID = ''\n",
    "seqdict = {}\n",
    "with open(encoded_fasta, 'r') as f:\n",
    "\t#read all chars of file into a string\n",
    "\tfor line in tqdm.tqdm(f):\n",
    "\t\tif line[0] == '>' and line[-1] == '\\n':\n",
    "\t\t\tseqdict[ID] = seqstr\n",
    "\t\t\tID = line[1:].strip()\n",
    "\t\t\tseqstr = ''\n",
    "\t\telse:\n",
    "\t\t\tseqstr += line.strip()\n",
    "del seqdict['']\n",
    "encoded_df = pd.DataFrame( seqdict.items() , columns=['protid', 'seq'] )\n",
    "#change index to protid\n",
    "encoded_df.index = encoded_df.protid\n",
    "encoded_df = encoded_df.drop( 'protid', axis=1 )\n",
    "encoded_df['ord'] = encoded_df.seq.map( lambda x: [ ord(c) for c in x] )\n",
    "#hex starts at 1\n",
    "encoded_df['hex2'] = encoded_df.ord.map( lambda x: [ hex(c) for c in x] )\n",
    "encoded_df['length_ord'] = encoded_df.ord.map( lambda x: len(x) )\n",
    "encoded_df['length_hex'] = encoded_df.hex2.map( lambda x: len(x) )\n",
    "encoded_df['length_seq'] = encoded_df.seq.map( lambda x: len(x) )\n",
    "encoded_df = encoded_df.sort_values('length_ord', ascending=False)\n",
    "print(encoded_df.head(10))\n",
    "print(encoded_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcd8222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          seq  \\\n",
      "protid                                                          \n",
      "A0A813AF04  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1I0BAB0  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A6C0JB65  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A1H8XK78  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "A0A849FTN9  \u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b\u001b...   \n",
      "\n",
      "                                                          ord  \\\n",
      "protid                                                          \n",
      "A0A813AF04  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1I0BAB0  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A6C0JB65  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A1H8XK78  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "A0A849FTN9  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...   \n",
      "\n",
      "                                                         hex2  length_ord  \\\n",
      "protid                                                                      \n",
      "A0A813AF04  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...        1024   \n",
      "A0A1I0BAB0  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         526   \n",
      "A0A6C0JB65  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         390   \n",
      "A0A1H8XK78  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         341   \n",
      "A0A849FTN9  [0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1b, 0x1...         323   \n",
      "\n",
      "            length_hex  length_seq  \n",
      "protid                              \n",
      "A0A813AF04        1024        1024  \n",
      "A0A1I0BAB0         526         526  \n",
      "A0A6C0JB65         390         390  \n",
      "A0A1H8XK78         341         341  \n",
      "A0A849FTN9         323         323  \n",
      "All checks passed. Sequence lengths match PDB total residues and ord/hex lengths.\n",
      "Encoded sequences DataFrame:\n"
     ]
    }
   ],
   "source": [
    "print(encoded_df.head())\n",
    "#grab the pdbs and get the total number of residues\n",
    "#ensure encoder produces fastas with the same residues as the pdbs\n",
    "pdbs = []\n",
    "for identifier in encoded_df.index:\n",
    "\tpdbs.append( str(identifier) + '.pdb' )\n",
    "encoded_df['pdb'] = pdbs\n",
    "for i in range(len(encoded_df)):\n",
    "\tidentifier = encoded_df.index[i]\n",
    "\tpdb_file = 'tmp/' + identifier + '.pdb'\n",
    "\tif not os.path.exists(pdb_file):\n",
    "\t\tgrab_struct(str(identifier), structfolder='tmp/')\n",
    "\tca_atoms = getCAatoms(pdb_file)\n",
    "\ttotal_residues = sum(len(atoms) for atoms in ca_atoms.values())\n",
    "\tencoded_df.at[identifier, 'total_residues'] = total_residues\n",
    "encoded_df['delta'] = encoded_df['length_ord'] - encoded_df['total_residues']\n",
    "assert (encoded_df['delta'] == 0).all(), \"Mismatch between sequence length and total residues in PDB files\"\n",
    "assert (encoded_df['length_ord'] == encoded_df['length_hex']).all(), \"Mismatch between ord and hex lengths\"\n",
    "assert (encoded_df['length_ord'] == encoded_df['length_seq']).all(), \"Mismatch between ord and sequence lengths\"\n",
    "assert (encoded_df['length_hex'] == encoded_df['length_seq']).all(), \"Mismatch between hex and sequence lengths\"\n",
    "print(\"All checks passed. Sequence lengths match PDB total residues and ord/hex lengths.\")\n",
    "print(\"Encoded sequences DataFrame:\")\n",
    "encoded_df.to_csv('encoded_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|‚ñç              | 31/1000 [00:17<08:55,  1.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontactPoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_dict\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontactPoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_index_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m \tedgeloss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrecon_loss_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplddt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge_probs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m \tedgeloss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/projects/foldtree2/src/losses/losses.py:178\u001b[0m, in \u001b[0;36mrecon_loss_diag\u001b[0;34m(data, pos_edge_index, decoder, poslossmod, neglossmod, plddt, offdiag, nclamp, key)\u001b[0m\n\u001b[1;32m    175\u001b[0m neg_edge_index \u001b[38;5;241m=\u001b[39m negative_sampling(pos_edge_index, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    177\u001b[0m neg_edge_index \u001b[38;5;241m=\u001b[39m neg_edge_index[:, neg_edge_index[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m neg_edge_index[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m--> 178\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_edge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m \tneg \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/foldtree2/src/mono_decoders.py:818\u001b[0m, in \u001b[0;36mMultiMonoDecoder.forward\u001b[0;34m(self, data, contact_pred_index, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task, decoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 818\u001b[0m \tresults\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontact_pred_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontact_pred_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/foldtree2/src/mono_decoders.py:476\u001b[0m, in \u001b[0;36mTransformer_AA_Decoder.forward\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m aa_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, xi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):  \u001b[38;5;66;03m# xi: (seq_len, 1, d_model)\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \t\u001b[38;5;66;03m# Remove batch dimension and padding (assume original lengths from batch)\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m \tseq_len \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \taa_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(xi[:seq_len, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    478\u001b[0m aa \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(aa_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from losses.losses import recon_loss_diag , aa_reconstruction_loss\n",
    "for epoch in range(num_epochs):\n",
    "\ttotal_loss_x = 0\n",
    "\ttotal_loss_edge = 0\n",
    "\ttotal_vq = 0\n",
    "\ttotal_loss_fft2 = 0\n",
    "\tfor data in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "\t\tdata = data.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tz, vqloss = encoder(data)\n",
    "\t\tdata['res'].x = z\n",
    "\t\t# For demonstration, only sequence and contacts tasks\n",
    "\t\tout = decoder(data, None)\n",
    "\t\trecon_x = out['aa'] if isinstance(out, dict) and 'aa' in out else out[0] if isinstance(out, (list, tuple)) else None\n",
    "\t\tfft2_x = out['fft2pred'] if isinstance(out, dict) and 'fft2pred' in out else out[1] if isinstance(out, (list, tuple)) else None\n",
    "\t\t# Edge loss: use contactPoints if available\n",
    "\t\tedge_index = data.edge_index_dict['res', 'contactPoints', 'res'] if hasattr(data, 'edge_index_dict') and ('res', 'contactPoints', 'res') in data.edge_index_dict else None\n",
    "\t\tif edge_index is not None:\n",
    "\t\t\tedgeloss, _ = recon_loss_diag(data, edge_index, decoder, plddt=False, offdiag=False , key = 'edge_probs')\n",
    "\t\telse:\n",
    "\t\t\tedgeloss = torch.tensor(0.0, device=device)\n",
    "\t\txloss = aa_reconstruction_loss(data['AA'].x, recon_x)\n",
    "\t\tfft2loss = F.smooth_l1_loss(torch.cat( [ data['fourier2dr'].x ,data['fourier2di'].x ] ,axis = 1 ) , fft2_x )\n",
    "\t\tloss = xweight * xloss + edgeweight * edgeloss + vqweight * vqloss + fft2loss* fft2weight\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\tif clip_grad:\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1.0)\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss_x += xloss.item()\n",
    "\t\ttotal_loss_edge += edgeloss.item()\n",
    "\t\ttotal_loss_fft2 += fft2loss.item()\n",
    "\t\ttotal_vq += vqloss.item() if isinstance(vqloss, torch.Tensor) else float(vqloss)\n",
    "\tscheduler.step(total_loss_x)\n",
    "\tprint(f\"Epoch {epoch}: AA Loss: {total_loss_x/len(train_loader):.4f}, Edge Loss: {total_loss_edge/len(train_loader):.4f}, VQ Loss: {total_vq/len(train_loader):.4f} , FFT2 Loss: {total_loss_fft2/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903373a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
