{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3af69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182db143",
   "metadata": {},
   "source": [
    "# Information-Theoretic Benchmarking of Species Tree Inference\n",
    "\n",
    "This notebook presents a comparative workflow for species tree inference using two different character sets: traditional amino acid sequences and foldtree-encoded structural features. The goal is to benchmark the phylogenetic signal carried by each character set using information-theoretic approaches.\n",
    "\n",
    "**Workflow Overview:**\n",
    "- Construct a species tree using a standard amino acid-based pipeline (multiple sequence alignment, concatenation, and maximum likelihood inference).\n",
    "- Construct an equivalent species tree using foldtree-encoded data.\n",
    "- For both trees, compute column-wise log-likelihoods and character frequencies.\n",
    "- Quantify the information content and phylogenetic signal of each character set by analyzing the distribution of likelihoods and character frequencies.\n",
    "\n",
    "This approach enables a direct comparison of how much evolutionary information is captured by sequence versus structure-based encodings, providing an objective benchmark for future phylogenomic analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f08cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a210460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 marker genes\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "markers = glob.glob( './families/marker_genes/marker_genes/*.fa')\n",
    "print( f\"Found {len(markers)} marker genes\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your model and associated matrices\n",
    "from foldtree2.ft2treebuilder import treebuilder\n",
    "model_path = \"../../models/your_trained_model\"  # Path to your model (without .pkl)\n",
    "mafftmat = model_path + \"_mafftmat.mtx\"\n",
    "submat = model_path + \"_submat.txt\"\n",
    "# Initialize the treebuilder class\n",
    "tb = treebuilder(model=model_path, mafftmat=mafftmat, submat=submat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c456e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_fasta_with_mafft(fasta_file):\n",
    "\t\"\"\"\n",
    "\tAlign a single FASTA file using MAFFT\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tfasta_file : str\n",
    "\t\tPath to input FASTA file\n",
    "\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\ttuple: (input_path, output_path, success_status)\n",
    "\t\"\"\"\n",
    "\t# Create output filename - same directory but with .aligned.fa extension\n",
    "\tinput_path = Path(fasta_file)\n",
    "\toutput_path = input_path.with_name(f\"{input_path.stem}.aligned.fa\")\n",
    "\t\n",
    "\t# Run MAFFT\n",
    "\tcmd = f\"mafft --auto --thread 1 {fasta_file} > {output_path}\"\n",
    "\tprint(f\"Aligning: {fasta_file}\")\n",
    "\t\n",
    "\ttry:\n",
    "\t\tsubprocess.run(cmd, shell=True, check=True, stderr=subprocess.PIPE)\n",
    "\t\treturn (fasta_file, str(output_path), True)\n",
    "\texcept subprocess.CalledProcessError as e:\n",
    "\t\tprint(f\"Error aligning {fasta_file}: {e}\")\n",
    "\t\treturn (fasta_file, str(output_path), False)\n",
    "\n",
    "# Get number of available cores (leave 1 core free for system processes)\n",
    "max_workers = max(1, multiprocessing.cpu_count() - 1)\n",
    "print(f\"Using {max_workers} cores for alignments\")\n",
    "\n",
    "# Process alignments in parallel\n",
    "aligned_files = []\n",
    "failed_files = []\n",
    "\n",
    "def align_fasta_with_mafft(fasta_file):\n",
    "\t\"\"\"\n",
    "\tAlign a single FASTA file using MAFFT\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tfasta_file : str\n",
    "\t\tPath to input FASTA file\n",
    "\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\ttuple: (input_path, output_path, success_status)\n",
    "\t\"\"\"\n",
    "\t# Create output filename - same directory but with .aligned.fa extension\n",
    "\tinput_path = Path(fasta_file)\n",
    "\toutput_path = input_path.with_name(f\"{input_path.stem}.aligned.fa\")\n",
    "\t\n",
    "\t# Run MAFFT\n",
    "\tcmd = f\"mafft --auto --thread 1 {fasta_file} > {output_path}\"\n",
    "\tprint(f\"Aligning: {fasta_file}\")\n",
    "\t\n",
    "\ttry:\n",
    "\t\tsubprocess.run(cmd, shell=True, check=True, stderr=subprocess.PIPE)\n",
    "\t\treturn (fasta_file, str(output_path), True)\n",
    "\texcept subprocess.CalledProcessError as e:\n",
    "\t\tprint(f\"Error aligning {fasta_file}: {e}\")\n",
    "\t\treturn (fasta_file, str(output_path), False)\n",
    "\n",
    "# Get number of available cores (leave 1 core free for system processes)\n",
    "max_workers = max(1, multiprocessing.cpu_count() - 1)\n",
    "print(f\"Using {max_workers} cores for alignments\")\n",
    "# Process alignments in parallel\n",
    "aligned_files = []\n",
    "failed_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837aa36",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def concatenate_alignments(alignment_files, output_file):\n",
    "\t\"\"\"\n",
    "\tConcatenate multiple alignment files into a single supermatrix alignment.\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\talignment_files : list\n",
    "\t\tList of paths to alignment files in FASTA format\n",
    "\toutput_file : str\n",
    "\t\tPath to save the concatenated alignment\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\ttuple\n",
    "\t\t(concatenated_alignment, partition_info)\n",
    "\t\t- concatenated_alignment: The final MultipleSeqAlignment object\n",
    "\t\t- partition_info: Dictionary with gene boundaries for partition file creation\n",
    "\t\"\"\"\n",
    "\tif not alignment_files:\n",
    "\t\tprint(\"No alignment files provided\")\n",
    "\t\treturn None, {}\n",
    "\t\n",
    "\t# Dictionary to store sequences for each species across all genes\n",
    "\tall_species = {}\n",
    "\tpartition_info = {}\n",
    "\tcurrent_position = 1\n",
    "\t\n",
    "\t# Process each alignment file\n",
    "\tfor i, aln_file in enumerate(alignment_files):\n",
    "\t\ttry:\n",
    "\t\t\t# Load the alignment\n",
    "\t\t\tgene_name = Path(aln_file).stem.replace('.aligned', '')\n",
    "\t\t\talignment = AlignIO.read(aln_file, \"fasta\")\n",
    "\t\t\taln_length = alignment.get_alignment_length()\n",
    "\t\t\t\n",
    "\t\t\t# Store partition information\n",
    "\t\t\tpartition_info[gene_name] = {\n",
    "\t\t\t\t'start': current_position,\n",
    "\t\t\t\t'end': current_position + aln_length - 1\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\t\t\t# Process each sequence in this alignment\n",
    "\t\t\tfor record in alignment:\n",
    "\t\t\t\t# Extract species identifier from the sequence header\n",
    "\t\t\t\tspecies_id = record.id.split('|')[-1]\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Initialize this species entry if it doesn't exist yet\n",
    "\t\t\t\tif species_id not in all_species:\n",
    "\t\t\t\t\tall_species[species_id] = {}\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Add this gene's sequence for this species\n",
    "\t\t\t\tall_species[species_id][gene_name] = str(record.seq)\n",
    "\t\t\t\n",
    "\t\t\tcurrent_position += aln_length\n",
    "\t\t\tprint(f\"Processed alignment {i+1}/{len(alignment_files)}: {gene_name} ({aln_length} columns)\")\n",
    "\t\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error processing {aln_file}: {str(e)}\")\n",
    "\t\n",
    "\t# Create the concatenated alignment\n",
    "\tconcatenated_records = []\n",
    "\tgene_names = list(partition_info.keys())\n",
    "\t\n",
    "\tfor species_id, genes in all_species.items():\n",
    "\t\t# Build the concatenated sequence for this species\n",
    "\t\tconcat_seq = \"\"\n",
    "\t\tfor gene in gene_names:\n",
    "\t\t\tif gene in genes:\n",
    "\t\t\t\tconcat_seq += genes[gene]\n",
    "\t\t\telse:\n",
    "\t\t\t\t# If this species doesn't have this gene, add gaps\n",
    "\t\t\t\tgene_length = partition_info[gene]['end'] - partition_info[gene]['start'] + 1\n",
    "\t\t\t\tconcat_seq += \"-\" * gene_length\n",
    "\t\t\n",
    "\t\t# Create a SeqRecord for this concatenated sequence\n",
    "\t\trecord = SeqRecord(\n",
    "\t\t\tSeq(concat_seq),\n",
    "\t\t\tid=species_id,\n",
    "\t\t\tdescription=f\"Concatenated {len(gene_names)} genes\"\n",
    "\t\t)\n",
    "\t\tconcatenated_records.append(record)\n",
    "\t\n",
    "\t# Create and save the concatenated alignment\n",
    "\tconcatenated_alignment = MultipleSeqAlignment(concatenated_records)\n",
    "\t\n",
    "\t# Save alignment to file\n",
    "\twith open(output_file, \"w\") as handle:\n",
    "\t\tAlignIO.write(concatenated_alignment, handle, \"fasta\")\n",
    "\t\n",
    "\t# Create a partition file for RAxML-NG\n",
    "\tpartition_file = f\"{output_file}.partition\"\n",
    "\twith open(partition_file, \"w\") as handle:\n",
    "\t\tfor gene, pos in partition_info.items():\n",
    "\t\t\thandle.write(f\"GTR+G, {gene} = {pos['start']}-{pos['end']}\\n\")\n",
    "\t\n",
    "\tprint(f\"Created concatenated alignment with {len(concatenated_records)} species and {concatenated_alignment.get_alignment_length()} columns\")\n",
    "\tprint(f\"Partition file saved to {partition_file}\")\n",
    "\treturn concatenated_alignment, partition_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64369397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_oma_ids_from_fasta(fasta_file):\n",
    "\t\"\"\"\n",
    "\tExtract OMA identifiers from a FASTA file\n",
    "\tID format example:\n",
    "\n",
    "\t>MOUSE45461 | OMA754554 | COQ5_MOUSE | [Mus musculus]\n",
    "\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tfasta_file : str\n",
    "\t\tPath to FASTA file\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tlist of str: OMA identifiers\n",
    "\t\"\"\"\n",
    "\toma_ids = []\n",
    "\ttry:\n",
    "\t\tfor record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "\t\t\t# Extract OMA ID from the FASTA header using the pipe-separated format\n",
    "\t\t\tid = record.description.split('|')[0]\t\n",
    "\t\t\toma_ids.append(id.strip())\n",
    "\treturn oma_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_oma_to_uniprot(oma_id, retry_limit=3):\n",
    "\t\"\"\"\n",
    "\tMap an OMA identifier to UniProt using the OMA API\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\toma_id : str\n",
    "\t\tOMA identifier (e.g., OMA123456)\n",
    "\tretry_limit : int\n",
    "\t\tNumber of times to retry on failure\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tdict: Mapping information (OMA ID, UniProt ID, etc.)\n",
    "\t\"\"\"\n",
    "\t# Extract numeric part from OMA ID\n",
    "\toma_numeric = re.sub(r'OMA:?', '', oma_id)\n",
    "\t\n",
    "\t# OMA API endpoint for protein information\n",
    "\tapi_url = f\"https://omabrowser.org/api/protein/OMA{oma_numeric}\"\n",
    "\t\n",
    "\tfor attempt in range(retry_limit):\n",
    "\t\ttry:\n",
    "\t\t\tresponse = requests.get(api_url)\n",
    "\t\t\tif response.ok:\n",
    "\t\t\t\tdata = response.json()\n",
    "\t\t\t\t# Extract UniProt ID if available\n",
    "\t\t\t\txrefs = data.get('xrefs', [])\n",
    "\t\t\t\tuniprot_id = None\n",
    "\t\t\t\tfor xref in xrefs:\n",
    "\t\t\t\t\tif xref.get('source') == 'UniProtKB/Swiss-Prot' or xref.get('source') == 'UniProtKB/TrEMBL':\n",
    "\t\t\t\t\t\tuniprot_id = xref.get('id')\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\treturn {\n",
    "\t\t\t\t\t'oma_id': f\"OMA{oma_numeric}\",\n",
    "\t\t\t\t\t'uniprot_id': uniprot_id,\n",
    "\t\t\t\t\t'species': data.get('species', {}).get('name', ''),\n",
    "\t\t\t\t\t'taxon_id': data.get('species', {}).get('taxon_id', ''),\n",
    "\t\t\t\t\t'sequence_length': len(data.get('sequence', '')),\n",
    "\t\t\t\t\t'protein_name': data.get('protein_name', '')\n",
    "\t\t\t\t}\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f\"Error fetching data for {oma_id}: HTTP {response.status_code}\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error mapping {oma_id} to UniProt: {str(e)}\")\n",
    "\t\t\n",
    "\t\t# Wait before retrying\n",
    "\t\ttime.sleep(1)\n",
    "\t\n",
    "\t# Return minimal info if all attempts failed\n",
    "\treturn {'oma_id': f\"OMA{oma_numeric}\", 'uniprot_id': None}\n",
    "\n",
    "def process_marker_gene(marker_file):\n",
    "\t\"\"\"Process a single marker gene file to extract OMA IDs and map to UniProt\"\"\"\n",
    "\toma_ids = extract_oma_ids_from_fasta(marker_file)\n",
    "\tmappings = []\n",
    "\t\n",
    "\tfor oma_id in oma_ids:\n",
    "\t\tmapping = map_oma_to_uniprot(oma_id)\n",
    "\t\tmappings.append(mapping)\n",
    "\t\t# Be nice to the API\n",
    "\t\ttime.sleep(0.2)\n",
    "\t\n",
    "\treturn {\n",
    "\t\t'marker_file': marker_file,\n",
    "\t\t'gene_name': Path(marker_file).stem,\n",
    "\t\t'mappings': mappings\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d835e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process marker genes to extract OMA IDs and map them to UniProt\n",
    "print(f\"Processing {len(markers)} marker gene files...\")\n",
    "\n",
    "# Use max 8 workers to avoid overwhelming the API\n",
    "max_workers = min(8, multiprocessing.cpu_count())\n",
    "marker_data = []\n",
    "\n",
    "# Process a sample of markers for testing (adjust as needed)\n",
    "sample_markers = markers[:10]  # Process first 10 markers for testing\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "\tfutures = [executor.submit(process_marker_gene, marker) for marker in sample_markers]\n",
    "\tfor future in concurrent.futures.as_completed(futures):\n",
    "\t\ttry:\n",
    "\t\t\tresult = future.result()\n",
    "\t\t\tmarker_data.append(result)\n",
    "\t\t\tprint(f\"Processed {result['gene_name']}: {len(result['mappings'])} sequences mapped\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error processing marker gene: {str(e)}\")\n",
    "\n",
    "# Convert mappings to DataFrame for analysis\n",
    "mapping_rows = []\n",
    "for marker in marker_data:\n",
    "\tfor mapping in marker['mappings']:\n",
    "\t\tmapping['marker_gene'] = marker['gene_name']\n",
    "\t\tmapping_rows.append(mapping)\n",
    "\n",
    "mapping_df = pd.DataFrame(mapping_rows)\n",
    "\n",
    "# Display summary of mappings\n",
    "print(f\"\\nMapping summary:\")\n",
    "print(f\"Total sequences processed: {len(mapping_rows)}\")\n",
    "print(f\"UniProt mappings found: {mapping_df['uniprot_id'].notna().sum()} ({mapping_df['uniprot_id'].notna().sum()/len(mapping_rows)*100:.1f}%)\")\n",
    "print(f\"Unique species: {mapping_df['species'].nunique()}\")\n",
    "\n",
    "# Save mapping results\n",
    "mapping_df.to_csv(\"oma_uniprot_mappings.csv\", index=False)\n",
    "print(\"Mapping data saved to oma_uniprot_mappings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc556452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_site_likelihood_analysis(aln , tree , model,  output_prefix = None):\n",
    "\t\"\"\"\n",
    "\tPlaceholder function for running site likelihood analysis.\n",
    "\tThis function should be implemented based on specific requirements.\n",
    "\t\"\"\"\n",
    "\tprint(\"Running site likelihood analysis...\")\n",
    "\t#raxml command is  --force --evaluate --msa your_alignment.phy --model GTR+G --tree fixed_tree.newick --site-lh\n",
    "\t# Example: assumes alignment and tree files are available for each HOG\n",
    "\t# Example: assumes alignment and tree files are available\n",
    "\tif output_prefix is None:\n",
    "\t\toutput_prefix = \"./raxmlng_results/example\"\n",
    "\t# Ensure output directory exists\n",
    "\timport os\n",
    "\tif os.path.exists(os.path.dirname(output_prefix)):\n",
    "\t\tprint(f\"Output directory {os.path.dirname(output_prefix)} already exists.\")\n",
    "\telse:\n",
    "\t\tprint(f\"Creating output directory: {os.path.dirname(output_prefix)}\")\t\n",
    "\t\t# Create output directory if it doesn't exist\n",
    "\t\tos.makedirs(os.path.dirname(output_prefix), exist_ok=True)\n",
    "\n",
    "\tcmd = [\n",
    "\t\t\"raxml-ng\",\n",
    "\t\t\"--force\",\n",
    "\t\t\"--evaluate\",\n",
    "\t\t\"--msa\", aln,\n",
    "\t\t\"--model\", model,\n",
    "\t\t\"--tree\", tree,\n",
    "\t\t\"--site-lh\",\n",
    "\t\t\"--prefix\", output_prefix\n",
    "\t]\n",
    "\tprint(f\"Running: {' '.join(cmd)}\")\n",
    "\tsubprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder for the structures of each group of marker genes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ab66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the tree for the amino acid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from Bio import AlignIO\n",
    "\n",
    "def extract_site_likelihoods(log_file):\n",
    "\t\"\"\"\n",
    "\tExtract site-wise log-likelihood values from RAxML-NG output\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tlog_file : str\n",
    "\t\tPath to the RAxML-NG log file containing site likelihoods\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tlist of floats: Site log-likelihood values\n",
    "\t\"\"\"\n",
    "\tlikelihoods = []\n",
    "\t\n",
    "\twith open(log_file, 'r') as f:\n",
    "\t\t# Skip to the part with site likelihoods\n",
    "\t\tfor line in f:\n",
    "\t\t\tif line.startswith('Site '):\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t# Parse the likelihood values\n",
    "\t\tfor line in f:\n",
    "\t\t\tif not line.strip() or line.startswith('Site '):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif 'Sum' in line:  # End of site likelihoods section\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\tparts = line.strip().split()\n",
    "\t\t\tif len(parts) >= 2:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tlikelihoods.append(float(parts[1]))\n",
    "\t\t\t\texcept ValueError:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\n",
    "\treturn likelihoods\n",
    "\n",
    "def create_column_likelihood_dataframe(alignment_file, tree_file, log_file,  output_dir=None):\n",
    "\t\"\"\"\n",
    "\tCalculate site likelihoods for an alignment and create a DataFrame with\n",
    "\talignment columns and their corresponding likelihood values\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\talignment_file : str\n",
    "\t\tPath to the aligned FASTA file\n",
    "\ttree_file : str\n",
    "\t\tPath to the tree file in Newick format\n",
    "\toutput_dir : str or None\n",
    "\t\tDirectory to store intermediate files (defaults to same directory as alignment)\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tpandas.DataFrame: DataFrame with columns for site index, alignment column, and likelihood\n",
    "\t\"\"\"\n",
    "\tif output_dir is None:\n",
    "\t\toutput_dir = os.path.dirname(alignment_file)\n",
    "\t\n",
    "\t# Load the alignment\n",
    "\talignment = AlignIO.read(alignment_file, \"fasta\")\n",
    "\t# Extract site likelihoods\n",
    "\tlikelihoods = extract_site_likelihoods(log_file)\n",
    "\t# Prepare data for DataFrame\n",
    "\tdata = []\n",
    "\tfor i in range(alignment.get_alignment_length()):\n",
    "\t\tif i < len(likelihoods):\n",
    "\t\t\tcolumn = [record.seq[i] for record in alignment]\n",
    "\t\t\tcolumn_str = ''.join(column)\n",
    "\t\t\tdata.append({\n",
    "\t\t\t\t'Site': i + 1,\n",
    "\t\t\t\t'Alignment_Column': column_str,\n",
    "\t\t\t\t'Log_Likelihood': likelihoods[i]\n",
    "\t\t\t})\n",
    "\t# Create DataFrame\n",
    "\tdf = pd.DataFrame(data)\n",
    "\treturn df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create supermatrix using alignment\n",
    "#mafft with ft2\n",
    "#mafft normal\n",
    "#foldmason\n",
    "\n",
    "\n",
    "#concat and run raxmlng for each super\n",
    "\n",
    "#visualize the trees\n",
    "\n",
    "#calculate likelihood scores for each column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3ee3c",
   "metadata": {},
   "source": [
    "## Align FoldTree2-encoded FASTA Files with MAFFT\n",
    "This cell will align all encoded FASTA files in a directory using MAFFT, producing aligned FASTA files for downstream benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for fam in \n",
    "\n",
    "# Directory containing encoded FASTA files\n",
    "encoded_dir = './families/encoded_fastas/'  # Change to your directory\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "# Find all encoded FASTA files\n",
    "encoded_fastas = list(Path(encoded_dir).glob(\"*.fasta\"))\n",
    "print(f\"Found {len(encoded_fastas)} encoded FASTA files.\")\n",
    "\n",
    "# Align each encoded FASTA file using MAFFT via treebuilder's static method\n",
    "for fasta_file in encoded_fastas:\n",
    "\taligned_path = str(fasta_file.with_name(f\"{fasta_file.stem}.aligned.fasta\"))\n",
    "\ttb.run_mafft_textaln(str(fasta_file), outaln=aligned_path, matrix=mafftmat)\n",
    "\tprint(f\"Aligned {fasta_file} -> {aligned_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07392b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#be"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
