{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db05fc51",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../../datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Base directory for all benchmarking files\u001b[39;00m\n\u001b[1;32m      8\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../datasets/foldtree2/minitcs/benchmark_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create directories to store data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m clusters_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../../datasets'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Base directory for all benchmarking files\n",
    "base_dir = '../../datasets/foldtree2/minitcs/benchmark_data'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Create directories to store data\n",
    "clusters_dir = os.path.join(base_dir, 'clusters')\n",
    "metadata_dir = os.path.join(base_dir, 'metadata')\n",
    "os.makedirs(clusters_dir, exist_ok=True)\n",
    "os.makedirs(metadata_dir, exist_ok=True)\n",
    "\n",
    "# Function to download AFDB clusters\n",
    "def download_afdb_clusters(cluster_url=\"https://ftp.ebi.ac.uk/pub/databases/alphafold/latest/UniProt.clusters.tsv\", \n",
    "\t\t\t\t\t\t  save_path=os.path.join(clusters_dir, \"afdb_clusters.tsv\")):\n",
    "\t\"\"\"\n",
    "\tDownload clusters from the AlphaFold Database.\n",
    "\t\"\"\"\n",
    "\tprint(f\"Downloading AFDB clusters from {cluster_url}...\")\n",
    "\tresponse = requests.get(cluster_url)\n",
    "\tif response.status_code == 200:\n",
    "\t\twith open(save_path, 'w') as f:\n",
    "\t\t\tf.write(response.text)\n",
    "\t\tprint(f\"Successfully downloaded clusters to {save_path}\")\n",
    "\t\t# Read the clusters into a DataFrame\n",
    "\t\tclusters_df = pd.read_csv(save_path, sep='\\t', header=None, \n",
    "\t\t\t\t\t\t\t\t names=['cluster_id', 'representative', 'members'])\n",
    "\t\treturn clusters_df\n",
    "\telse:\n",
    "\t\tprint(f\"Failed to download clusters. Status code: {response.status_code}\")\n",
    "\t\treturn None\n",
    "\n",
    "# Function to get metadata from UniProt\n",
    "def get_uniprot_metadata(uniprot_ids, batch_size=100):\n",
    "\t\"\"\"\n",
    "\tGet metadata from UniProt for a list of UniProt IDs.\n",
    "\tUses the batch retrieval API for efficiency.\n",
    "\t\"\"\"\n",
    "\tbase_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "\tall_metadata = []\n",
    "\t\n",
    "\t# Process in batches to avoid overwhelming the API\n",
    "\tfor i in tqdm(range(0, len(uniprot_ids), batch_size), desc=\"Fetching UniProt metadata\"):\n",
    "\t\tbatch_ids = uniprot_ids[i:i+batch_size]\n",
    "\t\tquery = \" OR \".join([f\"accession:{uid}\" for uid in batch_ids])\n",
    "\t\t\n",
    "\t\tparams = {\n",
    "\t\t\t'query': query,\n",
    "\t\t\t'format': 'tsv',\n",
    "\t\t\t'fields': 'accession,id,protein_name,gene_names,organism_name,length,reviewed,lineage_ids'\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tresponse = requests.get(base_url, params=params)\n",
    "\t\t\tif response.status_code == 200:\n",
    "\t\t\t\tbatch_df = pd.read_csv(StringIO(response.text), sep='\\t')\n",
    "\t\t\t\tall_metadata.append(batch_df)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f\"Error fetching batch {i//batch_size + 1}. Status code: {response.status_code}\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Exception occurred during batch {i//batch_size + 1}: {str(e)}\")\n",
    "\t\n",
    "\tif all_metadata:\n",
    "\t\tmetadata_df = pd.concat(all_metadata, ignore_index=True)\n",
    "\t\tmetadata_df.to_csv(os.path.join(metadata_dir, 'uniprot_metadata.tsv'), sep='\\t', index=False)\n",
    "\t\treturn metadata_df\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\n",
    "# Function to separate clusters into individual folders and save metadata\n",
    "def separate_clusters(clusters_df, metadata_df=None):\n",
    "\t\"\"\"\n",
    "\tCreate a separate folder for each cluster, save its members, and add metadata if available.\n",
    "\t\"\"\"\n",
    "\tclusters_output_dir = os.path.join(clusters_dir, 'individual_clusters')\n",
    "\tos.makedirs(clusters_output_dir, exist_ok=True)\n",
    "\t\n",
    "\tprint(\"Separating clusters into individual folders...\")\n",
    "\tfor index, row in tqdm(clusters_df.iterrows(), total=len(clusters_df), desc=\"Creating cluster folders\"):\n",
    "\t\tcluster_id = row['cluster_id']\n",
    "\t\tcluster_folder = os.path.join(clusters_output_dir, f\"cluster_{cluster_id}\")\n",
    "\t\tos.makedirs(cluster_folder, exist_ok=True)\n",
    "\t\t\n",
    "\t\t# Save cluster information\n",
    "\t\tcluster_info = pd.DataFrame({\n",
    "\t\t\t'cluster_id': [cluster_id],\n",
    "\t\t\t'representative': [row['representative']],\n",
    "\t\t\t'members': [row['members']]\n",
    "\t\t})\n",
    "\t\tcluster_info.to_csv(os.path.join(cluster_folder, 'cluster_info.tsv'), sep='\\t', index=False)\n",
    "\t\t\n",
    "\t\t# Save list of members as separate file\n",
    "\t\tmembers = row['members'].split(',')\n",
    "\t\tmembers_df = pd.DataFrame({'uniprot_id': members})\n",
    "\t\tmembers_df.to_csv(os.path.join(cluster_folder, 'members.tsv'), sep='\\t', index=False)\n",
    "\t\t\n",
    "\t\t# If metadata is available, filter and save for this cluster\n",
    "\t\tif metadata_df is not None:\n",
    "\t\t\t# Filter metadata for the members of this cluster\n",
    "\t\t\tcluster_metadata = metadata_df[metadata_df['Entry'].isin(members)]\n",
    "\t\t\tif not cluster_metadata.empty:\n",
    "\t\t\t\tcluster_metadata.to_csv(os.path.join(cluster_folder, 'metadata.tsv'), sep='\\t', index=False)\n",
    "\n",
    "# Main execution\n",
    "# 1. Download clusters\n",
    "clusters_df = download_afdb_clusters()\n",
    "\n",
    "if clusters_df is not None:\n",
    "\t# Get all protein IDs (including representatives and members)\n",
    "\tall_proteins = set()\n",
    "\tfor _, row in clusters_df.iterrows():\n",
    "\t\tall_proteins.add(row['representative'])\n",
    "\t\tall_proteins.update(row['members'].split(','))\n",
    "\t\n",
    "\tprotein_list = list(all_proteins)\n",
    "\tprint(f\"Fetching metadata for {len(protein_list)} proteins...\")\n",
    "\t\n",
    "\t# 2. Get metadata for all proteins\n",
    "\tmetadata_df = get_uniprot_metadata(protein_list)\n",
    "\t\n",
    "\tif metadata_df is not None:\n",
    "\t\tprint(f\"Successfully retrieved metadata for {len(metadata_df)} proteins\")\n",
    "\t\t# Ensure the accession column is named 'Entry' to match UniProt API output\n",
    "\t\tif 'accession' in metadata_df.columns and 'Entry' not in metadata_df.columns:\n",
    "\t\t\tmetadata_df.rename(columns={'accession': 'Entry'}, inplace=True)\n",
    "\t\t\n",
    "\t\t# 3. Separate clusters and include metadata\n",
    "\t\tseparate_clusters(clusters_df, metadata_df)\n",
    "\t\tprint(\"Completed cluster separation with metadata\")\n",
    "\telse:\n",
    "\t\t# If metadata retrieval fails, still separate clusters without metadata\n",
    "\t\tseparate_clusters(clusters_df)\n",
    "\t\tprint(\"Completed cluster separation without metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bfa01c",
   "metadata": {},
   "source": [
    "# Run ft2treebuilder and Maximum Likelihood Tree for Each Input Family\n",
    "This section will iterate over each input family, run the ft2treebuilder pipeline, and also generate a standard maximum likelihood tree for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "families_dir = '../families/'  # Adjust path as needed\n",
    "pdb_families = sorted([f for f in glob.glob(os.path.join(families_dir, '*.pdb'))])\n",
    "print(f\"Found {len(pdb_families)} PDB files for families.\")\n",
    "\n",
    "# Output directory for results\n",
    "output_dir = '../families/tree_results/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Model and matrix paths (adjust as needed)\n",
    "model_path = '../models/monodecoder_model'  # Path without .pkl\n",
    "mafftmat = model_path + '_mafftmat.mtx'\n",
    "submat = model_path + '_submat.txt'\n",
    "raxml_path = '../raxml-ng'  # Path to RAxML-NG executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ft2treebuilder(pdb_file, model_path, mafftmat, submat, output_dir, raxml_path):\n",
    "\t\"\"\"Run ft2treebuilder for a single PDB family\"\"\"\n",
    "\tfamily_name = Path(pdb_file).stem\n",
    "\tfamily_outdir = os.path.join(output_dir, family_name)\n",
    "\tos.makedirs(family_outdir, exist_ok=True)\n",
    "\t\n",
    "\tcmd = f\"python ../ft2treebuilder.py --model {model_path} --mafftmat {mafftmat} --submat {submat} --structures '{pdb_file}' --outdir {family_outdir} --raxmlpath {raxml_path}\"\n",
    "\tprint(f\"Running: {cmd}\")\n",
    "\tsubprocess.run(cmd, shell=True, check=True)\n",
    "\t\n",
    "\t# Return the family output directory and name for ML tree generation\n",
    "\treturn family_outdir, family_name\n",
    "\n",
    "def run_ml_tree(family_outdir, family_name, raxml_path):\n",
    "\t\"\"\"Run a standard maximum likelihood tree using RAxML-NG\"\"\"\n",
    "\t# Find the encoded fasta output\n",
    "\tencoded_fasta = os.path.join(family_outdir, 'encoded.fasta')\n",
    "\tif not os.path.exists(encoded_fasta):\n",
    "\t\t# Try to find it if not in expected location\n",
    "\t\tcandidates = list(Path(family_outdir).glob('*.fasta'))\n",
    "\t\tif candidates:\n",
    "\t\t\tencoded_fasta = str(candidates[0])\n",
    "\t\n",
    "\t# Run ML tree if encoded fasta exists\n",
    "\tif os.path.exists(encoded_fasta):\n",
    "\t\tml_tree_prefix = os.path.join(family_outdir, 'mltree')\n",
    "\t\tml_cmd = f\"{raxml_path} --msa {encoded_fasta} --model GTR+G --prefix {ml_tree_prefix} --threads 2 --seed 12345 --redo\"\n",
    "\t\tprint(f\"Running ML tree: {ml_cmd}\")\n",
    "\t\tsubprocess.run(ml_cmd, shell=True, check=True)\n",
    "\t\treturn True\n",
    "\telse:\n",
    "\t\tprint(f\"Encoded fasta not found for {family_name}, skipping ML tree.\")\n",
    "\t\treturn False\n",
    "\n",
    "# Main loop to process all families\n",
    "for pdb_file in tqdm(pdb_families, desc=\"Running ft2treebuilder on families\"):\n",
    "\t# Run ft2treebuilder\n",
    "\tfamily_outdir, family_name = run_ft2treebuilder(pdb_file, model_path, mafftmat, submat, output_dir, raxml_path)\n",
    "\t\n",
    "\t# Run standard ML tree\n",
    "\trun_ml_tree(family_outdir, family_name, raxml_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075984f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each AlphaFold DB cluster, load the tree, add lineage info, and compute tree scores\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from ete3 import Tree\n",
    "import sys\n",
    "\n",
    "# Ensure src is in the path for importing treescore\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "import treescore\n",
    "\n",
    "# Path to the separated clusters\n",
    "clusters_output_dir = os.path.join(clusters_dir, 'individual_clusters')\n",
    "\n",
    "# Helper: Try to find a tree file in a cluster folder\n",
    "def find_tree_file(cluster_folder):\n",
    "    # Try common tree file names and extensions\n",
    "    for ext in ['*.nwk', '*.tree', '*.tre', '*.newick']:\n",
    "        files = glob.glob(os.path.join(cluster_folder, ext))\n",
    "        if files:\n",
    "            return files[0]\n",
    "    return None\n",
    "\n",
    "# Helper: Load lineage info from metadata.tsv\n",
    "def load_lineages(metadata_path):\n",
    "    df = pd.read_csv(metadata_path, sep='\\t')\n",
    "    # Try to find the correct columns for UniProt ID and lineage\n",
    "    # Accepts 'Entry' or 'accession' for ID, and 'lineage_ids' or 'Taxonomic lineage (Ids)' for lineage\n",
    "    id_col = None\n",
    "    for c in ['Entry', 'accession', 'query']:\n",
    "        if c in df.columns:\n",
    "            id_col = c\n",
    "            break\n",
    "    lineage_col = None\n",
    "    for c in ['lineage_ids', 'Taxonomic lineage (Ids)']:\n",
    "        if c in df.columns:\n",
    "            lineage_col = c\n",
    "            break\n",
    "    if id_col is None or lineage_col is None:\n",
    "        raise ValueError(\"Could not find UniProt ID or lineage column in metadata\")\n",
    "    # Convert lineage string to set\n",
    "    return dict(zip(df[id_col], df[lineage_col].map(lambda x: set(str(x).split(',')) if pd.notnull(x) else set())))\n",
    "\n",
    "# Store results for all clusters\n",
    "cluster_scores = []\n",
    "\n",
    "for cluster_name in os.listdir(clusters_output_dir):\n",
    "    cluster_folder = os.path.join(clusters_output_dir, cluster_name)\n",
    "    if not os.path.isdir(cluster_folder):\n",
    "        continue\n",
    "\n",
    "    tree_file = find_tree_file(cluster_folder)\n",
    "    metadata_file = os.path.join(cluster_folder, 'metadata.tsv')\n",
    "    if not tree_file or not os.path.exists(metadata_file):\n",
    "        print(f\"Skipping {cluster_name}: missing tree or metadata\")\n",
    "        continue\n",
    "\n",
    "    # Load tree using ete3\n",
    "    try:\n",
    "        t = Tree(tree_file, format=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load tree for {cluster_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Load lineage info\n",
    "    try:\n",
    "        leaf_lineages = load_lineages(metadata_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load lineages for {cluster_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Add lineage info to leaves\n",
    "    treescore.label_leaves(t, leaf_lineages)\n",
    "\n",
    "    # Calculate taxonomy overlap scores\n",
    "    treescore.getTaxOverlap(t)\n",
    "    treescore.getTaxOverlap_root(t)\n",
    "\n",
    "    # Collect scores\n",
    "    score = getattr(t, 'score', None)\n",
    "    root_score = getattr(t, 'root_score', None)\n",
    "    cluster_scores.append({\n",
    "        'cluster': cluster_name,\n",
    "        'score': score,\n",
    "        'root_score': root_score\n",
    "    })\n",
    "\n",
    "    print(f\"Cluster: {cluster_name}, score: {score}, root_score: {root_score}\")\n",
    "\n",
    "# Optionally, convert results to DataFrame and save\n",
    "scores_df = pd.DataFrame(cluster_scores)\n",
    "scores_df.to_csv(os.path.join(clusters_output_dir, 'cluster_tree_scores.tsv'), sep='\\t', index=False)\n",
    "print(\"Saved cluster tree scores to cluster_tree_scores.tsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a029f",
   "metadata": {},
   "source": [
    "# Output Summary\n",
    "For each input family, the following outputs are generated in the `tree_results` directory:\n",
    "- ft2treebuilder output tree (using model-based encoding)\n",
    "- Standard maximum likelihood tree (using RAxML-NG on the encoded fasta)\n",
    "\n",
    "You can now visualize or compare these trees for downstream analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
