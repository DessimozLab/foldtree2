{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8502a6b",
   "metadata": {},
   "source": [
    "# Test MonoDecoders: Sequence and Geometry\n",
    "This notebook replicates the training logic from `learn.py` using the decoder in `mono_decoders.py` for amino acid and geometry prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6586f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5103ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmoi/projects/foldtree2\n"
     ]
    }
   ],
   "source": [
    "cd /home/dmoi/projects/foldtree2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "248b7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "from src import pdbgraph\n",
    "from src import foldtree2_ecddcd as ft2\n",
    "from src.mono_decoders import MultiMonoDecoder\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d142a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Data setup\n",
    "datadir = '../../datasets/foldtree2/'\n",
    "dataset_path = 'structs_traininffttest.h5'\n",
    "converter = pdbgraph.PDB2PyG(aapropcsv='config/aaindex1.csv')\n",
    "struct_dat = pdbgraph.StructureDataset(dataset_path)\n",
    "train_loader = DataLoader(struct_dat, batch_size=4, shuffle=True, num_workers=0)\n",
    "data_sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample: HeteroDataBatch(\n",
      "  identifier=[4],\n",
      "  AA={\n",
      "    x=[1185, 20],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  R_true={\n",
      "    x=[1185, 3, 3],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  bondangles={\n",
      "    x=[1185, 3],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  coords={\n",
      "    x=[1185, 3],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  fourier1di={\n",
      "    x=[1185, 80],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  fourier1dr={\n",
      "    x=[1185, 80],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  fourier2di={\n",
      "    x=[4, 1300],\n",
      "    batch=[4],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  fourier2dr={\n",
      "    x=[4, 1300],\n",
      "    batch=[4],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  godnode={\n",
      "    x=[4, 5],\n",
      "    batch=[4],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  godnode4decoder={\n",
      "    x=[4, 5],\n",
      "    batch=[4],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  plddt={\n",
      "    x=[1185, 1],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  positions={\n",
      "    x=[1185, 256],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  res={\n",
      "    x=[1185, 857],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  t_true={\n",
      "    x=[1185, 3],\n",
      "    batch=[1185],\n",
      "    ptr=[5],\n",
      "  },\n",
      "  (godnode4decoder, informs, res)={ edge_index=[2, 1185] },\n",
      "  (godnode, informs, res)={ edge_index=[2, 1185] },\n",
      "  (res, backbone, res)={\n",
      "    edge_index=[2, 2366],\n",
      "    edge_attr=[1181],\n",
      "  },\n",
      "  (res, backbonerev, res)={\n",
      "    edge_index=[2, 2366],\n",
      "    edge_attr=[1181],\n",
      "  },\n",
      "  (res, contactPoints, res)={\n",
      "    edge_index=[2, 8830],\n",
      "    edge_attr=[8830],\n",
      "  },\n",
      "  (res, hbond, res)={\n",
      "    edge_index=[2, 1618],\n",
      "    edge_attr=[1618],\n",
      "  },\n",
      "  (res, informs, godnode)={ edge_index=[2, 1185] },\n",
      "  (res, informs, godnode4decoder)={ edge_index=[2, 1185] },\n",
      "  (res, window, res)={\n",
      "    edge_index=[2, 2354],\n",
      "    edge_attr=[2354],\n",
      "  },\n",
      "  (res, windowrev, res)={\n",
      "    edge_index=[2, 1181],\n",
      "    edge_attr=[1181],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Data sample:', data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc573dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "/home/dmoi/miniforge3/envs/pyg/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 4 3 0.005\n",
      "MultiMonoDecoder(\n",
      "  (decoders): ModuleDict(\n",
      "    (sequence_transformer): Transformer_AA_Decoder(\n",
      "      (input_proj): Sequential(\n",
      "        (0): Linear(in_features=276, out_features=100, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.005, inplace=False)\n",
      "        (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (4): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "      )\n",
      "      (transformer_encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.005, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "            (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.005, inplace=False)\n",
      "            (dropout2): Dropout(p=0.005, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (lin): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): DynamicTanh(normalized_shape=100, alpha_init_value=0.5, channels_last=True)\n",
      "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): GELU(approximate='none')\n",
      "        (8): DynamicTanh(normalized_shape=50, alpha_init_value=0.5, channels_last=True)\n",
      "        (9): Linear(in_features=50, out_features=20, bias=True)\n",
      "        (10): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (contacts): HeteroGAE_geo_Decoder(\n",
      "      (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (convs): ModuleList(\n",
      "        (0-1): 2 x HeteroConv(num_relations=3)\n",
      "      )\n",
      "      (norms): ModuleList(\n",
      "        (0-1): 2 x GraphNorm(100)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.005, inplace=False)\n",
      "      (jk): JumpingKnowledge(cat)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (lin): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): DynamicTanh(normalized_shape=200, alpha_init_value=0.5, channels_last=True)\n",
      "        (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (7): GELU(approximate='none')\n",
      "        (8): DynamicTanh(normalized_shape=50, alpha_init_value=0.5, channels_last=True)\n",
      "      )\n",
      "      (godnodedecoder): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (3): GELU(approximate='none')\n",
      "        (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): DynamicTanh(normalized_shape=50, alpha_init_value=0.5, channels_last=True)\n",
      "        (7): Linear(in_features=50, out_features=2600, bias=True)\n",
      "      )\n",
      "      (contact_mlp): Sequential(\n",
      "        (0): Dropout(p=0.005, inplace=False)\n",
      "        (1): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Linear(in_features=50, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "ndim = data_sample['res'].x.shape[1]\n",
    "ndim_godnode = data_sample['godnode'].x.shape[1]\n",
    "ndim_fft2i = data_sample['fourier2di'].x.shape[1]\n",
    "ndim_fft2r = data_sample['fourier2dr'].x.shape[1]\n",
    "\n",
    "num_embeddings = 40\n",
    "embedding_dim = 20\n",
    "hidden_size = 100\n",
    "\n",
    "encoder = ft2.mk1_Encoder(\n",
    "\tin_channels=ndim,\n",
    "\thidden_channels=[hidden_size, hidden_size],\n",
    "\tout_channels=embedding_dim,\n",
    "\tmetadata={'edge_types': [('res','contactPoints','res'), ('res','hbond','res')]},\n",
    "\tnum_embeddings=num_embeddings,\n",
    "\tcommitment_cost=0.9,\n",
    "\tedge_dim=1,\n",
    "\tencoder_hidden=hidden_size,\n",
    "\tEMA=False,\n",
    "\tnheads=5,\n",
    "\tdropout_p=0.005,\n",
    "\treset_codes=False,\n",
    "\tflavor='transformer',\n",
    "\tfftin=False\n",
    ")\n",
    "\n",
    "# MultiMonoDecoder for sequence and geometry\n",
    "mono_configs = {\n",
    "\t'sequence_transformer': {\n",
    "\t\t'in_channels': {'res': embedding_dim},\n",
    "\t\t'xdim': 20,\n",
    "\t\t'concat_positions': True,\n",
    "\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*3 , ('res','backbonerev','res'): [hidden_size]*3},\n",
    "\t\t'layers': 3,\n",
    "\t\t'AAdecoder_hidden': [hidden_size, hidden_size//2, hidden_size//2],\n",
    "\t\t'amino_mapper': converter.aaindex,\n",
    "\t\t'flavor': 'sage',\n",
    "\t\t'dropout': 0.005,\n",
    "\t\t'normalize': True,\n",
    "\t\t'residual': True\n",
    "\t},\n",
    "\t\n",
    "\t'contacts': {\n",
    "\t\t'in_channels': {'res': embedding_dim, 'godnode4decoder': ndim_godnode, 'foldx': 23 ,  'fft2r': ndim_fft2r, 'fft2i': ndim_fft2i},\n",
    "\t\t'concat_positions': True,\n",
    "\t\t'hidden_channels': {('res','backbone','res'): [hidden_size]*3, ('res','backbonerev','res'): [hidden_size]*3, ('res','informs','godnode4decoder'): [hidden_size]*3},\n",
    "\t\t'layers': 2,\n",
    "\t\t'FFT2decoder_hidden': [hidden_size//2, hidden_size//2, hidden_size//2],\n",
    "\t\t'contactdecoder_hidden': [hidden_size//2, hidden_size//2],\n",
    "\t\t'nheads': 2,\n",
    "\t\t'Xdecoder_hidden': [hidden_size, hidden_size//2,  hidden_size//2 ],\n",
    "\t\t'metadata': converter.metadata,\n",
    "\t\t'flavor': 'sage',\n",
    "\t\t'dropout': 0.005,\n",
    "\t\t'output_fft': True,\n",
    "        'output_rt':False,\n",
    "\t\t'normalize': True,\n",
    "\t\t'residual': False,\n",
    "\t\t'contact_mlp': True\n",
    "\t}\n",
    "}\n",
    "decoder = MultiMonoDecoder(tasks=['sequence_transformer', 'contacts'], configs=mono_configs)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b3ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████| 1250/1250 [04:01<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: AA Loss: 2.3597, Edge Loss: 1.1617, VQ Loss: 0.2810 , FFT2 Loss: 30.1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|██████████▋                      | 405/1250 [01:20<03:16,  4.30it/s]"
     ]
    }
   ],
   "source": [
    "# Training loop (demo, similar to learn.py)\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "num_epochs = 5  # For demonstration, keep small\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "edgeweight = 0.01\n",
    "xweight = 1\n",
    "fft2weight = 0.01\n",
    "vqweight = 0.0001\n",
    "clip_grad = True\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\ttotal_loss_x = 0\n",
    "\ttotal_loss_edge = 0\n",
    "\ttotal_vq = 0\n",
    "\tfor data in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "\t\tdata = data.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tz, vqloss = encoder(data)\n",
    "\t\tdata['res'].x = z\n",
    "\t\t# For demonstration, only sequence and contacts tasks\n",
    "\t\tout = decoder(data, None)\n",
    "\t\trecon_x = out['aa'] if isinstance(out, dict) and 'aa' in out else out[0] if isinstance(out, (list, tuple)) else None\n",
    "\t\tfft2_x = out['fft2pred'] if isinstance(out, dict) and 'fft2pred' in out else out[1] if isinstance(out, (list, tuple)) else None\n",
    "\t\t# Edge loss: use contactPoints if available\n",
    "\t\tedge_index = data.edge_index_dict['res', 'contactPoints', 'res'] if hasattr(data, 'edge_index_dict') and ('res', 'contactPoints', 'res') in data.edge_index_dict else None\n",
    "\t\tif edge_index is not None:\n",
    "\t\t\tedgeloss, _ = ft2.recon_loss(data, edge_index, decoder, plddt=False, offdiag=False , key = 'edge_probs')\n",
    "\t\telse:\n",
    "\t\t\tedgeloss = torch.tensor(0.0, device=device)\n",
    "\t\txloss = ft2.aa_reconstruction_loss(data['AA'].x, recon_x)\n",
    "\t\tfft2loss = F.smooth_l1_loss(torch.cat( [ data['fourier2dr'].x ,data['fourier2di'].x ] ,axis = 1 ) , fft2_x )\n",
    "\t\tloss = xweight * xloss + edgeweight * edgeloss + vqweight * vqloss + fft2loss* fft2weight\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\tif clip_grad:\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1.0)\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss_x += xloss.item()\n",
    "\t\ttotal_loss_edge += edgeloss.item()\n",
    "\t\ttotal_vq += vqloss.item() if isinstance(vqloss, torch.Tensor) else float(vqloss)\n",
    "\tscheduler.step(total_loss_x)\n",
    "\t\n",
    "\tprint(f\"Epoch {epoch}: AA Loss: {total_loss_x/len(train_loader):.4f}, Edge Loss: {total_loss_edge/len(train_loader):.4f}, VQ Loss: {total_vq/len(train_loader):.4f} , FFT2 Loss: {fft2loss.item()/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32008153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
